{"cluster_depth": null, "cluster_roots": [], "link_data": {"directed": true, "multigraph": true, "graph": {}, "nodes": [{"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 36, "span_ids": ["imports"], "start_line": 1, "end_line": 5, "community": null}, "content": "from moatless.repository import FileRepository\nfrom moatless.workspace import Workspace\nfrom moatless.transition_rules import TransitionRules\nfrom moatless.loop import AgenticLoop", "kind": "Chunk", "id": "moatless/__init__.py#1.4"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_json_search_and_code.search_and_code_transitio", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 479, "span_ids": ["imports"], "start_line": 1, "end_line": 66, "community": null}, "content": "import json\nimport logging\nfrom typing import Optional\n\nimport instructor\n\nfrom moatless.transition_rules import TransitionRules\nfrom moatless.benchmark.evaluation import create_evaluation_name, Evaluation\nfrom moatless.edit.edit import EditCode\nfrom moatless.edit.plan import PlanToCode\nfrom moatless.find.decide import DecideRelevance\nfrom moatless.find.identify import IdentifyCode\nfrom moatless.find.search import SearchCode\nfrom moatless.transition_rules import TransitionRule\nfrom moatless.state import Finished, Rejected\nfrom moatless.transitions import (\r\n    search_and_code_transitions,\r\n    search_transitions,\r\n    code_transitions,\r\n)\n\n# model = \"claude-3-5-sonnet-20240620\"\r\n\n# model = \"gpt-4o-2024-05-13\"\r\nmodel = \"azure/gpt-4o\"\n\n# model = \"openrouter/anthropic/claude-3.5-sonnet\"\r\n\nglobal_params = {\r\n    \"model\": model,\r\n    \"temperature\": 0.2,\r\n    \"max_tokens\": 2000,\r\n    \"max_prompt_file_tokens\": 8000,\r\n}\n\nstate_params = {\r\n    SearchCode: {\r\n        \"provide_initial_context\": True,\r\n        \"max_search_results\": 75,\r\n        \"initial_context_tokens\": 6000,\r\n        \"initial_search_results\": 100,\r\n        \"initial_context_spans_per_file\": 5,\r\n    },\r\n    IdentifyCode: {\"expand_context\": True},\r\n    DecideRelevance: {\r\n        \"finish_after_relevant_count\": 1,\r\n    },\r\n    PlanToCode: {\r\n        \"max_tokens_in_edit_prompt\": 750,\r\n        \"expand_context_with_related_spans\": False,\r\n        \"finish_on_review\": True,\r\n    },\r\n    EditCode: {\r\n        \"chain_of_thought\": False,\r\n        \"show_file_context\": False,\r\n        \"max_prompt_file_tokens\": 8000,\r\n    },\r\n}\n\nindex_store_dir = f\"/home/albert/20240522-voyage-code-2\"\nrepo_base_dir = \"/tmp/repos\"\nevaluations_dir = \"/home/albert/repos/albert/moatless/evaluations\"\n\nsearch_and_code = search_and_code_transitions(\r\n    global_params=global_params, state_params=state_params\r\n)", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#2.65"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_identified_spans_but_failed_implementation_coding_test_set._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 703, "span_ids": ["imports", "impl:17"], "start_line": 68, "end_line": 134, "community": null}, "content": "identified_spans_but_failed_implementation = [\r\n    \"django__django-11583\",\r\n    \"django__django-11179\",\r\n    \"django__django-12286\",\r\n    \"django__django-12700\",\r\n    \"django__django-12708\",\r\n    \"django__django-13315\",\r\n    \"django__django-13933\",\r\n    \"django__django-14382\",\r\n    \"django__django-14608\",\r\n    \"django__django-14787\",\r\n    \"django__django-14999\",\r\n    \"django__django-15347\",\r\n    \"django__django-15789\",\r\n    \"django__django-16041\",\r\n    \"django__django-16046\",\r\n    \"django__django-16595\",\r\n    \"matplotlib__matplotlib-26020\",\r\n    \"matplotlib__matplotlib-24149\",\r\n    \"mwaskom__seaborn-3190\",\r\n    \"psf__requests-3362\",\r\n    \"pytest-dev__pytest-5692\",\r\n    \"scikit-learn__scikit-learn-11281\",\r\n    \"django__django-2708\",\r\n    \"scikit-learn__scikit-learn-13241\",\r\n    \"scikit-learn__scikit-learn-13779\",\r\n    \"scikit-learn__scikit-learn-14894\",\r\n    \"scikit-learn__scikit-learn-15535\",\r\n    \"scikit-learn__scikit-learn-25570\",\r\n    \"sympy__sympy-18621\",\r\n    \"sympy__sympy-23117\",\r\n    \"sympy__sympy-22714\",\r\n    \"sympy__sympy-24213\",\r\n]\n\ncoding_test_set = [\r\n    \"django__django-11848\",\r\n    \"django__django-12308\",\r\n    \"django__django-12497\",\r\n    \"django__django-13551\",\r\n    \"django__django-13660\",\r\n    \"django__django-14238\",\r\n    \"django__django-14411\",\r\n    \"django__django-14787\",\r\n    \"django__django-16041\",\r\n    \"django__django-17051\",\r\n    \"matplotlib__matplotlib-24149\",\r\n    \"mwaskom__seaborn-3190\",\r\n    \"psf__requests-1963\",\r\n    \"pylint-dev__pylint-6506\",\r\n    \"pylint-dev__pylint-7993\",\r\n    \"pytest-dev__pytest-7432\",\r\n    \"scikit-learn__scikit-learn-13142\",\r\n    \"scikit-learn__scikit-learn-25570\",\r\n    \"sphinx-doc__sphinx-7975\",\r\n    \"sympy__sympy-12481\",\r\n    \"sympy__sympy-14396\",\r\n    \"sympy__sympy-14817\",\r\n    \"sympy__sympy-15609\",\r\n    \"sympy__sympy-16988\",\r\n    \"sympy__sympy-18189\",\r\n    \"sympy__sympy-18532\",\r\n    \"sympy__sympy-21847\",\r\n    \"sympy__sympy-22005\",\r\n    \"sympy__sympy-22714\",\r\n    \"sympy__sympy-24066\",\r\n]", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#3.66"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_search_and_identify_set_run_evaluation.transitions.search_and_code_transitio", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 277, "span_ids": ["impl:17", "run_evaluation"], "start_line": 136, "end_line": 169, "community": null}, "content": "search_and_identify_set = [\r\n    \"matplotlib__matplotlib-25442\",\r\n    \"matplotlib__matplotlib-23562\",\r\n    \"pytest-dev__pytest-11148\",\r\n    \"sphinx-doc__sphinx-8721\",\r\n    \"sphinx-doc__sphinx-10325\",\r\n    \"scikit-learn__scikit-learn-15535\",\r\n    \"scikit-learn__scikit-learn-11281\",\r\n    \"astropy__astropy-6938\",\r\n    \"sympy__sympy-17022\",\r\n    \"sympy__sympy-17139\",\r\n    \"sympy__sympy-13031\",\r\n    \"django__django-15814\",\r\n    \"django__django-15498\",\r\n    \"django__django-12125\",\r\n    \"django__django-13964\",\r\n    \"django__django-11964\",\r\n    \"django__django-14580\",\r\n    \"django__django-17087\",\r\n]\n\n\ndef run_evaluation():\n    max_file_context_lines = 1000\n\n    transitions = search_and_code_transitions(\r\n        state_params={\r\n            PlanToCode: {\r\n                \"max_prompt_file_tokens\": 16000,\r\n                \"max_tokens_in_edit_prompt\": 500,\r\n                \"max_file_context_lines\": max_file_context_lines,\r\n            }\r\n        },\r\n    )", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#4.33"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_evaluate_search_evaluate_search.evaluation_run_evaluation", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 188, "span_ids": ["evaluate_search"], "start_line": 172, "end_line": 198, "community": null}, "content": "def evaluate_search():\n    transitions = TransitionRules(\r\n        global_params=global_params,\r\n        state_params={\r\n            SearchCode: {\"max_search_results\": 50, \"provide_initial_context\": True},\r\n        },\r\n        initial_state=SearchCode,\r\n        transitions=[\r\n            TransitionRule(source=SearchCode, dest=Finished, trigger=\"did_search\"),\r\n            TransitionRule(source=SearchCode, dest=Finished, trigger=\"finish\"),\r\n        ],\r\n    )\n\n    evaluation_name = create_evaluation_name(model, \"search\")\n\n    evaluation = Evaluation(\r\n        transitions=transitions,\r\n        evaluations_dir=evaluations_dir + \"/search\",\r\n        evaluation_name=evaluation_name,\r\n        index_store_dir=index_store_dir,\r\n        repo_base_dir=repo_base_dir,\r\n        max_file_context_tokens=16000,\r\n        litellm_callback=\"langfuse\",\r\n        detailed_report=True,\r\n    )\n\n    evaluation.run_evaluation_with_moatless_dataset(use_test_subset=True)", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#5.26"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_evaluate_search_and_identify_evaluate_search_and_identify.evaluation_run_evaluation", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 217, "span_ids": ["evaluate_search_and_identify"], "start_line": 201, "end_line": 228, "community": null}, "content": "def evaluate_search_and_identify(\r\n    resolved_by: Optional[int] = 4,\r\n    previous_trajectory_dir: Optional[str] = None,\r\n    instance_ids: Optional[list] = None,\r\n):\n    transitions = search_transitions(\r\n        global_params=global_params,\r\n        state_params=state_params,\r\n    )\n\n    evaluation_name = create_evaluation_name(\"search_and_identify_3\", model)\n    # evaluation_name = \"20240624_search_and_identify_claude-3-5-sonnet-20240620\"\r\n\n    evaluation = Evaluation(\r\n        transitions=transitions,\r\n        evaluations_dir=evaluations_dir + \"/search_and_identify\",\r\n        evaluation_name=evaluation_name,\r\n        index_store_dir=index_store_dir,\r\n        repo_base_dir=repo_base_dir,\r\n        previous_trajectory_dir=previous_trajectory_dir,\r\n        max_file_context_tokens=16000,\r\n        litellm_callback=\"langfuse\",\r\n        detailed_report=True,\r\n    )\n\n    evaluation.run_evaluation_with_moatless_dataset(\r\n        resolved_by=resolved_by, instance_ids=instance_ids\r\n    )", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#6.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_evaluate_search_and_code_evaluate_search_and_code.evaluation_run_evaluation", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 233, "span_ids": ["evaluate_search_and_code"], "start_line": 231, "end_line": 258, "community": null}, "content": "def evaluate_search_and_code(\r\n    resolved_by: Optional[int],\r\n    previous_trajectory_dir: Optional[str] = None,\r\n    retry_state: Optional[str] = None,\r\n    instance_ids: Optional[list] = None,\r\n):\n    evaluation_name = create_evaluation_name(\"search_and_code\", model)\n    # evaluation_name = \"20240624_search_and_code_2_claude-3-5-sonnet-20240620\"\r\n    # evaluation_name = \"20240623_moatless_claude-3.5-sonnet\"\r\n\n    evaluation = Evaluation(\r\n        transitions=search_and_code,\r\n        evaluations_dir=evaluations_dir + \"/search_and_code\",\r\n        evaluation_name=evaluation_name,\r\n        index_store_dir=index_store_dir,\r\n        repo_base_dir=repo_base_dir,\r\n        previous_trajectory_dir=previous_trajectory_dir,\r\n        retry_state=retry_state,\r\n        max_file_context_tokens=16000,\r\n        num_workers=3,\r\n        litellm_callback=\"langfuse\",\r\n        detailed_report=True,\r\n    )\n\n    evaluation.run_evaluation_with_moatless_dataset(\r\n        resolved_by=resolved_by,\r\n        instance_ids=instance_ids,\r\n    )", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#7.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_evaluate_coding_evaluate_coding.df.evaluation_run_evaluation", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 154, "span_ids": ["evaluate_coding"], "start_line": 261, "end_line": 279, "community": null}, "content": "def evaluate_coding():\n    evaluation_name = create_evaluation_name(\"coding\", model)\n    # evaluation_name = \"20240623_coding_2_claude-3.5-sonnet\"\r\n\n    evaluation = Evaluation(\r\n        transitions=code_transitions(\r\n            global_params=global_params, state_params=state_params\r\n        ),\r\n        use_expected_file_context=True,\r\n        evaluations_dir=evaluations_dir + \"/coding\",\r\n        evaluation_name=evaluation_name,\r\n        index_store_dir=index_store_dir,\r\n        repo_base_dir=repo_base_dir,\r\n        max_file_context_tokens=16000,\r\n        litellm_callback=\"langfuse\",\r\n        detailed_report=True,\r\n    )\n\n    df = evaluation.run_evaluation_with_moatless_dataset(instance_ids=coding_test_set)", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#8.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_evaluate_plan_evaluate_plan.for_instance_id_in_df_ind.print_df_loc_instance_id_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 476, "span_ids": ["evaluate_plan"], "start_line": 282, "end_line": 338, "community": null}, "content": "def evaluate_plan(previous_trajectory_dir: Optional[str] = None):\n    transitions = TransitionRules(\r\n        global_params=global_params,\r\n        state_params={\r\n            SearchCode: {\r\n                \"provide_initial_context\": True,\r\n                \"max_search_results\": 75,\r\n                \"initial_context_tokens\": 6000,\r\n                \"initial_search_results\": 100,\r\n                \"initial_context_spans_per_file\": 5,\r\n            },\r\n            PlanToCode: {\r\n                \"max_prompt_file_tokens\": 16000,\r\n                \"max_tokens_in_edit_prompt\": 750,\r\n                \"expand_context_with_related_spans\": False,\r\n            },\r\n        },\r\n        initial_state=SearchCode,\r\n        transitions=[\r\n            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger=\"did_search\"),\r\n            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger=\"finish\"),\r\n            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(\r\n                source=DecideRelevance,\r\n                dest=PlanToCode,\r\n                trigger=\"finish\",\r\n                exclude_fields={\"message\"},\r\n            ),\r\n            TransitionRule(source=PlanToCode, dest=Finished, trigger=\"edit_code\"),\r\n            TransitionRule(source=PlanToCode, dest=Rejected, trigger=\"finish\"),\r\n            TransitionRule(source=PlanToCode, dest=Rejected, trigger=\"reject\"),\r\n        ],\r\n    )\n\n    evaluation_name = create_evaluation_name(\"search_and_plan_2\", model)\n\n    evaluation = Evaluation(\r\n        transitions=transitions,\r\n        evaluations_dir=evaluations_dir + \"/search_and_plan\",\r\n        evaluation_name=evaluation_name,\r\n        index_store_dir=index_store_dir,\r\n        repo_base_dir=repo_base_dir,\r\n        previous_trajectory_dir=previous_trajectory_dir,\r\n        retry_state=\"PlanToCode\",\r\n        max_file_context_tokens=16000,\r\n        litellm_callback=\"langfuse\",\r\n        detailed_report=True,\r\n    )\n\n    df = evaluation.run_evaluation_with_moatless_dataset(\r\n        instance_ids=identified_spans_but_failed_implementation\r\n    )\n\n    # print out instance id and if planned\r\n    for instance_id in df.index:\n        print(df.loc[instance_id, \"instance_id\"], df.loc[instance_id, \"planned\"])", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#9.56"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py_if___name_____main____", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\claude_evaluation.py", "file_name": "claude_evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 201, "span_ids": ["impl:21"], "start_line": 341, "end_line": 361, "community": null}, "content": "if __name__ == \"__main__\":\n    logging.basicConfig(\r\n        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\r\n        level=logging.INFO,\r\n    )\n    logging.getLogger().setLevel(logging.INFO)\n    logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n    logging.getLogger(\"Evaluator\").setLevel(logging.INFO)\n\n    # evaluate_coding()\r\n    # evaluate_search_and_identify()\r\n    evaluate_search_and_code(\r\n        1,\r\n        \"/home/albert/repos/albert/moatless/evaluations/20240623_moatless_claude-3.5-sonnet/trajs\",\r\n        retry_state=\"PlanToCode\",\r\n    )\n    # evaluate_search_and_code()\r\n    # evaluate_search_and_code(\r\n    #    # \"/home/albert/repos/albert/moatless/evaluations/search_and_code/20240622_search_and_code_6_claude-3.5-sonnet/trajs\"\r\n    # )\r", "kind": "Chunk", "id": "benchmark/claude_evaluation.py#10.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\create_dataset.py_json_read_predictions.return.predictions", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\create_dataset.py", "file_name": "create_dataset.py", "file_type": "text/x-python", "category": "test", "tokens": 298, "span_ids": ["imports", "read_predictions"], "start_line": 1, "end_line": 36, "community": null}, "content": "import json\n\nimport pandas as pd\n\nfrom moatless.benchmark.swebench import setup_swebench_repo, sorted_instances\nfrom moatless.benchmark.utils import get_file_spans_from_patch\nfrom moatless.repository import FileRepository\n\nexperiments_runs = [\r\n    \"20240402_sweagent_claude3opus\",\r\n    \"20240402_sweagent_gpt4\",\r\n    \"20240509_amazon-q-developer-agent-20240430-dev\",\r\n    \"20240523_aider\",\r\n    \"20240524_opencsg_starship_gpt4\",\r\n    \"20240530_autocoderover-v20240408\",\r\n    \"20240604_CodeR\",\r\n    \"20240612_IBM_Research_Agent101\",\r\n    \"20240612_marscode-agent-dev\",\r\n    \"20240612_MASAI_gpt4o\",\r\n    \"20240615_appmap-navie_gpt4o\",\r\n    \"20240617_factory_code_droid\",\r\n    \"20240617_moatless_gpt4o\",\r\n]\n\ndataset_path = (\r\n    \"/home/albert/repos/albert/moatless/datasets/swebench_lite_all_evaluations.json\"\r\n)\n\n\ndef read_predictions(pred_path: str):\n    predictions = {}\n    with open(pred_path) as f:\n        for line in f.readlines():\n            prediction = json.loads(line)\n            predictions[prediction[\"instance_id\"]] = prediction[\"model_patch\"]\n    return predictions", "kind": "Chunk", "id": "benchmark/create_dataset.py#11.35"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\create_dataset.py_generate_report_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\create_dataset.py", "file_name": "create_dataset.py", "file_type": "text/x-python", "category": "test", "tokens": 791, "span_ids": ["impl:5", "generate_report"], "start_line": 39, "end_line": 156, "community": null}, "content": "def generate_report():\n    results = {}\n\n    experiments_dir = \"/home/albert/repos/stuffs/experiments/evaluation/lite\"\n\n    runs = []\n    for run_name in experiments_runs:\n        runs.append(\r\n            (\r\n                run_name,\r\n                f\"{experiments_dir}/{run_name}/all_preds.jsonl\",\r\n                f\"{experiments_dir}/{run_name}/results/results.json\",\r\n            )\r\n        )\n\n    runs.append(\r\n        (\r\n            \"autocoderover_v20240620\",\r\n            \"/home/albert/repos/stuffs/acr-experiments/evaluation/lite/20240621_autocoderover-v20240620/all_preds.jsonl\",\r\n            \"/home/albert/repos/stuffs/acr-experiments/evaluation/lite/20240621_autocoderover-v20240620/results.json\",\r\n        )\r\n    )\n\n    runs.append(\r\n        (\r\n            \"20240622_Lingma_Agent\",\r\n            \"/home/albert/repos/stuffs/alibaba-experiments/evaluation/lite/20240622_Lingma_Agent/all_preds.jsonl\",\r\n            \"/home/albert/repos/stuffs/alibaba-experiments/evaluation/lite/20240622_Lingma_Agent/results.json\",\r\n        )\r\n    )\n\n    for run_name, prediction_file, result_file in runs:\n        with open(result_file) as file:\n            final_report = json.load(file)\n\n        resolved_tasks = final_report[\"resolved\"]\n        predictions_by_id = read_predictions(prediction_file)\n\n        results[run_name] = {\r\n            \"resolved_tasks\": resolved_tasks,\r\n            \"predictions\": predictions_by_id,\r\n        }\n\n    evaluation_dataset = []\n\n    report = []\n\n    instances = sorted_instances(\r\n        split=\"test\", dataset_name=\"princeton-nlp/SWE-bench_Lite\"\r\n    )\n    for instance in instances:\n        instance_id = instance[\"instance_id\"]\n        expected_patch = instance[\"patch\"]\n        repo_dir = setup_swebench_repo(instance, repo_base_dir=\"/tmp/repos_2\")\n        file_repo = FileRepository(repo_dir)\n\n        expected_file_spans = get_file_spans_from_patch(file_repo, expected_patch)\n\n        evaluation_instance = {\r\n            \"instance_id\": instance_id,\r\n            \"repo\": instance[\"repo\"],\r\n            \"base_commit\": instance[\"base_commit\"],\r\n            \"problem_statement\": instance[\"problem_statement\"],\r\n            \"golden_patch\": instance[\"patch\"],\r\n            \"expected_spans\": expected_file_spans,\r\n            \"resolved_by\": [],\r\n            \"alternative_spans\": [],\r\n        }\n\n        for run_name, _, _ in runs:\n            prediction = results[run_name][\"predictions\"].get(instance_id)\n\n            if instance_id not in results[run_name][\"resolved_tasks\"]:\n                continue\n\n            file_spans = get_file_spans_from_patch(file_repo, prediction)\n\n            is_different = False\n            alternative_spans = {}\n            for file_path, span_ids in file_spans.items():\n                if file_path in expected_file_spans:\n                    alternative_spans[file_path] = span_ids\n\n                    if set(expected_file_spans[file_path]).difference(set(span_ids)):\n                        is_different = True\n\n            if is_different:\n                evaluation_instance[\"alternative_spans\"].append(\r\n                    {\"run_name\": run_name, \"spans\": alternative_spans}\r\n                )\n\n            resolved = {\r\n                \"name\": run_name,\r\n                \"patch\": prediction,\r\n                \"updated_spans\": file_spans,\r\n                \"alternative_spans\": alternative_spans,\r\n            }\n\n            evaluation_instance[\"resolved_by\"].append(resolved)\n\n        report.append(\r\n            {\r\n                \"instance_id\": instance_id,\r\n                \"resolved_by\": len(evaluation_instance[\"resolved_by\"]),\r\n            }\r\n        )\n\n        evaluation_dataset.append(evaluation_instance)\n\n        with open(dataset_path, \"w\") as f:\n            json.dump(evaluation_dataset, f, indent=2)\n\n    return pd.DataFrame(report)\n\n\nif __name__ == \"__main__\":\n    df = generate_report()", "kind": "Chunk", "id": "benchmark/create_dataset.py#12.117"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_concurrent.futures_TEST_SUBSET._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 553, "span_ids": ["imports"], "start_line": 1, "end_line": 70, "community": null}, "content": "import concurrent.futures\nimport json\nimport logging\nimport os\nimport subprocess\nimport time\nimport traceback\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nfrom typing import Optional, Tuple\n\nimport instructor\nimport litellm\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nfrom moatless.benchmark.report_v2 import to_result, generate_md_report\nfrom moatless.trajectory import Trajectory\nfrom moatless.transition_rules import TransitionRules\nfrom moatless.benchmark.swebench import (\r\n    found_in_alternative_spans,\r\n    found_in_expected_spans,\r\n    get_repo_dir_name,\r\n    load_instance,\r\n    setup_swebench_repo,\r\n    sorted_instances,\r\n)\nfrom moatless.benchmark.utils import (\r\n    get_missing_files,\r\n    trace_metadata,\r\n)\nfrom moatless.file_context import FileContext\nfrom moatless.loop import AgenticLoop\nfrom moatless.repository import FileRepository, GitRepository\nfrom moatless.workspace import Workspace\n\nlogger = logging.getLogger(__name__)\n\nTEST_SUBSET = [\r\n    \"astropy__astropy-14995\",\r\n    \"django__django-10914\",\r\n    \"django__django-11039\",\r\n    \"django__django-11179\",\r\n    \"django__django-12286\",\r\n    \"django__django-12453\",\r\n    \"django__django-12983\",\r\n    \"django__django-13230\",\r\n    \"django__django-13710\",\r\n    \"django__django-13757\",\r\n    \"django__django-14915\",\r\n    \"django__django-14999\",\r\n    \"django__django-15789\",\r\n    \"matplotlib__matplotlib-23913\",\r\n    \"matplotlib__matplotlib-23964\",\r\n    \"pydata__xarray-5131\",\r\n    \"pytest-dev__pytest-11143\",\r\n    \"pytest-dev__pytest-5692\",\r\n    \"pytest-dev__pytest-7373\",\r\n    \"scikit-learn__scikit-learn-13142\",\r\n    \"scikit-learn__scikit-learn-13241\",\r\n    \"scikit-learn__scikit-learn-13439\",\r\n    \"scikit-learn__scikit-learn-13496\",\r\n    \"scikit-learn__scikit-learn-13779\",\r\n    \"scikit-learn__scikit-learn-14894\",\r\n    \"scikit-learn__scikit-learn-25570\",\r\n    \"sympy__sympy-13480\",\r\n    \"sympy__sympy-13647\",\r\n    \"sympy__sympy-20212\",\r\n    \"sympy__sympy-24213\",\r\n]", "kind": "Chunk", "id": "benchmark/evaluation.py#13.69"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation_Evaluation.__init__.if_os_path_exists_result_.else_.self.report._resolved_ids_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 572, "span_ids": ["Evaluation", "Evaluation.__init__"], "start_line": 73, "end_line": 138, "community": null}, "content": "class Evaluation:\n    def __init__(\r\n        self,\r\n        index_store_dir: str,\r\n        repo_base_dir: str,\r\n        evaluations_dir: str,\r\n        evaluation_name: str,\r\n        transitions: TransitionRules,\r\n        instructor_mode: instructor.Mode | None = None,\r\n        max_cost: float = 0.5,\r\n        max_transitions: int = 25,\r\n        max_expansions: int = 2,\r\n        max_file_context_tokens: int = 16000,\r\n        markdown_report: bool = False,\r\n        litellm_callback: Optional[str] = None,\r\n        previous_trajectory_dir: Optional[str] = None,\r\n        retry_state: Optional[str] = None,\r\n        num_workers: int = 1,\r\n        detailed_report: bool = False,\r\n    ):\n        self.index_store_dir = index_store_dir\n        self.repo_base_dir = repo_base_dir\n        self.evaluations_dir = evaluations_dir\n        self.num_workers = num_workers\n        self.detailed_report = detailed_report\n        self.markdown_report = markdown_report\n\n        self.evaluation_name = evaluation_name\n        self.max_file_context_tokens = max_file_context_tokens\n        self.max_cost = max_cost\n        self.max_expansions = max_expansions\n        self.max_transitions = max_transitions\n        self.instructor_mode = instructor_mode\n\n        self.transitions = transitions\n\n        litellm.drop_params = True\n\n        self.evaluation_dir = f\"{evaluations_dir}/{evaluation_name}\"\n        self.trajectory_dir = f\"{self.evaluations_dir}/{evaluation_name}/trajs\"\n        self.logs_dir = f\"{self.evaluations_dir}/{evaluation_name}/prompt_logs\"\n        self.predictions_path = f\"{self.evaluation_dir}/all_preds.jsonl\"\n\n        self.previous_trajectory_dir = previous_trajectory_dir\n        self.retry_state = retry_state\n\n        logger.info(f\"Save trajectories to directory: {self.trajectory_dir}\")\n        if not os.path.exists(self.trajectory_dir):\n            os.makedirs(self.trajectory_dir)\n\n        logger.info(f\"Save logs to directory: {self.logs_dir}\")\n        if not os.path.exists(self.logs_dir):\n            os.makedirs(self.logs_dir)\n\n        if litellm_callback:\n            litellm.success_callback = [litellm_callback]\n            litellm.failure_callback = [litellm_callback]\n\n        # This is only to set instances as resolved after all evaluations have been run to generate the report\r\n        # TODO: Run swe-bench-docker after the prediction is generated\r\n        result_file = f\"{self.evaluation_dir}/result.json\"\n        if os.path.exists(result_file):\n            with open(os.path.join(result_file)) as f:\n                self.report = json.load(f)\n        else:\n            self.report = {\"resolved_ids\": []}", "kind": "Chunk", "id": "benchmark/evaluation.py#14.65"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation.run_evaluation_with_moatless_dataset_Evaluation.run_evaluation_with_moatless_dataset.return.self__run_evaluation_inst", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 217, "span_ids": ["Evaluation.run_evaluation_with_moatless_dataset"], "start_line": 140, "end_line": 175, "community": null}, "content": "class Evaluation:\n\n    def run_evaluation_with_moatless_dataset(\r\n        self,\r\n        resolved_by: Optional[int] = None,\r\n        use_test_subset: bool = False,\r\n        instance_ids: list[str] | None = None,\r\n    ):\n        file_path = os.path.join(\r\n            os.path.dirname(__file__), \"swebench_lite_all_evaluations.json\"\r\n        )\n        with open(file_path) as f:\n            instances = json.load(f)\n\n        instances = sorted(instances, key=lambda x: len(x[\"resolved_by\"]), reverse=True)\n\n        if use_test_subset:\n            instances = [\r\n                instance\r\n                for instance in instances\r\n                if instance[\"instance_id\"] in TEST_SUBSET\r\n            ]\n\n        if instance_ids:\n            instances = [\r\n                instance\r\n                for instance in instances\r\n                if instance[\"instance_id\"] in instance_ids\r\n            ]\n\n        if resolved_by:\n            instances = [\r\n                instance\r\n                for instance in instances\r\n                if len(instance[\"resolved_by\"]) >= resolved_by\r\n            ]\n\n        return self._run_evaluation(instances)", "kind": "Chunk", "id": "benchmark/evaluation.py#15.35"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation.run_swebench_evaluation_Evaluation.run_single_instance.return.to_result_instance_traje", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 174, "span_ids": ["Evaluation.run_single_instance", "Evaluation.run_swebench_evaluation"], "start_line": 177, "end_line": 202, "community": null}, "content": "class Evaluation:\n\n    def run_swebench_evaluation(\r\n        self,\r\n        dataset: str = \"princeton-nlp/SWE-bench_Lite\",\r\n        split=\"test\",\r\n        instance_ids: list[str] | None = None,\r\n    ):\n        instances = sorted_instances(dataset, split)\n\n        if instance_ids:\n            instances = [\r\n                instance\r\n                for instance in instances\r\n                if instance[\"instance_id\"] in instance_ids\r\n            ]\n\n        return self._run_evaluation_simple(instances)\n\n    def run_single_instance(\r\n        self,\r\n        instance_id: str,\r\n        dataset: str = \"princeton-nlp/SWE-bench_Lite\",\r\n        split=\"test\",\r\n    ) -> dict:\n        instance = load_instance(instance_id, dataset, split)\n        trajectory = self._evaluate_instance(instance)\n        return to_result(instance, trajectory, self.report)", "kind": "Chunk", "id": "benchmark/evaluation.py#16.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation._evaluate_instance_Evaluation._evaluate_instance.return.loop_trajectory", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 582, "span_ids": ["Evaluation._evaluate_instance"], "start_line": 204, "end_line": 289, "community": null}, "content": "class Evaluation:\n\n    def _evaluate_instance(self, instance: dict, retry: bool = False) -> Trajectory:\n        instance_id = instance[\"instance_id\"]\n        trajectory_path = os.path.join(self.trajectory_dir, f\"{instance_id}.json\")\n        prompt_log_dir = os.path.join(self.logs_dir, f\"{instance_id}\")\n        if not os.path.exists(prompt_log_dir):\n            os.makedirs(prompt_log_dir)\n\n        if os.path.exists(trajectory_path) and not retry:\r\n            # TODO: Retry when failed or not finished?\r\n            return Trajectory.load(trajectory_path)\n\n        repo_dir = setup_swebench_repo(instance)\n        persist_dir = os.path.join(self.index_store_dir, get_repo_dir_name(instance_id))\n        workspace = Workspace.from_dirs(\r\n            repo_path=repo_dir, index_dir=persist_dir, max_file_context_tokens=16000\r\n        )\n\n        problem_statement = instance[\"problem_statement\"]\n\n        previous_actions = []\n        if self.previous_trajectory_dir:\n            previous_trajectory_path = os.path.join(\r\n                self.previous_trajectory_dir, f\"{instance_id}.json\"\r\n            )\n            previous_trajectory = self.read_trajectory(previous_trajectory_path)\n            if previous_trajectory:\n                previous_actions = self.get_actions(previous_trajectory)\n\n        metadata = trace_metadata(\r\n            instance_id=instance_id,\r\n            session_id=self.evaluation_name,\r\n            trace_name=\"moatless\",\r\n        )\n\n        loop = AgenticLoop(\r\n            transition_rules=self.transitions,\r\n            workspace=workspace,\r\n            metadata=metadata,\r\n            mocked_actions=previous_actions,\r\n            reset_mocks_at_state=self.retry_state,\r\n            trajectory_path=trajectory_path,\r\n            prompt_log_dir=prompt_log_dir,\r\n            max_cost=self.max_cost,\r\n            max_transitions=self.max_transitions,\r\n            max_actions=self.max_expansions,\r\n            instructor_mode=self.instructor_mode,\r\n        )\n\n        info = {\r\n            \"evaluation_name\": self.evaluation_name,\r\n            \"instance_id\": instance[\"instance_id\"],\r\n        }\n\n        start_time = time.time()\n        try:\n            response = loop.run(problem_statement)\n            info[\"status\"] = response.status\n        except Exception:\n            info[\"error\"] = traceback.format_exc()\n            info[\"status\"] = \"error\"\n            logging.exception(f\"Error in evaluation of {instance['instance_id']} \")\n\n        info[\"duration\"] = time.time() - start_time\n        info[\"total_cost\"] = loop.total_cost()\n\n        if isinstance(workspace.file_repo, GitRepository):\n            diff = workspace.file_repo.diff()\n        else:\n            workspace.save()\n\n            output = subprocess.run(\r\n                [\"git\", \"diff\"],\r\n                capture_output=True,\r\n                text=True,\r\n                cwd=repo_dir,\r\n            )\n\n            if output:\n                diff = output.stdout\n            else:\n                diff = None\n\n        info[\"submission\"] = diff\n\n        loop.trajectory.save_info(info)\n        return loop.trajectory", "kind": "Chunk", "id": "benchmark/evaluation.py#17.85"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation._process_instance_Evaluation._process_instance.return.result_submission", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 166, "span_ids": ["Evaluation._process_instance"], "start_line": 291, "end_line": 312, "community": null}, "content": "class Evaluation:\n\n    def _process_instance(self, instance) -> Tuple[dict, str]:\n        trajectory = self._evaluate_instance(instance)\n\n        result = to_result(instance, trajectory, self.report)\n        submission = trajectory.info.get(\"submission\", \"\")\n\n        if self.markdown_report:\n            try:\n                md_report = generate_md_report(trajectory, instance)\n                if not os.path.exists(f\"{self.evaluation_dir}/reports\"):\n                    os.makedirs(f\"{self.evaluation_dir}/reports\")\n                with open(\r\n                    f\"{self.evaluation_dir}/reports/{instance['instance_id']}.md\",\r\n                    \"w\",\r\n                ) as file:\n                    file.write(md_report)\n            except Exception:\n                logging.exception(\r\n                    f\"Error in generating report for {instance['instance_id']} \"\r\n                )\n\n        return result, submission", "kind": "Chunk", "id": "benchmark/evaluation.py#18.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation._process_repo_group_Evaluation._run_evaluation.if_self_detailed_report_o.else_.self__run_evaluation_simp", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 336, "span_ids": ["Evaluation._process_repo_group", "Evaluation._run_evaluation"], "start_line": 314, "end_line": 359, "community": null}, "content": "class Evaluation:\n\n    def _process_repo_group(self, repo, instances):\n        results = []\n        transition_results = []\n        for i, instance in enumerate(instances):\n            logger.info(\r\n                f\"Processing {instance['instance_id']} ({i+1}/{len(instances)} in {repo})\"\r\n            )\n\n            trajectory = self._evaluate_instance(instance)\n            if not trajectory:\n                return None, None\n\n            result = to_result(instance, trajectory, report=self.report)\n            results.append(result)\n\n            try:\n                md_report = generate_md_report(trajectory, instance)\n                if not os.path.exists(f\"{self.evaluation_dir}/reports\"):\n                    os.makedirs(f\"{self.evaluation_dir}/reports\")\n                with open(\r\n                    f\"{self.evaluation_dir}/reports/{instance['instance_id']}.md\",\r\n                    \"w\",\r\n                ) as file:\n                    file.write(md_report)\n            except Exception:\n                logging.exception(\r\n                    f\"Error in generating report for {instance['instance_id']} \"\r\n                )\n\n            prediction = {\r\n                \"model_name_or_path\": self.evaluation_name,\r\n                \"instance_id\": result[\"instance_id\"],\r\n                \"model_patch\": trajectory[\"info\"].get(\"submission\", \"\"),\r\n            }\n\n            with open(self.predictions_path, \"a\") as file:\n                json_string = json.dumps(prediction)\n                file.write(json_string + \"\\n\")\n\n        return results, transition_results\n\n    def _run_evaluation(self, instances: list[dict]):\n        if self.detailed_report or self.num_workers > 1:\n            self._run_evaluation_detailed(instances)\n        else:\n            self._run_evaluation_simple(instances)", "kind": "Chunk", "id": "benchmark/evaluation.py#19.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation._run_evaluation_detailed_Evaluation._run_evaluation_detailed.with_concurrent_futures_P.for_future_in_pbar_.if_transition_results_.df_search_to_csv_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 459, "span_ids": ["Evaluation._run_evaluation_detailed"], "start_line": 361, "end_line": 428, "community": null}, "content": "class Evaluation:\n\n    def _run_evaluation_detailed(self, instances: list[dict]):\n        error = 0\n\n        with open(self.predictions_path, \"w\") as file:\n            file.write(\"\")\n\n        repo_groups = defaultdict(list)\n        for instance in instances:\n            repo_groups[instance.get(\"repo\")].append(instance)\n\n        results = []\n        transition_results = []\n\n        logger.info(f\"Processing {len(instances)} instances with {len(repo_groups)} repos with {self.num_workers} workers\")\n\n        with concurrent.futures.ProcessPoolExecutor(\r\n            max_workers=self.num_workers\r\n        ) as executor:\n            futures = []\n            for repo, group in repo_groups.items():\n                futures.append(executor.submit(self._process_repo_group, repo, group))\n\n            pbar = tqdm(concurrent.futures.as_completed(futures), total=len(futures))\n\n            for future in pbar:\n                try:\n                    group_results, group_transition_results = future.result()\n                    if not group_results:\n                        logger.warning(\"Error in processing repo group\")\n                        error += 1\n                        continue\n                except Exception:\n                    error += 1\n                    logger.exception(\"Error in processing repo group\")\n                    continue\n\n                results.extend(group_results)\n                transition_results.extend(group_transition_results)\n\n                df = pd.DataFrame(results)\n                df.to_csv(\r\n                    f\"{self.evaluation_dir}/result.csv\",\r\n                    index=False,\r\n                    sep=\",\",\r\n                    decimal=\",\",\r\n                    quoting=1,\r\n                )\n\n                avg_duration = df[\"duration\"].mean()\n                avg_cost = df[\"total_cost\"].mean()\n                total_identified = df[\"identified\"].sum()\n                total_processed = len(df)\n\n                logger.info(f\"Average duration: {avg_duration:.2f} seconds\")\n                logger.info(f\"Average cost: ${avg_cost:.4f}\")\n                logger.info(f\"Total identified: {total_identified}\")\n                logger.info(f\"Total processed: {total_processed}\")\n                logger.info(f\"Error count: {error}\")\n\n                if transition_results:\n                    df_search = pd.DataFrame(transition_results)\n                    df_search.to_csv(\r\n                        f\"{self.evaluation_dir}/transition_results.csv\",\r\n                        index=False,\r\n                        sep=\",\",\r\n                        decimal=\",\",\r\n                        quoting=1,\r\n                    )", "kind": "Chunk", "id": "benchmark/evaluation.py#20.67"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py_Evaluation._run_evaluation_simple_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\evaluation.py", "file_name": "evaluation.py", "file_type": "text/x-python", "category": "test", "tokens": 555, "span_ids": ["Evaluation.read_trajectory", "Evaluation._run_evaluation_simple", "Evaluation.get_actions", "create_evaluation_name"], "start_line": 430, "end_line": 518, "community": null}, "content": "class Evaluation:\n\n    def _run_evaluation_simple(self, instances: list[dict]):\n        with open(self.predictions_path, \"w\") as file:\n            file.write(\"\")\n\n        count = 0\n        identified = 0\n        generated = 0\n        error = 0\n\n        sum_duration = 0\n        sum_total_cost = 0\n\n        stats = {}\n        pbar = tqdm(instances)\n        for instance in pbar:\n            trajectory = self._evaluate_instance(instance)\n            if not trajectory:\n                continue\n\n            result, transition_result = to_result(instance, trajectory, report=self.report)\n\n            sum_duration += result[\"duration\"]\n            sum_total_cost += result[\"total_cost\"]\n\n            if result[\"status\"] == \"error\":\n                error += 1\n\n            if result[\"status\"] in [\"generated\", \"failed\", \"resolved\"]:\n                generated += 1\n\n            if result[\"identified\"] is not None:\n                identified += 1\n\n            count += 1\n\n            if sum_duration > 0:\n                stats[\"avg_duration\"] = sum_duration / count\n\n            if sum_total_cost > 0:\n                stats[\"avg_cost\"] = sum_total_cost / count\n                stats[\"total_cost\"] = sum_total_cost\n\n            if identified > 0:\n                success_rate = (identified / count) * 100\n                stats[\"identified\"] = f\"{success_rate:.2f}%\"\n\n            if generated > 0:\n                success_rate = (generated / count) * 100\n                stats[\"generated\"] = f\"{success_rate:.2f}%\"\n\n            stats[\"error\"] = error\n\n            pbar.set_postfix(stats)\n\n            prediction = {\r\n                \"model_name_or_path\": self.evaluation_name,\r\n                \"instance_id\": instance[\"instance_id\"],\r\n                \"model_patch\": trajectory[\"info\"].get(\"submission\", \"\"),\r\n            }\n\n            with open(self.predictions_path, \"a\") as file:\n                json_string = json.dumps(prediction)\n                file.write(json_string + \"\\n\")\n\n\n    def read_trajectory(self, path) -> Optional[dict]:\n        if os.path.exists(path):\n            with open(path) as f:\n                return json.load(f)\n        else:\n            return None\n\n    def get_actions(self, trajectory: dict):\n        actions = []\n        for transition in trajectory[\"transitions\"]:\n            for action in transition[\"actions\"]:\n                actions.append(action)\n        return actions\n\n\ndef create_evaluation_name(\r\n    name: str,\r\n    model: str,\r\n):\n    date_str = datetime.now(tz=timezone.utc).strftime(\"%Y%m%d\")\n    model_name = model.split(\"/\")[-1]\n    return f\"{date_str}_{name}_{model_name}\"", "kind": "Chunk", "id": "benchmark/evaluation.py#21.88"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py_json_logger.logging_getLogger___name_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py", "file_name": "report_v1.py", "file_type": "text/x-python", "category": "test", "tokens": 75, "span_ids": ["imports"], "start_line": 1, "end_line": 10, "community": null}, "content": "import json\nimport logging\nimport os\n\nfrom moatless import FileRepository\nfrom moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo\nfrom moatless.benchmark.utils import get_missing_files\nfrom moatless.file_context import FileContext\n\nlogger = logging.getLogger(__name__)", "kind": "Chunk", "id": "benchmark/report_v1.py#22.9"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py_to_result_to_result.return.result_transitions", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py", "file_name": "report_v1.py", "file_type": "text/x-python", "category": "test", "tokens": 2140, "span_ids": ["to_result"], "start_line": 13, "end_line": 320, "community": null}, "content": "def to_result(instance: dict, trajectory: dict, report: dict | None) -> tuple[dict, list]:\n    \"\"\"\r\n    Generate reports from saved trajectories with version 1 format.\r\n    \"\"\"\n\n    info = trajectory[\"info\"]\n\n    resolved = report and info.get(\"instance_id\", \"\") in report[\"resolved\"]\n\n    try:\n        transitions = []\n        result = {\r\n            \"instance_id\": instance[\"instance_id\"],\r\n            \"duration\": info.get(\"duration\", 0),\r\n            \"total_cost\": info.get(\"total_cost\", 0),\r\n            \"resolved_by\": (len(instance.get(\"resolved_by\", []))),\r\n            \"status\": None,\r\n            \"transitions\": len(trajectory[\"transitions\"]),\r\n            \"edited\": False,\r\n            \"planned\": False,\r\n            \"identified\": None,\r\n            \"expected_identified\": None,\r\n            \"alt_identified\": None,\r\n            \"found_in_search\": None,\r\n            \"file_identified\": None,\r\n            \"file_in_search\": None,\r\n            \"edit_retries\": 0,\r\n            \"has_diff\": False,\r\n            \"lint_codes\": None,\r\n            \"review\": False,\r\n            \"p_query\": 0,\r\n            \"p_file\": 0,\r\n            \"p_code\": 0,\r\n            \"p_class\": 0,\r\n            \"p_function\": 0,\r\n            \"lints\": \"\",\r\n        }\n\n        lint_codes = set()\n        search_results_spans = {}\n        identified_spans = {}\n        planned_spans = {}\n        edited_spans = {}\n\n        id_iterations = 0\n        search_iterations = 0\n\n        if instance.get(\"expected_spans\"):\n            for transition in trajectory[\"transitions\"]:\n                if transition[\"name\"] not in result:\n                    result[transition[\"name\"]] = 0\n                    result[f\"{transition['name']}_cost\"] = 0\n\n                result[transition[\"name\"]] += 1\n\n                expected_span_str = \"\"\n                for file_path, span_ids in instance[\"expected_spans\"].items():\n                    expected_span_str += f\"{file_path}: {span_ids} \"\n\n                transition_result = {\r\n                    \"instance_id\": instance[\"instance_id\"],\r\n                    \"resolved\": resolved,\r\n                    \"name\": transition[\"name\"],\r\n                    \"cost\": 0,\r\n                    \"expected_spans\": expected_span_str,\r\n                    \"actual_spans\": \"\",\r\n                }\n\n                if not transition[\"actions\"]:\n                    continue\n\n                for traj_action in transition[\"actions\"]:\n                    result[f\"{transition['name']}_cost\"] += traj_action.get(\r\n                        \"completion_cost\", 0\r\n                    )\n                    transition_result[\"cost\"] += traj_action.get(\r\n                        \"completion_cost\", 0\r\n                    )\n\n                if transition[\"name\"] == \"SearchCode\":\n                    search_iterations += 1\n\n                    action = transition[\"actions\"][-1]\n\n                    if \"search_requests\" in action[\"action\"]:\n                        for search_request in action[\"action\"][\"search_requests\"]:\n                            if search_request.get(\"query\"):\n                                result[\"p_query\"] += 1\n\n                            if search_request.get(\"file_pattern\"):\n                                result[\"p_file\"] += 1\n\n                            if search_request.get(\"code_snippet\"):\n                                result[\"p_code\"] += 1\n\n                            if search_request.get(\r\n                                    \"class_name\"\r\n                            ) or search_request.get(\"class_names\"):\n                                result[\"p_class\"] += 1\n\n                            if search_request.get(\r\n                                    \"function_name\"\r\n                            ) or search_request.get(\"function_names\"):\n                                result[\"p_function\"] += 1\n\n                    if \"output\" in action and action.get(\"output\"):\n                        output = action[\"output\"]\n\n                        if \"query\" in output:\n                            result[\"p_query\"] += 1\n\n                        if \"file_pattern\" in output:\n                            result[\"p_file\"] += 1\n\n                        if \"code_snippet\" in output:\n                            result[\"p_code\"] += 1\n\n                        if \"class_name\" in output or \"class_names\" in output:\n                            result[\"p_class\"] += 1\n\n                        if \"function_name\" in output or \"function_names\" in output:\n                            result[\"p_function\"] += 1\n\n                        if output.get(\"ranked_spans\"):\n                            for ranked_span in output[\"ranked_spans\"]:\n                                if (\r\n                                        ranked_span[\"file_path\"]\r\n                                        not in search_results_spans\r\n                                ):\n                                    search_results_spans[\r\n                                        ranked_span[\"file_path\"]\r\n                                    ] = []\n                                search_results_spans[\r\n                                    ranked_span[\"file_path\"]\r\n                                ].append(ranked_span[\"span_id\"])\n\n                            if not result[\"found_in_search\"] and (\r\n                                    found_in_expected_spans(\r\n                                        instance, search_results_spans\r\n                                    )\r\n                                    or found_in_alternative_spans(\r\n                                instance, search_results_spans\r\n                            )\r\n                            ):\n                                result[\"found_in_search\"] = search_iterations\n\n                            if not result[\"file_in_search\"]:\n                                missing_files = get_missing_files(\r\n                                    instance[\"expected_spans\"],\r\n                                    search_results_spans,\r\n                                )\n                                if not missing_files:\n                                    result[\"file_in_search\"] = search_iterations\n\n                if transition[\"name\"] == \"IdentifyCode\":\n                    id_iterations += 1\n\n                    action = transition[\"actions\"][-1]\n                    if action.get(\"action\"):\n                        identified_str = \"\"\n                        if action[\"action\"].get(\"identified_spans\"):\n                            for span in action[\"action\"][\"identified_spans\"]:\n                                identified_str += (\r\n                                    f\"{span['file_path']}: {span['span_ids']} \"\r\n                                )\n                                if span[\"file_path\"] not in identified_spans:\n                                    identified_spans[span[\"file_path\"]] = []\n\n                                transition_result[\"actual_spans\"] += (\r\n                                    f\"{span['file_path']}: {','.join(span['span_ids'])} \"\r\n                                )\n                                for span_id in span[\"span_ids\"]:\n                                    identified_spans[span[\"file_path\"]].append(\r\n                                        span_id\r\n                                    )\n                        result[\"identified_spans\"] = identified_str\n\n                    if not result[\"file_identified\"]:\n                        missing_files = get_missing_files(\r\n                            instance[\"expected_spans\"],\r\n                            identified_spans,\r\n                        )\n                        if not missing_files:\n                            result[\"file_identified\"] = id_iterations\n\n                    if result[\r\n                        \"expected_identified\"\r\n                    ] is None and found_in_expected_spans(\r\n                        instance, identified_spans\r\n                    ):\n                        result[\"expected_identified\"] = id_iterations\n\n                    if result[\r\n                        \"alt_identified\"\r\n                    ] is None and found_in_alternative_spans(\r\n                        instance, identified_spans\r\n                    ):\n                        result[\"alt_identified\"] = id_iterations\n\n                    if result.get(\"alt_identified\") or result.get(\r\n                            \"expected_identified\"\r\n                    ):\n                        result[\"identified\"] = min(\r\n                            result.get(\"alt_identified\") or 1000,\r\n                            result.get(\"expected_identified\") or 1000,\r\n                        )\n\n                if transition[\"name\"] == \"PlanToCode\":\n                    action = transition[\"actions\"][-1][\"action\"]\n                    if action.get(\"action\") == \"review\":\n                        result[\"review\"] = True\n\n                    if \"file_path\" in action:\n                        if \"span_id\" not in action:\n                            logger.warning(\r\n                                f\"Span id missing in planning action in {instance['instance_id']}\"\r\n                            )\n                        else:\n                            file_path = action[\"file_path\"]\n                            if file_path not in planned_spans:\n                                planned_spans[file_path] = []\n                            planned_spans[file_path].append(action[\"span_id\"])\n                            transition_result[\"actual_spans\"] = (\r\n                                f\"{file_path}: {action['span_id']} \"\r\n                            )\n\n                    if not result.get(\"planned\") and (\r\n                            found_in_expected_spans(\r\n                                instance,\r\n                                planned_spans,\r\n                            )\r\n                            or found_in_alternative_spans(instance, planned_spans)\r\n                    ):\n                        result[\"planned\"] = True\n\n                if transition[\"name\"] == \"EditCode\":\n                    result[\"edit_retries\"] = len(transition[\"actions\"]) - 1\n\n                    action = transition[\"actions\"][-1]\n                    output = action.get(\"output\", {})\n\n                    if output:\n                        edited = output.get(\"diff\")\n\n                        if edited:\n                            result[\"has_diff\"] = True\n\n                        for lint in output.get(\"verification_errors\", []):\n                            lint_codes.add(lint[\"code\"])\n\n                        if edited and \"file_path\" in transition[\"state\"]:\n                            file_path = transition[\"state\"][\"file_path\"]\n                            if file_path not in edited_spans:\n                                edited_spans[file_path] = []\n                            edited_spans[file_path].append(\r\n                                transition[\"state\"][\"span_id\"]\r\n                            )\n                            transition_result[\"actual_spans\"] = (\r\n                                f\"{file_path}: {transition['state']['span_id']} \"\r\n                            )\n\n                        if not result.get(\"edited\") and (\r\n                                found_in_expected_spans(\r\n                                    instance,\r\n                                    edited_spans,\r\n                                )\r\n                                or found_in_alternative_spans(instance, edited_spans)\r\n                        ):\n                            result[\"edited\"] = True\n\n                transitions.append(transition_result)\n\n            if result.get(\"alt_identified\") or result.get(\"expected_identified\"):\n                result[\"identified\"] = min(\r\n                    result.get(\"alt_identified\") or 1000,\r\n                    result.get(\"expected_identified\") or 1000,\r\n                )\n\n            result[\"expected_files\"] = list(instance[\"expected_spans\"].keys())\n            result[\"edited_files\"] = list(edited_spans.keys())\n            result[\"identified_spans\"] = sum(\r\n                [len(v) for v in identified_spans.values()]\r\n            )\n\n        result[\"lints\"] = \",\".join(lint_codes)\n\n        if report and info.get(\"instance_id\", \"\") in report[\"resolved\"]:\n            result[\"status\"] = \"resolved\"\n        elif result[\"edited\"]:\n            result[\"status\"] = \"edited\"\n        elif result[\"identified\"]:\n            result[\"status\"] = \"identified\"\n        elif result[\"found_in_search\"]:\n            result[\"status\"] = \"found_in_search\"\n        elif result[\"file_identified\"]:\n            result[\"status\"] = \"file_identified\"\n        else:\n            result[\"status\"] = \"\"\n\n        if \"error\" in info:\n            result[\"error\"] = info[\"error\"].split(\"\\n\")[0]\n        else:\n            result[\"error\"] = \"\"\n\n    except Exception as e:\n        raise e\n\n    return result, transitions", "kind": "Chunk", "id": "benchmark/report_v1.py#23.307"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py_generate_md_report_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v1.py", "file_name": "report_v1.py", "file_type": "text/x-python", "category": "test", "tokens": 802, "span_ids": ["generate_md_report"], "start_line": 323, "end_line": 419, "community": null}, "content": "def generate_md_report(trajectory: dict, instance: dict):\n    info = trajectory[\"info\"]\n    markdown = f\"# {instance['instance_id']}\\n\"\n\n    markdown += \"\\n## Problem statement\\n\"\n    markdown += f\"```\\n{instance['problem_statement']}\\n```\\n\"\n\n    if \"error\" in trajectory[\"info\"]:\n        markdown += \"\\n## Error\\n\"\n        markdown += f\"```\\n{trajectory['info']['error']}\\n```\\n\"\n    else:\n        markdown += \"\\n## Prediction\\n\"\n        markdown += f\"```diff\\n{info['submission']}\\n```\\n\"\n\n    markdown += \"\\n## Golden patch\\n\"\n    markdown += f\"```diff\\n{instance['golden_patch']}\\n```\\n\"\n\n    markdown += \"\\n## Trajectory\\n\"\n\n    repo_dir = setup_swebench_repo(instance)\n    file_repo = FileRepository(repo_dir)\n\n    for j, step in enumerate(trajectory[\"transitions\"]):\n        for i, traj_action in enumerate(step[\"actions\"]):\n            state_name = step['state']\n            markdown += f\"### {j+1} {state_name} ({i+1})\\n\\n\"\n\n            if not traj_action.get(\"action\"):\n                continue\n            action = traj_action[\"action\"]\n\n            if state_name == \"PlanToCode\":\n                if action.get(\"scratch_pad\"):\n                    markdown += \"*\" + action[\"scratch_pad\"] + \"*\"\n\n                if action.get(\"instructions\"):\n                    markdown += f\"\\n\\n * {action['instructions']}\"\n\n                if action.get(\"file_path\"):\n                    markdown += f\"\\n * {action['file_path']}\"\n\n                if action.get(\"span_id\"):\n                    markdown += f\"\\n * {action['span_id']}\"\n\n                if action.get(\"file_path\") and action.get(\"span_id\"):\n                    markdown += \"\\n\\n#### File context \\n\\n\"\n                    try:\n                        file_context = FileContext(file_repo)\n                        file_context.add_span_to_context(\r\n                            action.get(\"file_path\"),\r\n                            action.get(\"span_id\"),\r\n                        )\n                        markdown += file_context.create_prompt(\r\n                            show_outcommented_code=True\r\n                        )\n                    except Exception as e:\n                        logger.error(e)\n\n            if state_name == \"EditCode\":\n                markdown += \"#### LLM Response\\n\\n\"\n                markdown += f\"```\\n{action.get('content', '')}\\n```\\n\"\n\n                output = traj_action.get(\"output\")\n                if output:\n                    if output.get(\"diff\"):\n                        markdown += \"#### Diff\\n\\n\"\n                        markdown += f\"```diff\\n{output['diff']}\\n```\\n\"\n\n                    if output.get(\"errors\"):\n                        markdown += \"#### Errors\\n\\n\"\n                        markdown += f\"{output['errors']}\\n\\n\"\n\n                    if output.get(\"message\"):\n                        markdown += \"#### Message\\n\\n\"\n                        markdown += f\"{output['message']}\\n\\n\"\n\n            if state_name == \"ClarifyCodeChange\":\n                if action.get(\"thoughts\"):\n                    markdown += \"*\" + action[\"thoughts\"] + \"*\"\n\n                if action.get(\"output\") and action.get(\"output\").get(\"start_line\"):\n                    markdown += f\"\\n* Start Line: {action['output']['start_line']}\\n\"\n                    markdown += f\"\\n* End Line: {action['output']['end_line']}\\n\"\n\n            if state_name == \"Finished\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n            if state_name == \"Rejected\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n    markdown += \"## Alternative patches\\n\"\n    for alternative in instance[\"resolved_by\"]:\n        markdown += f\"### {alternative['name']}\\n\"\n        markdown += f\"```diff\\n{alternative['patch']}\\n```\\n\"\n\n    return markdown", "kind": "Chunk", "id": "benchmark/report_v1.py#24.96"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py_logging_logger_2.logging_getLogger___name_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py", "file_name": "report_v2.py", "file_type": "text/x-python", "category": "test", "tokens": 271, "span_ids": ["imports"], "start_line": 1, "end_line": 32, "community": null}, "content": "import logging\n\nfrom moatless import FileRepository\nfrom moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo\nfrom moatless.benchmark.utils import get_missing_files\nfrom moatless.edit.plan import ApplyChange\nfrom moatless.file_context import FileContext\nfrom moatless.find.search import SearchRequest\n\nlogger = logging.getLogger(__name__)\n\nimport logging\n\nfrom moatless import FileRepository\nfrom moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo\nfrom moatless.benchmark.utils import get_missing_files\nfrom moatless.file_context import FileContext\n\nlogger = logging.getLogger(__name__)\n\nimport logging\nfrom typing import Dict, List, Tuple, Optional\n\nfrom moatless import FileRepository\nfrom moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo\nfrom moatless.benchmark.utils import get_missing_files\nfrom moatless.file_context import FileContext\nfrom moatless.trajectory import Trajectory\nfrom moatless.types import ActionTransaction, Usage, Content\nfrom moatless.state import AgenticState\n\nlogger = logging.getLogger(__name__)", "kind": "Chunk", "id": "benchmark/report_v2.py#25.31"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py_to_result_to_result.return.result", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py", "file_name": "report_v2.py", "file_type": "text/x-python", "category": "test", "tokens": 1759, "span_ids": ["to_result"], "start_line": 35, "end_line": 264, "community": null}, "content": "def to_result(instance: Dict, trajectory: Trajectory, report: Optional[Dict] = None) -> Dict:\n    info = trajectory._info\n\n    if report and \"resolved_ids\" in report and instance[\"instance_id\"] in report[\"resolved_ids\"]:\n        result_status = \"resolved\"\n    else:\n        result_status = info.get(\"status\")\n\n    resolved = result_status == \"resolved\"\n\n    try:\n        result = {\r\n            \"instance_id\": instance[\"instance_id\"],\r\n            \"duration\": info.get(\"duration\", 0),\r\n            \"total_cost\": info.get(\"total_cost\", 0),\r\n            \"resolved_by\": (len(instance.get(\"resolved_by\", []))),\r\n            \"status\": None,\r\n            \"result_status\": result_status,\r\n            \"transitions\": len(trajectory.transitions),\r\n            \"edited\": False,\r\n            \"planned\": False,\r\n            \"identified\": None,\r\n            \"expected_identified\": None,\r\n            \"alt_identified\": None,\r\n            \"found_in_search\": None,\r\n            \"file_identified\": None,\r\n            \"file_in_search\": None,\r\n            \"edit_retries\": 0,\r\n            \"has_diff\": False,\r\n            \"lint_codes\": None,\r\n            \"review\": False,\r\n            \"p_query\": 0,\r\n            \"p_file\": 0,\r\n            \"p_code\": 0,\r\n            \"p_class\": 0,\r\n            \"p_function\": 0,\r\n            \"lints\": \"\",\r\n        }\n\n        lint_codes = set()\n        search_results_spans: Dict[str, List[str]] = {}\n        identified_spans: Dict[str, List[str]] = {}\n        planned_spans: Dict[str, List[str]] = {}\n        edited_spans: Dict[str, List[str]] = {}\n\n        id_iterations = 0\n        search_iterations = 0\n\n        selected_transition_ids = []\n        current_state = trajectory.get_current_state()\n        while current_state:\n            selected_transition_ids.append(current_state.id)\n            current_state = current_state.previous_state\n\n        logger.info(f\"Selected transitions: {selected_transition_ids}\")\n\n        if instance.get(\"expected_spans\"):\n            for transition in trajectory.transitions:\n                if selected_transition_ids and transition.id not in selected_transition_ids:\n                    continue\n\n                state: AgenticState = transition.state\n                state_name = state.name\n\n                if state_name not in result:\n                    result[state_name] = 0\n                    result[f\"{state_name}_cost\"] = 0\n\n                result[state_name] += 1\n\n                expected_span_str = \"\"\n                for file_path, span_ids in instance[\"expected_spans\"].items():\n                    expected_span_str += f\"{file_path}: {span_ids} \"\n\n                if not state._actions:\n                    continue\n\n                for action in state._actions:\n                    result[f\"{state_name}_cost\"] += action.usage.completion_cost if action.usage else 0\n\n                if state_name == \"SearchCode\":\n                    search_iterations += 1\n\n                    action = state._actions[-1]\n\n                    if isinstance(action.request, SearchRequest):\n                        for search_request in action.request.search_requests:\n                            if search_request.query:\n                                result[\"p_query\"] += 1\n                            if search_request.file_pattern:\n                                result[\"p_file\"] += 1\n                            if search_request.code_snippet:\n                                result[\"p_code\"] += 1\n                            if search_request.class_name or search_request.class_names:\n                                result[\"p_class\"] += 1\n                            if search_request.function_name or search_request.function_names:\n                                result[\"p_function\"] += 1\n\n                if state_name == \"IdentifyCode\":\n                    id_iterations += 1\n\n                    if state.ranked_spans:\n                        for ranked_span in state.ranked_spans:\n                            if ranked_span.file_path not in search_results_spans:\n                                search_results_spans[ranked_span.file_path] = []\n                            search_results_spans[ranked_span.file_path].append(ranked_span.span_id)\n\n                        if not result[\"found_in_search\"] and (\r\n                                found_in_expected_spans(instance, search_results_spans)\r\n                                or found_in_alternative_spans(instance, search_results_spans)\r\n                        ):\n                            result[\"found_in_search\"] = search_iterations\n\n                        if not result[\"file_in_search\"]:\n                            missing_files = get_missing_files(\r\n                                instance[\"expected_spans\"],\r\n                                search_results_spans,\r\n                            )\n                            if not missing_files:\n                                result[\"file_in_search\"] = search_iterations\n\n                    if state._actions:\n                        action = state._actions[-1]\n                        identified_str = \"\"\n                        if action.request.identified_spans:\n                            for span in action.request.identified_spans:\n                                identified_str += f\"{span.file_path}: {span.span_ids} \"\n                                if span.file_path not in identified_spans:\n                                    identified_spans[span.file_path] = []\n\n                                for span_id in span.span_ids:\n                                    identified_spans[span.file_path].append(span_id)\n                        result[\"identified_spans\"] = identified_str\n\n                    if not result[\"file_identified\"]:\n                        missing_files = get_missing_files(\r\n                            instance[\"expected_spans\"],\r\n                            identified_spans,\r\n                        )\n                        if not missing_files:\n                            result[\"file_identified\"] = id_iterations\n\n                    if result[\"expected_identified\"] is None and found_in_expected_spans(instance, identified_spans):\n                        result[\"expected_identified\"] = id_iterations\n\n                    if result[\"alt_identified\"] is None and found_in_alternative_spans(instance, identified_spans):\n                        result[\"alt_identified\"] = id_iterations\n\n                    if result.get(\"alt_identified\") or result.get(\"expected_identified\"):\n                        result[\"identified\"] = min(\r\n                            result.get(\"alt_identified\") or 1000,\r\n                            result.get(\"expected_identified\") or 1000,\r\n                        )\n\n                if state_name == \"PlanToCode\":\n                    action = state._actions[-1]\n\n                    if action.request.action == \"review\":\n                        result[\"review\"] = True\n\n                    if action.request.file_path:\n                        file_path = action.request.file_path\n                        if file_path not in planned_spans:\n                            planned_spans[file_path] = []\n                        planned_spans[file_path].append(action.request.span_id)\n\n                    if not result.get(\"planned\") and (\r\n                            found_in_expected_spans(instance, planned_spans)\r\n                            or found_in_alternative_spans(instance, planned_spans)\r\n                    ):\n                        result[\"planned\"] = True\n\n                if state_name == \"EditCode\":\n                    result[\"edit_retries\"] = len(state._actions) - 1\n\n                    action = state._actions[-1]\n                    edited = action.response and action.response.trigger == \"finish\"\n\n                    if edited and hasattr(state, 'file_path'):\n                        file_path = state.file_path\n                        if file_path not in edited_spans:\n                            edited_spans[file_path] = []\n                        edited_spans[file_path].append(state.span_id)\n\n                    if not result.get(\"edited\") and (\r\n                            found_in_expected_spans(instance, edited_spans)\r\n                            or found_in_alternative_spans(instance, edited_spans)\r\n                    ):\n                        result[\"edited\"] = True\n\n                    if action.response and action.response.output:\n                        output = action.response.output\n                        if edited:\n                            result[\"has_diff\"] = True\n\n                        for lint in output.get(\"verification_errors\", []):\n                            lint_codes.add(lint[\"code\"])\n\n            if result.get(\"alt_identified\") or result.get(\"expected_identified\"):\n                result[\"identified\"] = min(\r\n                    result.get(\"alt_identified\") or 1000,\r\n                    result.get(\"expected_identified\") or 1000,\r\n                )\n\n            result[\"expected_files\"] = list(instance[\"expected_spans\"].keys())\n            result[\"edited_files\"] = list(edited_spans.keys())\n            result[\"identified_spans\"] = sum(len(v) for v in identified_spans.values())\n\n        result[\"lints\"] = \",\".join(lint_codes)\n\n        if result[\"edited\"]:\n            result[\"status\"] = \"edited\"\n        elif result[\"identified\"]:\n            result[\"status\"] = \"identified\"\n        elif result[\"found_in_search\"]:\n            result[\"status\"] = \"found_in_search\"\n        elif result[\"file_identified\"]:\n            result[\"status\"] = \"file_identified\"\n        else:\n            result[\"status\"] = \"\"\n\n        if \"error\" in info:\n            result[\"error\"] = info[\"error\"].split(\"\\n\")[0]\n        else:\n            result[\"error\"] = \"\"\n\n    except Exception as e:\n        raise e\n\n    return result", "kind": "Chunk", "id": "benchmark/report_v2.py#26.229"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py_generate_md_report_generate_md_report.return.markdown", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py", "file_name": "report_v2.py", "file_type": "text/x-python", "category": "test", "tokens": 739, "span_ids": ["generate_md_report"], "start_line": 266, "end_line": 353, "community": null}, "content": "def generate_md_report(trajectory: Trajectory, instance: Dict) -> str:\n    info = trajectory._info\n    markdown = f\"# {instance['instance_id']}\\n\"\n\n    markdown += \"\\n## Problem statement\\n\"\n    markdown += f\"```\\n{instance['problem_statement']}\\n```\\n\"\n\n    if \"error\" in trajectory._info:\n        markdown += \"\\n## Error\\n\"\n        markdown += f\"```\\n{trajectory._info['error']}\\n```\\n\"\n    else:\n        markdown += \"\\n## Prediction\\n\"\n        markdown += f\"```diff\\n{info['submission']}\\n```\\n\"\n\n    markdown += \"\\n## Golden patch\\n\"\n    markdown += f\"```diff\\n{instance['golden_patch']}\\n```\\n\"\n\n    markdown += \"\\n## Trajectory\\n\"\n\n    repo_dir = setup_swebench_repo(instance)\n    file_repo = FileRepository(repo_dir)\n\n    for j, transition in enumerate(trajectory.transitions):\n        state = transition.state\n        for i, action in enumerate(state._actions):\n            markdown += f\"### {j+1} {state.name} ({i+1})\\n\\n\"\n\n            if state.name == \"PlanToCode\":\n                if action.request.file_path:\n                    if action.request.instructions:\n                        markdown += f\"\\n\\n * {action.request.instructions}\"\n                    markdown += f\"\\n * {action.request.file_path}\"\n                    markdown += f\"\\n * {action.request.span_id}\"\n\n                    markdown += \"\\n\\n#### File context \\n\\n\"\n                    try:\n                        file_context = FileContext(file_repo)\n                        file_context.add_span_to_context(\r\n                            action.request.file_path,\r\n                            action.request.span_id,\r\n                        )\n                        markdown += file_context.create_prompt(\r\n                            show_outcommented_code=True\r\n                        )\n                    except Exception as e:\n                        logger.error(e)\n\n            if state.name == \"EditCode\":\n                markdown += \"#### LLM Response\\n\\n\"\n                markdown += f\"```\\n{action.request.content if isinstance(action.request, Content) else ''}\\n```\\n\"\n\n                if action.response and action.response.output:\n                    output = action.response.output\n                    if output.get(\"diff\"):\n                        markdown += \"#### Diff\\n\\n\"\n                        markdown += f\"```diff\\n{output['diff']}\\n```\\n\"\n\n                    if output.get(\"errors\"):\n                        markdown += \"#### Errors\\n\\n\"\n                        markdown += f\"{output['errors']}\\n\\n\"\n\n                    if output.get(\"message\"):\n                        markdown += \"#### Message\\n\\n\"\n                        markdown += f\"{output['message']}\\n\\n\"\n\n            if state.name == \"ClarifyCodeChange\":\n\n                if action.request.scratch_pad:\n                    markdown += f\"*{action.request.scratch_pad}*\"\n\n                if action.response and action.response.output:\n                    output = action.response.output\n                    if output.get(\"start_line\"):\n                        markdown += f\"\\n* Start Line: {output['start_line']}\\n\"\n                        markdown += f\"\\n* End Line: {output['end_line']}\\n\"\n\n            if state.name == \"Finished\":\n                markdown += f\"*{action.request.thoughts}*\\n\"\n\n            if state.name == \"Rejected\":\n                markdown += f\"*{action.request.thoughts}*\\n\"\n\n    markdown += \"## Alternative patches\\n\"\n    for alternative in instance[\"resolved_by\"]:\n        markdown += f\"### {alternative['name']}\\n\"\n        markdown += f\"```diff\\n{alternative['patch']}\\n```\\n\"\n\n    return markdown", "kind": "Chunk", "id": "benchmark/report_v2.py#27.87"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py_generate_md_report_2_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\report_v2.py", "file_name": "report_v2.py", "file_type": "text/x-python", "category": "test", "tokens": 802, "span_ids": ["generate_md_report_2"], "start_line": 354, "end_line": 450, "community": null}, "content": "def generate_md_report(trajectory: dict, instance: dict):\n    info = trajectory[\"info\"]\n    markdown = f\"# {instance['instance_id']}\\n\"\n\n    markdown += \"\\n## Problem statement\\n\"\n    markdown += f\"```\\n{instance['problem_statement']}\\n```\\n\"\n\n    if \"error\" in trajectory[\"info\"]:\n        markdown += \"\\n## Error\\n\"\n        markdown += f\"```\\n{trajectory['info']['error']}\\n```\\n\"\n    else:\n        markdown += \"\\n## Prediction\\n\"\n        markdown += f\"```diff\\n{info['submission']}\\n```\\n\"\n\n    markdown += \"\\n## Golden patch\\n\"\n    markdown += f\"```diff\\n{instance['golden_patch']}\\n```\\n\"\n\n    markdown += \"\\n## Trajectory\\n\"\n\n    repo_dir = setup_swebench_repo(instance)\n    file_repo = FileRepository(repo_dir)\n\n    for j, step in enumerate(trajectory[\"transitions\"]):\n        for i, traj_action in enumerate(step[\"actions\"]):\n            state_name = step['state']\n            markdown += f\"### {j+1} {state_name} ({i+1})\\n\\n\"\n\n            if not traj_action.get(\"action\"):\n                continue\n            action = traj_action[\"action\"]\n\n            if state_name == \"PlanToCode\":\n                if action.get(\"scratch_pad\"):\n                    markdown += \"*\" + action[\"scratch_pad\"] + \"*\"\n\n                if action.get(\"instructions\"):\n                    markdown += f\"\\n\\n * {action['instructions']}\"\n\n                if action.get(\"file_path\"):\n                    markdown += f\"\\n * {action['file_path']}\"\n\n                if action.get(\"span_id\"):\n                    markdown += f\"\\n * {action['span_id']}\"\n\n                if action.get(\"file_path\") and action.get(\"span_id\"):\n                    markdown += \"\\n\\n#### File context \\n\\n\"\n                    try:\n                        file_context = FileContext(file_repo)\n                        file_context.add_span_to_context(\r\n                            action.get(\"file_path\"),\r\n                            action.get(\"span_id\"),\r\n                        )\n                        markdown += file_context.create_prompt(\r\n                            show_outcommented_code=True\r\n                        )\n                    except Exception as e:\n                        logger.error(e)\n\n            if state_name == \"EditCode\":\n                markdown += \"#### LLM Response\\n\\n\"\n                markdown += f\"```\\n{action.get('content', '')}\\n```\\n\"\n\n                output = traj_action.get(\"output\")\n                if output:\n                    if output.get(\"diff\"):\n                        markdown += \"#### Diff\\n\\n\"\n                        markdown += f\"```diff\\n{output['diff']}\\n```\\n\"\n\n                    if output.get(\"errors\"):\n                        markdown += \"#### Errors\\n\\n\"\n                        markdown += f\"{output['errors']}\\n\\n\"\n\n                    if output.get(\"message\"):\n                        markdown += \"#### Message\\n\\n\"\n                        markdown += f\"{output['message']}\\n\\n\"\n\n            if state_name == \"ClarifyCodeChange\":\n                if action.get(\"thoughts\"):\n                    markdown += \"*\" + action[\"thoughts\"] + \"*\"\n\n                if action.get(\"output\") and action.get(\"output\").get(\"start_line\"):\n                    markdown += f\"\\n* Start Line: {action['output']['start_line']}\\n\"\n                    markdown += f\"\\n* End Line: {action['output']['end_line']}\\n\"\n\n            if state_name == \"Finished\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n            if state_name == \"Rejected\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n    markdown += \"## Alternative patches\\n\"\n    for alternative in instance[\"resolved_by\"]:\n        markdown += f\"### {alternative['name']}\\n\"\n        markdown += f\"```diff\\n{alternative['patch']}\\n```\\n\"\n\n    return markdown", "kind": "Chunk", "id": "benchmark/report_v2.py#28.96"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 16, "span_ids": ["imports"], "start_line": 1, "end_line": 2, "community": null}, "content": "from moatless.benchmark.swebench.utils import *  # noqa\r", "kind": "Chunk", "id": "swebench/__init__.py#29.1"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_logging_found_in_expected_spans.return.not_missing_spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 393, "span_ids": ["sorted_instances", "get_repo_dir_name", "load_instances", "found_in_expected_spans", "imports", "load_instance"], "start_line": 1, "end_line": 60, "community": null}, "content": "import logging\nimport os\nfrom typing import Optional\n\nfrom datasets import load_dataset\n\nfrom moatless.benchmark.utils import (\r\n    file_spans_to_dict,\r\n    get_missing_files,\r\n    get_missing_spans,\r\n)\nfrom moatless.file_context import FileContext\nfrom moatless.index import CodeIndex\nfrom moatless.repository import FileRepository, GitRepository\nfrom moatless.utils.repo import setup_github_repo\nfrom moatless.workspace import Workspace\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_instances(\r\n    dataset_name: str = \"princeton-nlp/SWE-bench_Lite\", split: str = \"test\"\r\n):\n    data = load_dataset(dataset_name, split=split)\n    return {d[\"instance_id\"]: d for d in data}\n\n\ndef load_instance(\r\n    instance_id: str,\r\n    dataset_name: str = \"princeton-nlp/SWE-bench_Lite\",\r\n    split: str = \"test\",\r\n):\n    data = load_instances(dataset_name, split=split)\n    return data[instance_id]\n\n\ndef sorted_instances(\r\n    dataset_name: str = \"princeton-nlp/SWE-bench_Lite\",\r\n    split: str = \"test\",\r\n    sort_by: str = \"created_at\",\r\n):\n    data = load_dataset(dataset_name, split=split)\n    instances = list(data)\n    instances = sorted(instances, key=lambda x: x[sort_by])\n    return instances\n\n\ndef get_repo_dir_name(repo: str):\n    return repo.replace(\"/\", \"_\")\n\n\ndef found_in_expected_spans(instance: dict, spans: dict):\n    for file_path, span_ids in instance[\"expected_spans\"].items():\n        if not span_ids:\n            logging.warning(\r\n                f\"{instance['instance_id']} Expected spans for {file_path} is empty\"\r\n            )\n    missing_spans = get_missing_spans(instance[\"expected_spans\"], spans)\n    return not missing_spans", "kind": "Chunk", "id": "swebench/utils.py#30.59"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_found_in_alternative_spans_sync_file_context_with_search_trajectory.for_transition_in_traject.for_action_in_transition_.if_action_action_get_.for_span_in_action_actio.workspace_file_context_ad", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 203, "span_ids": ["found_in_alternative_spans", "sync_file_context_with_search_trajectory"], "start_line": 63, "end_line": 87, "community": null}, "content": "def found_in_alternative_spans(instance: dict, spans: dict):\n    if \"alternative_spans\" not in instance:\n        return False\n    for alternative_spans in instance[\"alternative_spans\"]:\n        for file_path, span_ids in alternative_spans[\"spans\"].items():\n            if not span_ids:\n                logging.warning(\r\n                    f\"{instance['instance_id']} Alternative spans for {file_path} is empty\"\r\n                )\n\n        missing_spans = get_missing_spans(alternative_spans[\"spans\"], spans)\n        if not missing_spans:\n            return True\n\n    return False\n\n\ndef sync_file_context_with_search_trajectory(workspace: Workspace, trajectory: dict):\n    for transition in trajectory[\"transitions\"]:\n        for action in transition[\"actions\"]:\n            if action[\"action\"].get(\"identified_spans\"):\n                for span in action[\"action\"][\"identified_spans\"]:\n                    workspace.file_context.add_spans_to_context(\r\n                        span[\"file_path\"], span[\"span_ids\"]\r\n                    )", "kind": "Chunk", "id": "swebench/utils.py#31.24"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_verify_search_trajectory_verify_search_trajectory.return.result", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 854, "span_ids": ["verify_search_trajectory"], "start_line": 90, "end_line": 199, "community": null}, "content": "def verify_search_trajectory(\r\n    trajectory: dict, instance: dict, workspace: Workspace\r\n) -> dict:\n    result = {\r\n        \"transitions\": len(trajectory[\"transitions\"]),\r\n        \"identifieed\": None,\r\n        \"expected_identified\": None,\r\n        \"alt_identified\": None,\r\n        \"identified\": None,\r\n        \"file_identified\": None,\r\n        \"found_in_search\": None,\r\n        \"tokens\": 0,\r\n        \"expanded_imports\": False,\r\n        \"expanded_related\": False,\r\n        \"expanded_small_classes\": False,\r\n        \"expanded_tokens\": 0,\r\n    }\n\n    file_context = workspace.create_file_context()\n    search_file_context = workspace.create_file_context()\n\n    iterations = 0\n    for transition in trajectory[\"transitions\"]:\n        if transition[\"name\"] == \"SearchCode\":\n            iterations += 1\n\n        for action in transition[\"actions\"]:\n            if (\r\n                \"output\" in action\r\n                and action.get(\"output\")\r\n                and action[\"output\"].get(\"ranked_spans\")\r\n            ):\n                for ranked_span in action[\"output\"][\"ranked_spans\"]:\n                    search_file_context.add_spans_to_context(\r\n                        ranked_span[\"file_path\"], [ranked_span[\"span_id\"]]\r\n                    )\n\n            if action[\"action\"].get(\"identified_spans\"):\n                for span in action[\"action\"][\"identified_spans\"]:\n                    file_context.add_spans_to_context(\r\n                        span[\"file_path\"], span[\"span_ids\"]\r\n                    )\n\n            if result[\"found_in_search\"] is None and (\r\n                found_in_expected_spans(\r\n                    instance,\r\n                    file_spans_to_dict(search_file_context.to_files_with_spans()),\r\n                )\r\n                or found_in_alternative_spans(\r\n                    instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n                )\r\n            ):\n                result[\"found_in_search\"] = iterations\n\n            if result[\"file_identified\"] is None:\n                missing_files = get_missing_files(\r\n                    instance[\"expected_spans\"],\r\n                    file_spans_to_dict(file_context.to_files_with_spans()),\r\n                )\n                if not missing_files:\n                    result[\"file_identified\"] = iterations\n\n            if result[\"expected_identified\"] is None and found_in_expected_spans(\r\n                instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n            ):\n                result[\"expected_identified\"] = iterations\n\n            if result[\"alt_identified\"] is None and found_in_alternative_spans(\r\n                instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n            ):\n                result[\"alt_identified\"] = iterations\n\n    if result[\"expected_identified\"] is not None:\n        result[\"identified\"] = result[\"expected_identified\"]\n\n    if result[\"alt_identified\"] is not None and (\r\n        result[\"identified\"] is None or result[\"alt_identified\"] < result[\"identified\"]\r\n    ):\n        result[\"identified\"] = result[\"alt_identified\"]\n\n    result[\"tokens\"] = file_context.context_size()\n\n    file_context.expand_context_with_init_spans()\n    actual_span_dicts = file_spans_to_dict(file_context.to_files_with_spans())\n\n    if found_in_expected_spans(\r\n        instance, actual_span_dicts\r\n    ) or found_in_alternative_spans(instance, actual_span_dicts):\n        result[\"expanded_imports\"] = True\n\n    file_context.expand_context_with_related_spans(max_tokens=8000)\n    if found_in_expected_spans(\r\n        instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n    ) or found_in_alternative_spans(\r\n        instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n    ):\n        result[\"expanded_related\"] = True\n\n    file_context.expand_small_classes(max_tokens=500)\n    if found_in_expected_spans(\r\n        instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n    ) or found_in_alternative_spans(\r\n        instance, file_spans_to_dict(file_context.to_files_with_spans())\r\n    ):\n        result[\"expanded_small_classes\"] = True\n\n    result[\"expanded_tokens\"] = file_context.context_size()\n\n    result[\"iterations\"] = iterations\n    return result", "kind": "Chunk", "id": "swebench/utils.py#32.109"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_generate_md_report_generate_md_report.return.markdown", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 718, "span_ids": ["generate_md_report"], "start_line": 202, "end_line": 278, "community": null}, "content": "def generate_md_report(trajectory: dict, instance: dict):\n    info = trajectory[\"info\"]\n    markdown = f\"# {info['instance_id']}\\n\"\n\n    markdown += \"\\n## Problem statement\\n\"\n    markdown += f\"```\\n{instance['problem_statement']}\\n```\\n\"\n\n    if \"error\" in trajectory[\"info\"]:\n        markdown += \"\\n## Error\\n\"\n        markdown += f\"```\\n{trajectory['info']['error']}\\n```\\n\"\n    else:\n        markdown += \"\\n## Prediction\\n\"\n        markdown += f\"```diff\\n{info['submission']}\\n```\\n\"\n\n    markdown += \"\\n## Golden patch\\n\"\n    markdown += f\"```diff\\n{instance['golden_patch']}\\n```\\n\"\n\n    markdown += \"\\n## Trajectory\\n\"\n\n    repo_dir = setup_swebench_repo(instance)\n    file_repo = FileRepository(repo_dir)\n\n    for step in trajectory[\"transitions\"]:\n        for i, action in enumerate(step[\"actions\"]):\n            markdown += f\"### {step['name']} ({i})\\n\\n\"\n\n            if step[\"name\"] == \"PlanToCode\":\n                if action.get(\"action\").get(\"thoughts\"):\n                    markdown += \"*\" + action[\"action\"][\"thoughts\"] + \"*\"\n\n                if action.get(\"action\", {}).get(\"action\", {}).get(\"description\"):\n                    markdown += f\"\\n\\n * {action['action']['action']['description']}\"\n\n                if action.get(\"action\", {}).get(\"action\", {}).get(\"file_path\"):\n                    markdown += f\"\\n * {action['action']['action']['file_path']}\"\n\n                if action.get(\"action\", {}).get(\"action\", {}).get(\"span_id\"):\n                    markdown += f\"\\n * {action['action']['action']['span_id']}\"\n\n                    markdown += \"\\n\\n#### File context \\n\\n\"\n\n                    file_context = FileContext(file_repo)\n                    file_context.add_span_to_context(\r\n                        action[\"action\"][\"action\"][\"file_path\"],\r\n                        action[\"action\"][\"action\"][\"span_id\"],\r\n                    )\n\n                    markdown += file_context.create_prompt(show_outcommented_code=True)\n\n            if step[\"name\"] == \"EditCode\":\n                markdown += \"#### LLM Response\\n\\n\"\n                markdown += f\"```\\n{action['action']['content']}\\n```\\n\"\n\n                if action.get(\"output\", {}).get(\"message\"):\n                    markdown += \"#### Output\\n\\n\"\n                    markdown += f\"{action['output']['message']}\\n\\n\"\n\n            if step[\"name\"] == \"ClarifyCodeChange\":\n                if action.get(\"thoughts\"):\n                    markdown += \"*\" + action[\"thoughts\"] + \"*\"\n\n                if action.get(\"output\", {}).get(\"start_line\"):\n                    markdown += f\"\\n* Start Line: {action['output']['start_line']}\\n\"\n                    markdown += f\"\\n* End Line: {action['output']['end_line']}\\n\"\n\n            if step[\"name\"] == \"Finished\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n            if step[\"name\"] == \"Rejected\":\n                markdown += f\"*{action['properties']['message']}*\\n\"\n\n    markdown += \"## Alternative patches\\n\"\n    for alternative in instance[\"resolved_by\"]:\n        markdown += f\"### {alternative['name']}\\n\"\n        markdown += f\"```diff\\n{alternative['patch']}\\n```\\n\"\n\n    return markdown", "kind": "Chunk", "id": "swebench/utils.py#33.76"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_setup_swebench_repo_setup_swebench_repo.return.setup_github_repo_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 165, "span_ids": ["setup_swebench_repo"], "start_line": 281, "end_line": 301, "community": null}, "content": "def setup_swebench_repo(\r\n    instance_data: Optional[dict] = None,\r\n    instance_id: str = None,\r\n    repo_base_dir: Optional[str] = None,\r\n) -> str:\n    assert (\r\n        instance_data or instance_id\r\n    ), \"Either instance_data or instance_id must be provided\"\n    if not instance_data:\n        instance_data = load_instance(instance_id)\n\n    if not repo_base_dir:\n        repo_base_dir = os.getenv(\"REPO_DIR\", \"/tmp/repos\")\n\n    repo_dir_name = instance_data[\"repo\"].replace(\"/\", \"__\")\n    github_repo_path = f\"swe-bench/{repo_dir_name}\"\n    return setup_github_repo(\r\n        repo=github_repo_path,\r\n        base_commit=instance_data[\"base_commit\"],\r\n        base_dir=repo_base_dir,\r\n    )", "kind": "Chunk", "id": "swebench/utils.py#34.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py_create_workspace_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\swebench\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 273, "span_ids": ["create_workspace"], "start_line": 304, "end_line": 338, "community": null}, "content": "def create_workspace(\r\n    instance: Optional[dict] = None,\r\n    instance_id: Optional[str] = None,\r\n    repo_base_dir: Optional[str] = None,\r\n    index_store_dir: Optional[str] = None,\r\n):\n    \"\"\"\r\n    Create a workspace for the given SWE-bench instance.\r\n    \"\"\"\n    assert instance or instance_id, \"Either instance or instance_id must be provided\"\n    if not instance:\n        instance = load_instance(instance_id)\n\n    if not index_store_dir:\n        index_store_dir = os.getenv(\"INDEX_STORE_DIR\", \"/tmp/index_store\")\n\n    if not repo_base_dir:\n        repo_base_dir = os.getenv(\"REPO_DIR\", \"/tmp/repos\")\n\n    repo_dir_name = instance[\"repo\"].replace(\"/\", \"__\")\n    repo_url = f\"https://github.com/swe-bench/{repo_dir_name}.git\"\n    repo_dir = f\"{repo_base_dir}/swe-bench_{repo_dir_name}\"\n    repo = GitRepository.from_repo(\r\n        git_repo_url=repo_url, repo_path=repo_dir, commit=instance[\"base_commit\"]\r\n    )\n\n    code_index = CodeIndex.from_index_name(\r\n        instance[\"instance_id\"], index_store_dir=index_store_dir, file_repo=repo\r\n    )\n\n    return Workspace(\r\n        file_repo=repo,\r\n        code_index=code_index,\r\n    )", "kind": "Chunk", "id": "swebench/utils.py#35.34"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_logging_find_relevant_spans.return.relevant_spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 337, "span_ids": ["imports", "find_relevant_spans"], "start_line": 1, "end_line": 46, "community": null}, "content": "import logging\nimport re\nimport time\n\nfrom moatless.codeblocks.module import Module\nfrom moatless.repository import FileRepository\nfrom moatless.types import FileWithSpans\n\nlogger = logging.getLogger(__name__)\n\n\ndef find_relevant_spans(original_block: Module, updated_block: Module):\n    \"\"\"Find relevant spans in test content. Used for finding the \"perfect\" context in benchmark instances.\"\"\"\n\n    relevant_spans = set()\n\n    for span in updated_block.spans_by_id.values():\n        if span.span_id in relevant_spans:\n            continue\n\n        if original_block.has_span(span.span_id):\n            updated_content = updated_block.to_prompt(\r\n                span_ids=set(span.span_id), show_outcommented_code=False\r\n            ).strip()\n            original_content = original_block.to_prompt(\r\n                span_ids=set(span.span_id), show_outcommented_code=False\r\n            ).strip()\n            if original_content != updated_content:\n                relevant_spans.add(span.span_id)\n\n            # TODO: Second prio after token count\r\n            related_span_ids = original_block.find_related_span_ids(span.span_id)\n            relevant_spans.update(related_span_ids)\n        else:\n            parent_block = updated_block.find_first_by_span_id(span.span_id).parent\n            original_parent_block = original_block.find_by_path(\r\n                parent_block.full_path()\r\n            )\n            span_ids = list(original_parent_block.belongs_to_span.span_id)\n\n            related_span_ids = updated_block.find_related_span_ids(span.span_id)\n            for related_span_id in related_span_ids:\n                if original_block.has_span(related_span_id):\n                    span_ids.append(related_span_id)\n\n    return relevant_spans", "kind": "Chunk", "id": "benchmark/utils.py#36.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_get_diff_lines_get_diff_lines.return.changes", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 277, "span_ids": ["get_diff_lines"], "start_line": 49, "end_line": 87, "community": null}, "content": "def get_diff_lines(diff_input):\n    if not diff_input:\n        return []\n    file_name_re = re.compile(r\"diff --git a/(.+) b/.+\")\n    file_name_no_git_re = re.compile(r\"--- a/(.+)\")\n\n    line_change_re = re.compile(r\"^@@ -(\\d+),(\\d+) \\+(\\d+),(\\d+) @@\")\n\n    changes = []\n\n    current_file = None\n    for line in diff_input.splitlines():\n        file_match = file_name_re.match(line)\n        if file_match:\n            current_file = file_match.group(1)\n            continue\n\n        if not current_file:\n            file_match = file_name_no_git_re.match(line)\n            if file_match:\n                current_file = file_match.group(1)\n\n            continue\n\n        line_change_match = line_change_re.match(line)\n        if line_change_match:\n            old_start, old_length, new_start, new_length = map(\r\n                int, line_change_match.groups()\r\n            )\n\n            adjustment_start = max(1, min(3, old_start - 3))\n            adjusted_start = old_start + adjustment_start\n\n            relevant_diff_lines = max(0, old_length - 7)\n            adjusted_end = adjusted_start + relevant_diff_lines\n\n            changes.append((current_file, adjusted_start, adjusted_end))\n\n    return changes", "kind": "Chunk", "id": "benchmark/utils.py#37.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_compare_patches_create_file_spans_from_patch.return.files_with_spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 274, "span_ids": ["compare_patches", "create_file_spans_from_patch"], "start_line": 90, "end_line": 126, "community": null}, "content": "def compare_patches(expected_patch, actual_patch):\n    expected_diffs = get_diff_lines(expected_patch)\n    actual_diffs = get_diff_lines(actual_patch)\n\n    expected_files = set()\n    file_hits = set()\n    line_hits = 0\n\n    for patch_diff in expected_diffs:\n        change_file, change_start, change_end = patch_diff\n\n        for actual_diff in actual_diffs:\n            actual_change_file, actual_change_start, actual_change_end = actual_diff\n            expected_files.add(change_file)\n            if change_file == actual_change_file:\n                file_hits.add(change_file)\n                if (\r\n                    change_start >= actual_change_start\r\n                    and change_end <= actual_change_end\r\n                ):\n                    line_hits += 1\n                    continue\n\n    return len(expected_files) - len(file_hits), len(expected_diffs) - line_hits\n\n\ndef create_file_spans_from_patch(repo_dir: str, patch: str) -> list[FileWithSpans]:\n    repository = FileRepository(repo_dir)\n    files_with_spans = []\n    for file_path, span_ids in get_file_spans_from_patch(repository, patch).items():\n        file_with_spans = FileWithSpans(\r\n            file_path=file_path,\r\n            span_ids=span_ids,\r\n        )\n        files_with_spans.append(file_with_spans)\n\n    return files_with_spans", "kind": "Chunk", "id": "benchmark/utils.py#38.36"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_get_file_spans_from_patch_get_file_spans_from_patch.return.expected_files_with_spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 168, "span_ids": ["get_file_spans_from_patch"], "start_line": 129, "end_line": 148, "community": null}, "content": "def get_file_spans_from_patch(\r\n    repository: FileRepository, patch: str\r\n) -> dict[str, list[str]]:\n    expected_diff_lines = get_diff_lines(patch)\n    expected_files_with_spans = {}\n\n    for diff_line in expected_diff_lines:\n        file = repository.get_file(diff_line[0])\n\n        if file is None or file.module is None:\n            continue\n\n        if file.file_path not in expected_files_with_spans:\n            expected_files_with_spans[file.file_path] = []\n\n        spans = file.module.find_spans_by_line_numbers(diff_line[1], diff_line[2])\n        for span in spans:\n            if span.span_id not in expected_files_with_spans[file.file_path]:\n                expected_files_with_spans[file.file_path].append(span.span_id)\n    return expected_files_with_spans", "kind": "Chunk", "id": "benchmark/utils.py#39.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_get_files_from_patch_file_spans_to_dict.return.span_dict", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 162, "span_ids": ["get_files_from_patch", "file_spans_to_dict"], "start_line": 151, "end_line": 168, "community": null}, "content": "def get_files_from_patch(patch: str) -> list[str]:\n    diff_lines = get_diff_lines(patch)\n    return [diff_line[0] for diff_line in diff_lines]\n\n\ndef file_spans_to_dict(files_with_spans: list[FileWithSpans]) -> dict[str, list[str]]:\n    span_dict = {}\n    if not files_with_spans:\n        return span_dict\n\n    for file_with_spans in files_with_spans:\n        if file_with_spans.file_path not in span_dict:\n            span_dict[file_with_spans.file_path] = []\n\n        for span_id in file_with_spans.span_ids:\n            if span_id not in span_dict[file_with_spans.file_path]:\n                span_dict[file_with_spans.file_path].append(span_id)\n    return span_dict", "kind": "Chunk", "id": "benchmark/utils.py#40.17"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_get_missing_files_get_missing_spans.return.misses", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 215, "span_ids": ["get_missing_spans", "get_missing_files"], "start_line": 171, "end_line": 198, "community": null}, "content": "def get_missing_files(\r\n    expected_files_with_spans: dict[str, list[str]],\r\n    actual_files_with_spans: dict[str, list[str]],\r\n) -> list[str]:\n    misses = list(expected_files_with_spans.keys())\n    for actual_file in actual_files_with_spans:\n        if actual_file in misses:\n            misses.remove(actual_file)\n    return misses\n\n\ndef get_missing_spans(\r\n    expected_files_with_spans: dict[str, list[str]],\r\n    actual_files_with_spans: dict[str, list[str]],\r\n) -> dict[str, list[str]]:\n    misses = {}\n    for expected_file, span_ids in expected_files_with_spans.items():\n        if expected_file not in actual_files_with_spans:\n            misses[expected_file] = span_ids\n            continue\n\n        for span_id in span_ids:\n            if span_id not in actual_files_with_spans[expected_file]:\n                if expected_file not in misses:\n                    misses[expected_file] = []\n                misses[expected_file].append(span_id)\n\n    return misses", "kind": "Chunk", "id": "benchmark/utils.py#41.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_calculate_estimated_context_window_calculate_estimated_context_window.return.expected_changes_sum_tok", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 376, "span_ids": ["calculate_estimated_context_window"], "start_line": 201, "end_line": 255, "community": null}, "content": "def calculate_estimated_context_window(instance, results):\n    patch_diffs = get_diff_lines(instance[\"patch\"])\n    expected_changes = []\n\n    for patch_diff in patch_diffs:\n        change_file, change_start, change_end = patch_diff\n        expected_changes.append(\r\n            {\r\n                \"file_path\": change_file,\r\n                \"start_line\": change_start,\r\n                \"end_line\": change_end,\r\n                \"closest_match_context_window\": None,\r\n                \"closest_match_lines\": None,\r\n                \"position\": None,\r\n                \"distance\": None,\r\n                \"context_window\": None,\r\n            }\r\n        )\n\n    sum_tokens = 0\n\n    for i, result in enumerate(results):\n        sum_tokens += result.tokens\n        for change in expected_changes:\n            if result.file_path == change[\"file_path\"]:\n                if (\r\n                    result.start_line - 1 <= change[\"start_line\"]\r\n                    and result.end_line + 1 >= change[\"end_line\"]\r\n                ):\n                    change[\"distance\"] = result.distance\n                    change[\"context_window\"] = sum_tokens\n                    change[\"position\"] = i\n\n                    if all(\r\n                        context[\"context_window\"] is not None\r\n                        for context in expected_changes\r\n                    ):\n                        return expected_changes, sum_tokens\n                else:\n                    closest_match_lines = change.get(\"closest_match_lines\")\n                    if (\r\n                        not closest_match_lines\r\n                        or abs(result.start_line - change[\"start_line\"])\r\n                        < abs(closest_match_lines[0] - change[\"start_line\"])\r\n                    ) or (\r\n                        abs(result.end_line - change[\"end_line\"])\r\n                        == abs(closest_match_lines[0] - change[\"end_line\"])\r\n                    ):\n                        change[\"closest_match_lines\"] = (\r\n                            result.start_line,\r\n                            result.end_line,\r\n                        )\n                        change[\"closest_match_context_window\"] = sum_tokens\n\n    return expected_changes, sum_tokens", "kind": "Chunk", "id": "benchmark/utils.py#42.54"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py_get_total_cost_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\benchmark\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 156, "span_ids": ["trace_metadata", "get_total_cost"], "start_line": 258, "end_line": 281, "community": null}, "content": "def get_total_cost(trace_id):\n    try:\n        import langfuse\n    except ImportError:\n        logger.info(\"Langfuse not installed, can't get total cost\")\n        return 0\n\n    langfuse = langfuse.Langfuse()\n    trace = langfuse.get_trace(trace_id)\n\n    return trace.total_cost\n\n\ndef trace_metadata(instance_id: str, session_id: str, trace_name: str):\n    date_time_str = time.strftime(\"%Y%m%d-%H%M%S\")\n    trace_id = f\"coder_{instance_id}_{date_time_str}\"\n    return {\r\n        \"session_id\": session_id,\r\n        \"name\": trace_name,\r\n        \"trace\": trace_name,\r\n        \"trace_id\": trace_id,\r\n        \"tags\": [instance_id],\r\n    }", "kind": "Chunk", "id": "benchmark/utils.py#43.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\__init__.py_from_moatless_codeblocks__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 127, "span_ids": ["imports", "get_parser_by_path", "supports_codeblocks"], "start_line": 1, "end_line": 19, "community": null}, "content": "from moatless.codeblocks.codeblocks import CodeBlock, CodeBlockType\nfrom moatless.codeblocks.parser.create import create_parser\nfrom moatless.codeblocks.parser.java import JavaParser\nfrom moatless.codeblocks.parser.parser import CodeParser\nfrom moatless.codeblocks.parser.python import PythonParser\n\n\ndef supports_codeblocks(path: str):\n    return path.endswith(\".py\")\n\n\ndef get_parser_by_path(file_path: str) -> CodeParser | None:\n    if file_path.endswith(\".py\"):\n        return PythonParser()\n    elif file_path.endswith(\".java\"):\n        return JavaParser()\n    else:\n        return None", "kind": "Chunk", "id": "codeblocks/__init__.py#44.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_re_CodeBlockTypeGroup.ERROR._Error_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 139, "span_ids": ["imports", "CodeBlockTypeGroup", "SpanMarker"], "start_line": 1, "end_line": 29, "community": null}, "content": "import re\nfrom enum import Enum\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ConfigDict, Field, model_validator, field_validator\nfrom typing_extensions import deprecated\n\nfrom moatless.codeblocks.parser.comment import get_comment_symbol\nfrom moatless.utils.colors import Colors\n\nBlockPath = list[str]\n\n\nclass SpanMarker(Enum):\n    TAG = 1\n    COMMENT = 2\n\n\nclass CodeBlockTypeGroup(str, Enum):\n    STRUCTURE = \"Structures\"\n    IMPLEMENTATION = \"Implementation\"\n    IMPORT = \"Imports\"\n\n    BLOCK_DELIMITER = \"BlockDelimiter\"\n    SPACE = \"Space\"\n\n    COMMENT = \"Comment\"\n\n    ERROR = \"Error\"", "kind": "Chunk", "id": "codeblocks/codeblocks.py#45.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlockType_CodeBlockType.__init__.self.group.group", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 416, "span_ids": ["CodeBlockType.__init__", "CodeBlockType"], "start_line": 32, "end_line": 73, "community": null}, "content": "class CodeBlockType(Enum):\n    MODULE = (\r\n        \"Module\",\r\n        CodeBlockTypeGroup.STRUCTURE,\r\n    )  # TODO: Module shouldn't be a STRUCTURE\r\n    CLASS = (\"Class\", CodeBlockTypeGroup.STRUCTURE)\n    FUNCTION = (\"Function\", CodeBlockTypeGroup.STRUCTURE)\n\n    # TODO: Remove and add sub types to functions and classes\r\n    CONSTRUCTOR = (\"Constructor\", CodeBlockTypeGroup.STRUCTURE)\n    TEST_SUITE = (\"TestSuite\", CodeBlockTypeGroup.STRUCTURE)\n    TEST_CASE = (\"TestCase\", CodeBlockTypeGroup.STRUCTURE)\n\n    IMPORT = (\"Import\", CodeBlockTypeGroup.IMPORT)\n\n    EXPORT = (\"Export\", CodeBlockTypeGroup.IMPLEMENTATION)\n    COMPOUND = (\"Compound\", CodeBlockTypeGroup.IMPLEMENTATION)\n    # Dependent clauses are clauses that are dependent on another compound statement and can't be shown on their own\r\n    DEPENDENT_CLAUSE = (\"DependentClause\", CodeBlockTypeGroup.IMPLEMENTATION)\n    ASSIGNMENT = (\"Assignment\", CodeBlockTypeGroup.IMPLEMENTATION)\n    CALL = (\"Call\", CodeBlockTypeGroup.IMPLEMENTATION)\n    STATEMENT = (\"Statement\", CodeBlockTypeGroup.IMPLEMENTATION)\n\n    CODE = (\"Code\", CodeBlockTypeGroup.IMPLEMENTATION)\n\n    # TODO: Incorporate in code block?\r\n    BLOCK_DELIMITER = (\"BlockDelimiter\", CodeBlockTypeGroup.BLOCK_DELIMITER)\n\n    # TODO: Remove as it's just to fill upp spaces at the end of the file?\r\n    SPACE = (\"Space\", CodeBlockTypeGroup.SPACE)\n\n    COMMENT = (\"Comment\", CodeBlockTypeGroup.COMMENT)\n    COMMENTED_OUT_CODE = (\r\n        \"Placeholder\",\r\n        CodeBlockTypeGroup.COMMENT,\r\n    )  # TODO: Replace to PlaceholderComment\r\n\n    ERROR = (\"Error\", CodeBlockTypeGroup.ERROR)\n\n    def __init__(self, value: str, group: CodeBlockTypeGroup):\n        self._value_ = value\n        self.group = group", "kind": "Chunk", "id": "codeblocks/codeblocks.py#46.41"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlockType.from_string_CodeBlockType.from_string.return.tag_to_block_type_get_tag", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 224, "span_ids": ["CodeBlockType.from_string"], "start_line": 75, "end_line": 99, "community": null}, "content": "class CodeBlockType(Enum):\n\n    @classmethod\r\n    def from_string(cls, tag: str) -> Optional[\"CodeBlockType\"]:\n        if not tag.startswith(\"definition\"):\n            return None\n\n        tag_to_block_type = {\r\n            \"definition.assignment\": cls.ASSIGNMENT,\r\n            \"definition.block_delimiter\": cls.BLOCK_DELIMITER,\r\n            \"definition.call\": cls.CALL,\r\n            \"definition.class\": cls.CLASS,\r\n            \"definition.code\": cls.CODE,\r\n            \"definition.comment\": cls.COMMENT,\r\n            \"definition.compound\": cls.COMPOUND,\r\n            \"definition.constructor\": cls.CONSTRUCTOR,\r\n            \"definition.dependent_clause\": cls.DEPENDENT_CLAUSE,\r\n            \"definition.error\": cls.ERROR,\r\n            \"definition.export\": cls.EXPORT,\r\n            \"definition.function\": cls.FUNCTION,\r\n            \"definition.import\": cls.IMPORT,\r\n            \"definition.module\": cls.MODULE,\r\n            \"definition.statement\": cls.STATEMENT,\r\n            \"definition.test_suite\": cls.TEST_SUITE,\r\n            \"definition.test_case\": cls.TEST_CASE,\r\n        }\n        return tag_to_block_type.get(tag)", "kind": "Chunk", "id": "codeblocks/codeblocks.py#47.24"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_NON_CODE_BLOCKS_PathTree.extend_tree.for_path_in_paths_.self_add_to_tree_path_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 303, "span_ids": ["PathTree.child_tree", "PathTree.from_block_paths", "PathTree", "PathTree.extend_tree", "impl:3", "PathTree.merge"], "start_line": 102, "end_line": 147, "community": null}, "content": "NON_CODE_BLOCKS = [\r\n    CodeBlockType.BLOCK_DELIMITER,\r\n    CodeBlockType.COMMENT,\r\n    CodeBlockType.COMMENTED_OUT_CODE,\r\n    CodeBlockType.EXPORT,\r\n    CodeBlockType.IMPORT,\r\n    CodeBlockType.ERROR,\r\n    CodeBlockType.SPACE,\r\n]\n\nINDEXED_BLOCKS = [\r\n    CodeBlockType.FUNCTION,\r\n    CodeBlockType.CLASS,\r\n    CodeBlockType.TEST_SUITE,\r\n    CodeBlockType.TEST_CASE,\r\n]\n\n\n@deprecated(\"Use BlockSpans to define code block visibility instead\")\r\nclass PathTree(BaseModel):\n    show: bool = Field(default=False, description=\"Show the block and all sub blocks.\")\n    tree: dict[str, \"PathTree\"] = Field(default_factory=dict)\n\n    @staticmethod\r\n    def from_block_paths(block_paths: list[BlockPath]) -> \"PathTree\":\n        tree = PathTree()\n        for block_path in block_paths:\n            tree.add_to_tree(block_path)\n\n        return tree\n\n    def child_tree(self, key: str) -> Optional[\"PathTree\"]:\n        return self.tree.get(key, None)\n\n    def merge(self, other: \"PathTree\"):\n        if other.show:\n            self.show = True\n\n        for key, value in other.tree.items():\n            if key not in self.tree:\n                self.tree[key] = PathTree()\n            self.tree[key].merge(value)\n\n    def extend_tree(self, paths: list[list[str]]):\n        for path in paths:\n            self.add_to_tree(path)", "kind": "Chunk", "id": "codeblocks/codeblocks.py#48.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_PathTree.add_to_tree_PathTree.add_to_tree.self_tree_path_0_add_to", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 147, "span_ids": ["PathTree.add_to_tree"], "start_line": 149, "end_line": 168, "community": null}, "content": "@deprecated(\"Use BlockSpans to define code block visibility instead\")\r\nclass PathTree(BaseModel):\n\n    def add_to_tree(self, path: list[str]):\n        if path is None:\n            return\n\n        if len(path) == 0:\n            self.show = True\n            return\n\n        if len(path) == 1:\n            if path[0] not in self.tree:\n                self.tree[path[0]] = PathTree(show=True)\n            else:\n                self.tree[path[0]].show = True\n\n            return\n\n        if path[0] not in self.tree:\n            self.tree[path[0]] = PathTree(show=False)\n\n        self.tree[path[0]].add_to_tree(path[1:])", "kind": "Chunk", "id": "codeblocks/codeblocks.py#49.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_ReferenceScope_RelationshipType.TYPE._type_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 138, "span_ids": ["ReferenceScope", "RelationshipType"], "start_line": 171, "end_line": 190, "community": null}, "content": "class ReferenceScope(str, Enum):\n    EXTERNAL = \"external\"\n    DEPENDENCY = \"dependency\"  # External dependency\r\n    FILE = \"file\"  # File in repository\r\n    PROJECT = \"project\"\n    CLASS = \"class\"\n    LOCAL = \"local\"\n    GLOBAL = \"global\"\n\n\nclass RelationshipType(str, Enum):\n    UTILIZES = \"utilizes\"\n    USES = \"uses\"\n    DEFINED_BY = \"defined_by\"\n    IS_A = \"is_a\"\n    PROVIDES = \"provides\"\n    IMPORTS = \"imports\"\n    CALLS = \"calls\"\n    DEPENDENCY = \"dependency\"\n    TYPE = \"type\"", "kind": "Chunk", "id": "codeblocks/codeblocks.py#50.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_Relationship_Relationship.__str__.return.f_start_node_self_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 357, "span_ids": ["Relationship.validate_path", "Relationship.__hash__", "Relationship.__eq__", "Relationship.full_path", "Relationship.__str__", "Relationship"], "start_line": 193, "end_line": 238, "community": null}, "content": "class Relationship(BaseModel):\n    scope: ReferenceScope = Field(description=\"The scope of the reference.\")\n    identifier: Optional[str] = Field(default=None, description=\"ID\")\n    type: RelationshipType = Field(\r\n        default=RelationshipType.USES, description=\"The type of the reference.\"\r\n    )\n    external_path: list[str] = Field(\r\n        default=[], description=\"The path to the referenced parent code block.\"\r\n    )\n    resolved_path: list[str] = Field(\r\n        default=[], description=\"The path to the file with the referenced code block.\"\r\n    )\n    path: list[str] = Field(\r\n        default=[], description=\"The path to the referenced code block.\"\r\n    )\n\n    @classmethod\r\n    @model_validator(mode=\"before\")\r\n    def validate_path(cls, values):\n        external_path = values.get(\"external_path\")\n        path = values.get(\"path\")\n        if not external_path and not path:\n            raise ValueError(\"Cannot create Reference without external_path or path.\")\n        return values\n\n    def __hash__(self):\n        return hash((self.scope, tuple(self.path)))\n\n    def __eq__(self, other):\n        return (self.scope, self.path) == (other.scope, other.path)\n\n    def full_path(self):\n        return self.external_path + self.path\n\n    def __str__(self):\n        start_node = self.identifier if self.identifier else \"\"\n\n        end_node = \"\"\n        if self.external_path:\n            end_node = \"/\".join(self.external_path)\n        if self.path:\n            if self.external_path:\n                end_node += \"/\"\n            end_node += \".\".join(self.path)\n\n        return f\"({start_node})-[:{self.type.name} {{scope: {self.scope.value}}}]->({end_node})\"", "kind": "Chunk", "id": "codeblocks/codeblocks.py#51.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_Parameter_ValidationError.error", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 384, "span_ids": ["Parameter", "SpanType", "BlockSpan.block_type", "BlockSpan.__str__", "BlockSpan:12", "BlockSpan.get_first_child_block_path", "ValidationError", "BlockSpan"], "start_line": 241, "end_line": 300, "community": null}, "content": "class Parameter(BaseModel):\n    identifier: str = Field(description=\"The identifier of the parameter.\")\n    type: Optional[str] = Field(description=\"The type of the parameter.\")\n\n\nclass SpanType(str, Enum):\n    INITATION = \"init\"\n    DOCUMENTATION = \"docs\"\n    IMPLEMENTATION = \"impl\"\n\n\nclass BlockSpan(BaseModel):\n    span_id: str = Field()\n    span_type: SpanType = Field(description=\"Type of span.\")\n    start_line: int = Field(description=\"Start line of the span.\")\n    end_line: int = Field(description=\"End line of the span.\")\n\n    initiating_block: \"CodeBlock\" = Field(\r\n        default=None,\r\n        description=\"The block that initiated the span.\",\r\n    )\n\n    @property\r\n    def block_type(self):\n        return self.initiating_block.type\n\n    # TODO: Remove\r\n    visible: bool = Field(default=True, description=\"If the span should be visible.\")\n\n    index: int = 0\n\n    parent_block_path: BlockPath = Field(\r\n        default=None,\r\n        description=\"Path to the parent block of the span.\",\r\n    )\n\n    is_partial: bool = Field(\r\n        default=False,\r\n        description=\"If the span is covering a partial part of the parent block.\",\r\n    )\n\n    block_paths: list[BlockPath] = Field(\r\n        default=[],\r\n        description=\"Block paths that should be shown when the span is shown.\",\r\n    )\n\n    tokens: int = Field(default=0, description=\"Number of tokens in the span.\")\n\n    def __str__(self):\n        return f\"{self.span_id} ({self.span_type.value}, {self.tokens} tokens)\"\n\n    def get_first_child_block_path(self):\n        for block_path in self.block_paths:\n            if len(block_path) == len(self.parent_block_path):\n                continue\n            return block_path\n\n\nclass ValidationError(BaseModel):\n    error: str", "kind": "Chunk", "id": "codeblocks/codeblocks.py#52.59"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock_CodeBlock.remove_child.del_self_children_index_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 810, "span_ids": ["CodeBlock.replace_child", "CodeBlock.replace_children", "CodeBlock.__init__", "CodeBlock.validate_type", "CodeBlock.insert_children", "CodeBlock.append_children", "CodeBlock.remove_child", "CodeBlock.insert_child", "CodeBlock", "CodeBlock.append_child", "CodeBlock.last"], "start_line": 303, "end_line": 402, "community": null}, "content": "class CodeBlock(BaseModel):\n    content: str\n    type: CodeBlockType\n    identifier: Optional[str] = None\n    parameters: list[Parameter] = []  # TODO: Move to Function sub class\r\n    relationships: list[Relationship] = []\n    span_ids: set[str] = set()\n    belongs_to_span: BlockSpan | None = None\n    content_lines: list[str] = []\n    start_line: int = 0\n    end_line: int = 0\n    properties: dict = {}\n    pre_code: str = \"\"\n    pre_lines: int = 0\n    indentation: str = \"\"\n    tokens: int = 0\n    children: list[\"CodeBlock\"] = []\n    validation_errors: list[ValidationError] = []\n    parent: Optional[\"CodeBlock\"] = None\n    previous: Optional[\"CodeBlock\"] = None\n    next: Optional[\"CodeBlock\"] = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @classmethod\r\n    @field_validator(\"type\", mode=\"before\")\r\n    def validate_type(cls, v):\n        if v is None:\n            raise ValueError(\"Cannot create CodeBlock without type.\")\n        return v\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        for child in self.children:\n            child.parent = self\n\n        if self.pre_code and not re.match(r\"^[ \\n\\\\]*$\", self.pre_code):\n            raise ValueError(\r\n                f\"Failed to parse code block with type {self.type} and content `{self.content}`. \"\r\n                f\"Expected pre_code to only contain spaces and line breaks. Got `{self.pre_code}`\"\r\n            )\n\n        if self.pre_code and not self.indentation and not self.pre_lines:\n            pre_code_lines = self.pre_code.split(\"\\n\")\n            self.pre_lines = len(pre_code_lines) - 1\n            if self.pre_lines > 0:\n                self.indentation = pre_code_lines[-1]\n            else:\n                self.indentation = self.pre_code\n\n        self.content_lines = self.content.split(\"\\n\")\n        # if self.indentation and self.pre_lines:\r\n        #    self.content_lines[1:] = [line[len(self.indentation):] for line in self.content_lines[1:]]\r\n\n    def last(self):\n        if self.next:\n            return self.next.last()\n        return self\n\n    def insert_child(self, index: int, child: \"CodeBlock\"):\n        if index == 0 and self.children[0].pre_lines == 0:\n            self.children[0].pre_lines = 1\n\n        self.children.insert(index, child)\n        child.parent = self\n\n    def insert_children(self, index: int, children: list[\"CodeBlock\"]):\n        for child in children:\n            self.insert_child(index, child)\n            index += 1\n\n    def append_child(self, child: \"CodeBlock\"):\n        self.children.append(child)\n        self.span_ids.update(child.span_ids)\n        child.parent = self\n\n    def append_children(self, children: list[\"CodeBlock\"]):\n        for child in children:\n            self.append_child(child)\n\n    def replace_children(\r\n        self, start_index: int, end_index: int, children: list[\"CodeBlock\"]\r\n    ):\n        self.children = (\r\n            self.children[:start_index] + children + self.children[end_index:]\r\n        )\n        for child in children:\n            child.parent = self\n\n    def replace_child(self, index: int, child: \"CodeBlock\"):\n        # TODO: Do a proper update of everything when replacing child blocks\r\n        child.pre_code = self.children[index].pre_code\n        child.pre_lines = self.children[index].pre_lines\n        self.sync_indentation(self.children[index], child)\n\n        self.children[index] = child\n        child.parent = self\n\n    def remove_child(self, index: int):\n        del self.children[index]", "kind": "Chunk", "id": "codeblocks/codeblocks.py#53.99"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.sync_indentation_CodeBlock.sync_indentation.if_.elif_original_indentation.updated_block_add_indenta", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 174, "span_ids": ["CodeBlock.sync_indentation"], "start_line": 404, "end_line": 423, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def sync_indentation(self, original_block: \"CodeBlock\", updated_block: \"CodeBlock\"):\n        original_indentation_length = len(original_block.indentation) + len(\r\n            self.indentation\r\n        )\n        updated_indentation_length = len(updated_block.indentation) + len(\r\n            updated_block.parent.indentation\r\n        )\n\n        # To handle separate code blocks provdided out of context\r\n        if (\r\n            original_indentation_length == updated_indentation_length\r\n            and len(updated_block.indentation) == 0\r\n        ):\n            updated_block.indentation = \" \" * original_indentation_length\n\n        elif original_indentation_length > updated_indentation_length:\n            additional_indentation = \" \" * (\r\n                original_indentation_length - updated_indentation_length\r\n            )\n            updated_block.add_indentation(additional_indentation)", "kind": "Chunk", "id": "codeblocks/codeblocks.py#54.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.replace_by_path_CodeBlock.is_visible.return.self_belongs_to_span_and_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 367, "span_ids": ["CodeBlock.has_visible_children", "CodeBlock.to_string", "CodeBlock.get_all_child_blocks", "CodeBlock.is_visible", "CodeBlock.__str__", "CodeBlock.get_children", "CodeBlock.replace_by_path", "CodeBlock.sum_tokens", "CodeBlock.show_related_spans"], "start_line": 425, "end_line": 482, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def replace_by_path(self, path: list[str], new_block: \"CodeBlock\"):\n        if not path:\n            return\n\n        for i, child in enumerate(self.children):\n            if child.identifier == path[0]:\n                if len(path) == 1:\n                    self.replace_child(i, new_block)\n                    return\n                else:\n                    child.replace_by_path(path[1:], new_block)\n\n    def __str__(self):\n        return self.to_string()\n\n    def to_string(self):\n        return self._to_string()\n\n    def sum_tokens(self):\n        tokens = self.tokens\n        tokens += sum([child.sum_tokens() for child in self.children])\n        return tokens\n\n    def get_all_child_blocks(self) -> list[\"CodeBlock\"]:\n        blocks = []\n        for child in self.children:\n            blocks.append(child)\n            blocks.extend(child.get_all_child_blocks())\n        return blocks\n\n    def get_children(\r\n        self, exclude_blocks: list[CodeBlockType] = None\r\n    ) -> list[\"CodeBlock\"]:\n        if exclude_blocks is None:\n            exclude_blocks = []\n        return [child for child in self.children if child.type not in exclude_blocks]\n\n    def show_related_spans(\r\n        self,\r\n        span_id: Optional[str] = None,  # TODO: Set max tokens to show\r\n    ):\n        related_spans = self.find_related_spans(span_id)\n        for span in related_spans:\n            span.visible = True\n\n    def has_visible_children(self):\n        for child in self.children:\n            if child.is_visible:\n                return True\n\n            if child.has_visible_children():\n                return True\n\n        return False\n\n    @property\r\n    def is_visible(self):\n        return self.belongs_to_span and self.belongs_to_span.visible", "kind": "Chunk", "id": "codeblocks/codeblocks.py#55.57"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock._to_string_CodeBlock._to_string.return.contents", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 131, "span_ids": ["CodeBlock._to_string"], "start_line": 484, "end_line": 502, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def _to_string(self) -> str:\n        contents = \"\"\n\n        if self.pre_lines:\n            contents += \"\\n\" * (self.pre_lines - 1)\n            for i, line in enumerate(self.content_lines):\n                if i == 0 and line:\n                    contents += \"\\n\" + self.indentation + line\n                elif line:\n                    contents += \"\\n\" + line\n                else:\n                    contents += \"\\n\"\n        else:\n            contents += self.pre_code + self.content\n\n        for _i, child in enumerate(self.children):\n            contents += child._to_string()\n\n        return contents", "kind": "Chunk", "id": "codeblocks/codeblocks.py#56.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock._build_path_tree_CodeBlock._build_path_tree.return.path_tree", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 248, "span_ids": ["CodeBlock._build_path_tree"], "start_line": 504, "end_line": 542, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def _build_path_tree(\r\n        self, block_paths: list[str], include_references: bool = False\r\n    ):\n        path_tree = PathTree()\n\n        for block_path in block_paths:\n            if block_path:\n                path = block_path.split(\".\")\n                if include_references:\n                    block = self.find_by_path(path)\n                    if block:\n                        if self.type == CodeBlockType.CLASS:\n                            references = [\r\n                                self._fix_reference_path(reference)\r\n                                for reference in self.get_all_relationships(\r\n                                    exclude_types=[\r\n                                        CodeBlockType.FUNCTION,\r\n                                        CodeBlockType.TEST_CASE,\r\n                                    ]\r\n                                )\r\n                                if reference\r\n                                and reference.scope != ReferenceScope.EXTERNAL\r\n                            ]  # FIXME skip _fix_reference_path?\r\n                        else:\n                            references = [\r\n                                self._fix_reference_path(reference)\r\n                                for reference in self.get_all_relationships()\r\n                                if reference\r\n                                and reference.scope != ReferenceScope.EXTERNAL\r\n                            ]  # FIXME skip _fix_reference_path?\r\n\n                        for ref in references:\n                            path_tree.add_to_tree(ref.path)\n\n                path_tree.add_to_tree(path)\n            elif block_path == \"\":\n                path_tree.show = True\n\n        return path_tree", "kind": "Chunk", "id": "codeblocks/codeblocks.py#57.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.to_tree_CodeBlock.to_tree.return.f_indent_str_indent_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 822, "span_ids": ["CodeBlock.to_tree"], "start_line": 544, "end_line": 653, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def to_tree(\r\n        self,\r\n        indent: int = 0,\r\n        current_span: BlockSpan | None = None,\r\n        highlight_spans: set[str] | None = None,\r\n        only_identifiers: bool = False,\r\n        show_full_path: bool = True,\r\n        show_tokens: bool = False,\r\n        show_spans: bool = False,\r\n        debug: bool = False,\r\n        exclude_not_highlighted: bool = False,\r\n        include_line_numbers: bool = False,\r\n        include_types: list[CodeBlockType] | None = None,\r\n        include_parameters: bool = False,\r\n        include_block_delimiters: bool = False,\r\n        include_references: bool = False,\r\n        include_merge_history: bool = False,\r\n    ):\n        if not include_merge_history and self.type == CodeBlockType.BLOCK_DELIMITER:\n            return \"\"\n\n        indent_str = \" \" * indent\n\n        highlighted = False\n\n        child_tree = \"\"\n        for _i, child in enumerate(self.children):\n            if child.belongs_to_span and (\r\n                not current_span\r\n                or current_span.span_id != child.belongs_to_span.span_id\r\n            ):\n                current_span = child.belongs_to_span\n\n                highlighted = highlight_spans is None or (\r\n                    current_span is not None and current_span.span_id in highlight_spans\r\n                )\n\n                if show_spans:\n                    color = Colors.WHITE if highlighted else Colors.GRAY\n                    child_tree += f\"{indent_str} {indent} {color}Span: {current_span}{Colors.RESET}\\n\"\n\n            if (\r\n                exclude_not_highlighted\r\n                and not highlighted\r\n                and not child.has_any_span(highlight_spans)\r\n            ):\n                continue\n\n            child_tree += child.to_tree(\r\n                indent=indent + 1,\r\n                current_span=current_span,\r\n                highlight_spans=highlight_spans,\r\n                exclude_not_highlighted=exclude_not_highlighted,\r\n                only_identifiers=only_identifiers,\r\n                show_full_path=show_full_path,\r\n                show_tokens=show_tokens,\r\n                debug=debug,\r\n                show_spans=show_spans,\r\n                include_line_numbers=include_line_numbers,\r\n                include_types=include_types,\r\n                include_parameters=include_parameters,\r\n                include_block_delimiters=include_block_delimiters,\r\n                include_references=include_references,\r\n                include_merge_history=include_merge_history,\r\n            )\n\n        is_visible = not highlight_spans or self.belongs_to_any_span(highlight_spans)\n        extra = \"\"\n        if show_tokens:\n            extra += f\" ({self.tokens} tokens)\"\n\n        if include_references and self.relationships:\n            extra += \" references: \" + \", \".join(\r\n                [str(ref) for ref in self.relationships]\r\n            )\n\n        content = (\r\n            Colors.YELLOW\r\n            if is_visible\r\n            else Colors.GRAY\r\n            + (self.content.strip().replace(\"\\n\", \"\\\\n\") or \"\")\r\n            + Colors.RESET\r\n        )\n\n        if self.identifier:\n            if only_identifiers:\n                content = \"\"\n            content += Colors.GREEN if is_visible else Colors.GRAY\n            if include_parameters and self.parameters:\n                content += f\"{self.identifier}({', '.join([param.identifier for param in self.parameters])})\"\n            elif show_full_path:\n                content += f\" ({self.path_string()})\"\n            else:\n                content += f\" ({self.identifier})\"\n\n            content += Colors.RESET\n\n        if include_line_numbers:\n            extra += f\" {self.start_line}-{self.end_line}\"\n\n        if debug and self.properties:\n            extra += f\" properties: {self.properties}\"\n\n        if include_merge_history and self.merge_history:\n            extra += \" merge_history: \" + \", \".join(\r\n                [str(action) for action in self.merge_history]\r\n            )\n\n        type_color = Colors.BLUE if is_visible else Colors.GRAY\n        return f\"{indent_str} {indent} {type_color}{self.type.value}{Colors.RESET} `{content}`{extra}{Colors.RESET}\\n{child_tree}\"", "kind": "Chunk", "id": "codeblocks/codeblocks.py#58.109"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock._to_prompt_string_CodeBlock._to_prompt_string.return.contents", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 329, "span_ids": ["CodeBlock._to_prompt_string"], "start_line": 655, "end_line": 697, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def _to_prompt_string(\r\n        self,\r\n        show_span_id: bool = False,\r\n        span_marker: SpanMarker = SpanMarker.COMMENT,\r\n        show_line_numbers: bool = False,\r\n    ) -> str:\n        contents = \"\"\n\n        if show_span_id:\n            contents += \"\\n\\n\"\n            if span_marker == SpanMarker.COMMENT:\n                span_comment = self.create_comment(\r\n                    f\"span_id: {self.belongs_to_span.span_id}\"\r\n                )\n                contents += f\"{self.indentation}{span_comment}\"\n            elif span_marker == SpanMarker.TAG:\n                contents += f\"\\n<span id='{self.belongs_to_span.span_id}'>\"\n\n            if not self.pre_lines:\n                contents += \"\\n\"\n\n        def print_line(line_number):\n            if not show_line_numbers:\n                return \"\"\n            return str(line_number).ljust(6)\n\n        # Just to write out the first line number when there are no pre_lines on first block\r\n        if self.parent.type == CodeBlockType.MODULE and self.parent.children[0] == self:\n            contents += print_line(self.start_line)\n\n        if self.pre_lines:\n            for i in range(self.pre_lines):\n                contents += \"\\n\"\n                contents += print_line(self.start_line - self.pre_lines + i + 1)\n\n        contents += self.indentation + self.content_lines[0]\n\n        for i, line in enumerate(self.content_lines[1:]):\n            contents += \"\\n\"\n            contents += print_line(self.start_line + i + 1)\n            contents += line\n\n        return contents", "kind": "Chunk", "id": "codeblocks/codeblocks.py#59.42"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.to_prompt_CodeBlock.to_prompt.return.contents", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 636, "span_ids": ["CodeBlock.to_prompt"], "start_line": 699, "end_line": 788, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def to_prompt(\r\n        self,\r\n        span_ids: set[str] | None = None,\r\n        start_line: Optional[int] = None,\r\n        end_line: Optional[int] = None,\r\n        show_outcommented_code: bool = True,\r\n        outcomment_code_comment: str = \"...\",\r\n        show_span_id: bool = False,\r\n        current_span_id: Optional[str] = None,\r\n        show_line_numbers: bool = False,\r\n        exclude_block_types: list[CodeBlockType] | None = None,\r\n        include_block_types: list[CodeBlockType] | None = None,\r\n    ):\n        contents = \"\"\n\n        has_outcommented_code = False\n        for _i, child in enumerate(self.children):\n            show_child = True\n\n            if exclude_block_types and child.type in exclude_block_types:\n                show_child = False\n\n            if show_child and span_ids:\n                show_child = child.has_any_span(span_ids)\n\n            if show_child and include_block_types:\n                show_child = child.has_blocks_with_types(include_block_types)\n\n            if show_child and start_line and end_line:\n                show_child = child.has_lines(\r\n                    start_line, end_line\r\n                ) or child.is_within_lines(start_line, end_line)\n\n            if show_child:\n                if has_outcommented_code:\n                    contents += child.create_commented_out_block(\r\n                        outcomment_code_comment\r\n                    ).to_string()\n\n                has_outcommented_code = False\n\n                show_new_span_id = (\r\n                    show_span_id\r\n                    and child.belongs_to_span\r\n                    and (\r\n                        not current_span_id\r\n                        or current_span_id != child.belongs_to_span.span_id\r\n                    )\r\n                )\n                if child.belongs_to_span:\n                    current_span_id = child.belongs_to_span.span_id\n\n                contents += child._to_prompt_string(\r\n                    show_span_id=show_new_span_id, show_line_numbers=show_line_numbers\r\n                )\n                contents += child.to_prompt(\r\n                    span_ids=span_ids,\r\n                    start_line=start_line,\r\n                    end_line=end_line,\r\n                    show_outcommented_code=show_outcommented_code,\r\n                    outcomment_code_comment=outcomment_code_comment,\r\n                    show_span_id=show_span_id,\r\n                    current_span_id=current_span_id,\r\n                    show_line_numbers=show_line_numbers,\r\n                    exclude_block_types=exclude_block_types,\r\n                    include_block_types=include_block_types,\r\n                )\n            elif show_outcommented_code and child.type not in [\r\n                CodeBlockType.COMMENT,\r\n                CodeBlockType.COMMENTED_OUT_CODE,\r\n            ]:\n                has_outcommented_code = True\n\n        if (\r\n            outcomment_code_comment\r\n            and has_outcommented_code\r\n            and child.type\r\n            not in [\r\n                CodeBlockType.COMMENT,\r\n                CodeBlockType.COMMENTED_OUT_CODE,\r\n                CodeBlockType.SPACE,\r\n            ]\r\n        ):\n            contents += \"\\n.    \" if show_line_numbers else \"\\n\"\n            contents += child.create_commented_out_block(\r\n                outcomment_code_comment\r\n            ).to_string()\n            contents += \"\\n\"\n\n        return contents", "kind": "Chunk", "id": "codeblocks/codeblocks.py#60.89"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.__eq___CodeBlock.find_type_group_in_parents.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 282, "span_ids": ["CodeBlock.structure_block", "CodeBlock.find_type_in_parents", "CodeBlock.find_block_by_type", "CodeBlock.find_type_group_in_parents", "CodeBlock.__eq__"], "start_line": 790, "end_line": 840, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def __eq__(self, other):\n        if not isinstance(other, CodeBlock):\n            return False\n\n        return self.full_path() == other.full_path()\n\n    def find_block_by_type(self, block_type: CodeBlockType) -> Optional[\"CodeBlock\"]:\n        if self.type == block_type:\n            return self\n\n        for child in self.children:\n            block = child.find_block_by_type(block_type)\n            if block:\n                return block\n\n        return None\n\n    def find_type_in_parents(self, block_type: CodeBlockType) -> Optional[\"CodeBlock\"]:\n        if not self.parent:\n            return None\n\n        if self.parent.type == block_type:\n            return self.parent\n\n        if self.parent:\n            return self.parent.find_type_in_parents(block_type)\n\n        return None\n\n    def structure_block(self):\n        if self.type.group == CodeBlockTypeGroup.STRUCTURE:\n            return self\n\n        if self.parent:\n            return self.parent.structure_block()\n\n        return None\n\n    def find_type_group_in_parents(\r\n        self, block_type_group: CodeBlockTypeGroup\r\n    ) -> Optional[\"CodeBlock\"]:\n        if not self.parent:\n            return None\n\n        if self.parent.type.group == block_type_group:\n            return self.parent\n\n        if self.parent:\n            return self.parent.find_type_group_in_parents(block_type_group)\n\n        return None", "kind": "Chunk", "id": "codeblocks/codeblocks.py#61.50"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_spans_by_line_numbers_CodeBlock.find_spans_by_line_numbers.return.spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 209, "span_ids": ["CodeBlock.find_spans_by_line_numbers"], "start_line": 842, "end_line": 874, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_spans_by_line_numbers(\r\n        self, start_line: int, end_line: int = None\r\n    ) -> list[BlockSpan]:\n        spans = []\n        for child in self.children:\n            if end_line is None:\n                end_line = start_line\n\n            if child.end_line < start_line:\n                continue\n\n            if child.start_line > end_line:\n                return spans\n\n            if (\r\n                child.belongs_to_span\r\n                and child.belongs_to_span.span_id not in spans\r\n                and (\r\n                    not child.children\r\n                    or child.start_line >= start_line\r\n                    and child.end_line <= end_line\r\n                    or child.start_line == start_line\r\n                    or child.end_line == end_line\r\n                )\r\n            ):\n                spans.append(child.belongs_to_span)\n\n            child_spans = child.find_spans_by_line_numbers(start_line, end_line)\n            for span in child_spans:\n                if span not in spans:\n                    spans.append(span)\n\n        return spans", "kind": "Chunk", "id": "codeblocks/codeblocks.py#62.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.dict_CodeBlock.get_blocks.return.blocks", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 245, "span_ids": ["CodeBlock.module", "CodeBlock.root", "CodeBlock.get_blocks", "CodeBlock.dict", "CodeBlock.full_path", "CodeBlock.path_string"], "start_line": 876, "end_line": 916, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def dict(self, **kwargs):\n        # TODO: Add **kwargs to dict call\r\n        return super().dict(exclude={\"parent\", \"merge_history\"})\n\n    def path_string(self):\n        return \".\".join(self.full_path())\n\n    def full_path(self):\n        path = []\n        if self.parent:\n            path.extend(self.parent.full_path())\n\n        if self.identifier:\n            path.append(self.identifier)\n\n        return path\n\n    @property\r\n    def module(self) -> \"Module\":  # noqa: F821\r\n        if self.parent:\n            return self.parent.module\n        return self\n\n    @deprecated(\"Use codeblock.module\")\r\n    def root(self) -> \"Module\":  # noqa: F821\r\n        return self.module\n\n    def get_blocks(\r\n        self, has_identifier: bool, include_types: list[CodeBlockType] | None = None\r\n    ) -> list[\"CodeBlock\"]:\n        blocks = [self]\n\n        for child in self.children:\n            if has_identifier and not child.identifier:\n                continue\n\n            if include_types and child.type not in include_types:\n                continue\n\n            blocks.extend(child.get_indexable_blocks())\n        return blocks", "kind": "Chunk", "id": "codeblocks/codeblocks.py#63.40"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_reference_CodeBlock.find_reference.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 194, "span_ids": ["CodeBlock.find_reference"], "start_line": 918, "end_line": 943, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_reference(self, ref_path: [str]) -> Relationship | None:\n        for child in self.children:\n            if child.type == CodeBlockType.IMPORT:\n                for reference in child.relationships:\n                    if (\r\n                        reference.path[len(reference.path) - len(ref_path) :]\r\n                        == ref_path\r\n                    ):\n                        return reference\n\n            child_path = child.full_path()\n\n            if child_path[len(child_path) - len(ref_path) :] == ref_path:\n                if self.type == CodeBlockType.CLASS:\n                    return Relationship(scope=ReferenceScope.CLASS, path=child_path)\n                if self.type == CodeBlockType.MODULE:\n                    return Relationship(scope=ReferenceScope.GLOBAL, path=child_path)\n\n                return Relationship(scope=ReferenceScope.LOCAL, path=child_path)\n\n        if self.parent:\n            reference = self.parent.find_reference(ref_path)\n            if reference:\n                return reference\n\n        return None", "kind": "Chunk", "id": "codeblocks/codeblocks.py#64.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.get_all_relationships_CodeBlock.find_blocks_by_span_id.return.blocks", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 681, "span_ids": ["CodeBlock.find_blocks_by_span_id", "CodeBlock.find_validation_errors", "CodeBlock.create_comment", "CodeBlock.create_comment_block", "CodeBlock.is_complete", "CodeBlock.get_all_relationships", "CodeBlock.find_by_path", "CodeBlock.create_commented_out_block", "CodeBlock.add_indentation", "CodeBlock.find_errors"], "start_line": 945, "end_line": 1049, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def get_all_relationships(\r\n        self, exclude_types: list[CodeBlockType] = None\r\n    ) -> list[Relationship]:\n        if exclude_types is None:\n            exclude_types = []\n        references = []\n        references.extend(self.relationships)\n        for childblock in self.children:\n            if not exclude_types or childblock.type not in exclude_types:\n                references.extend(\r\n                    childblock.get_all_relationships(exclude_types=exclude_types)\r\n                )\n\n        return references\n\n    def is_complete(self):\n        if self.type == CodeBlockType.COMMENTED_OUT_CODE:\n            return False\n        return all(child.is_complete() for child in self.children)\n\n    def find_errors(self) -> list[\"CodeBlock\"]:\n        errors = []\n\n        if self.children:\n            for child in self.children:\n                errors.extend(child.find_errors())\n\n        if self.type == CodeBlockType.ERROR:\n            errors.append(self)\n\n        return errors\n\n    def find_validation_errors(self) -> list[ValidationError]:\n        errors = []\n        errors.extend(self.validation_errors)\n\n        for child in self.children:\n            errors.extend(child.find_validation_errors())\n\n        return errors\n\n    def create_commented_out_block(self, comment_out_str: str = \"...\"):\n        return CodeBlock(\r\n            type=CodeBlockType.COMMENTED_OUT_CODE,\r\n            indentation=self.indentation,\r\n            parent=self,\r\n            pre_lines=1,\r\n            content=self.create_comment(comment_out_str),\r\n        )\n\n    def create_comment_block(self, comment: str = \"...\", pre_lines: int = 1):\n        return CodeBlock(\r\n            type=CodeBlockType.COMMENT,\r\n            indentation=self.indentation,\r\n            parent=self,\r\n            pre_lines=pre_lines,\r\n            content=self.create_comment(comment),\r\n        )\n\n    def create_comment(self, comment: str) -> str:\n        symbol = get_comment_symbol(\"python\")  # FIXME: Derive language from Module\r\n        return f\"{symbol} {comment}\"\n\n    def add_indentation(self, indentation: str):\n        if self.pre_lines:\n            self.indentation += indentation\n\n        # TODO: Find a more graceful way to solve multi line blocks\r\n        if \"\\n\" in self.content:\n            lines = self.content.split(\"\\n\")\n            content = lines[0]\n            for line in lines[1:]:\n                if line.startswith(\" \"):\n                    content += \"\\n\" + indentation + line\n            self.content = content\n\n        for child in self.children:\n            child.add_indentation(indentation)\n\n    def find_by_path(self, path: list[str]) -> Optional[\"CodeBlock\"]:\n        if path is None:\n            return None\n\n        if not path:\n            return self\n\n        for child in self.children:\n            if child.identifier == path[0]:\n                if len(path) == 1:\n                    return child\n                else:\n                    return child.find_by_path(path[1:])\n\n        return None\n\n    def find_blocks_by_span_id(self, span_id: str) -> list[\"CodeBlock\"]:\n        blocks = []\n        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:\n            blocks.append(self)\n\n        for child in self.children:\r\n            # TODO: Optimize to just check relevant children (by mapping spans?\r\n            blocks.extend(child.find_blocks_by_span_id(span_id))\n\n        return blocks", "kind": "Chunk", "id": "codeblocks/codeblocks.py#65.104"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_last_before_span_CodeBlock.find_last_before_span.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 150, "span_ids": ["CodeBlock.find_last_before_span"], "start_line": 1051, "end_line": 1068, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_last_before_span(\r\n        self, span_id: str, last_before_span: Optional[\"CodeBlock\"] = None\r\n    ) -> Optional[\"CodeBlock\"]:\n        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:\n            return last_before_span\n\n        for child in self.children:\n            if child.belongs_to_span and child.belongs_to_span.span_id == span_id:\n                return last_before_span\n\n            if child.belongs_to_span and child.belongs_to_span.span_id != span_id:\n                last_before_span = child\n\n            result = child.find_last_before_span(span_id, last_before_span)\n            if result:\n                return result\n\n        return None", "kind": "Chunk", "id": "codeblocks/codeblocks.py#66.17"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_first_by_span_id_CodeBlock.find_first_by_start_line.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 718, "span_ids": ["CodeBlock.find_by_identifier", "CodeBlock.find_incomplete_blocks_with_type", "CodeBlock.find_blocks_with_types", "CodeBlock.find_first_by_start_line", "CodeBlock.has_blocks_with_types", "CodeBlock.find_blocks_with_type", "CodeBlock.has_any_block", "CodeBlock.find_first_by_span_id", "CodeBlock.find_incomplete_blocks_with_types", "CodeBlock.find_blocks_with_identifier", "CodeBlock.find_last_by_span_id"], "start_line": 1070, "end_line": 1174, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_first_by_span_id(self, span_id: str) -> Optional[\"CodeBlock\"]:\n        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:\n            return self\n\n        for child in self.children:\n            found = child.find_first_by_span_id(span_id)\n            if found:\n                return found\n\n        return None\n\n    def find_last_by_span_id(self, span_id: str) -> Optional[\"CodeBlock\"]:\n        for child in reversed(self.children):\n            if child.belongs_to_span and child.belongs_to_span.span_id == span_id:\n                return child\n\n            found = child.find_last_by_span_id(span_id)\n            if found:\n                return found\n\n        return None\n\n    def has_any_block(self, blocks: list[\"CodeBlock\"]) -> bool:\n        for block in blocks:\n            if block.full_path()[: len(self.full_path())] == self.full_path():\n                return True\n        return False\n\n    def find_by_identifier(\r\n        self,\r\n        identifier: str,\r\n        type: CodeBlockType | None = None,\r\n        recursive: bool = False,\r\n    ):\n        for child in self.children:\n            if child.identifier == identifier and (not type or child.type == type):\n                return child\n\n            if recursive:\n                found = child.find_by_identifier(identifier, type, recursive)\n                if found:\n                    return found\n        return None\n\n    def find_blocks_with_identifier(self, identifier: str) -> list[\"CodeBlock\"]:\n        blocks = []\n        for child_block in self.children:\n            if child_block.identifier == identifier:\n                blocks.append(child_block)\n            blocks.extend(child_block.find_blocks_with_identifier(identifier))\n        return blocks\n\n    def find_incomplete_blocks_with_type(self, block_type: CodeBlockType):\n        return self.find_incomplete_blocks_with_types([block_type])\n\n    def find_incomplete_blocks_with_types(self, block_types: [CodeBlockType]):\n        matching_blocks = []\n        for child_block in self.children:\n            if child_block.type in block_types and not child_block.is_complete():\n                matching_blocks.append(child_block)\n\n            if child_block.children:\n                matching_blocks.extend(\r\n                    child_block.find_incomplete_blocks_with_types(block_types)\r\n                )\n\n        return matching_blocks\n\n    def find_blocks_with_types(\r\n        self, block_types: list[CodeBlockType]\r\n    ) -> list[\"CodeBlock\"]:\n        matching_blocks = []\n        if self.type in block_types:\n            matching_blocks.append(self)\n        for child_block in self.children:\n            matching_blocks.extend(\r\n                child_block.find_blocks_with_types(block_types=block_types)\r\n            )\n        return matching_blocks\n\n    def has_blocks_with_types(self, block_types: list[CodeBlockType]) -> bool:\n        if self.type in block_types:\n            return True\n        for child_block in self.children:\n            if child_block.has_blocks_with_types(block_types):\n                return True\n        return False\n\n    def find_blocks_with_type(self, block_type: CodeBlockType) -> list[\"CodeBlock\"]:\n        return self.find_blocks_with_types([block_type])\n\n    def find_first_by_start_line(self, start_line: int) -> Optional[\"CodeBlock\"]:\n        for child in self.children:\n            if child.start_line >= start_line:\n                return child\n\n            if child.end_line >= start_line:\n                if not child.children:\n                    return child\n\n                found = child.find_first_by_start_line(start_line)\n                if found:\n                    return found\n\n        return None", "kind": "Chunk", "id": "codeblocks/codeblocks.py#67.104"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_last_by_end_line_CodeBlock.find_last_by_end_line.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 125, "span_ids": ["CodeBlock.find_last_by_end_line"], "start_line": 1176, "end_line": 1194, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_last_by_end_line(\r\n        self, end_line: int, tokens: Optional[int] = None\r\n    ) -> Optional[\"CodeBlock\"]:\n        last_child = None\n        for child in self.children:\n            if child.start_line > end_line or (tokens and child.tokens > tokens):\n                return last_child\n\n            if tokens:\n                tokens -= child.tokens\n\n            last_child = child\n\n            if child.end_line > end_line:\n                found = child.find_last_by_end_line(end_line, tokens=tokens)\n                if found:\n                    return found\n\n        return None", "kind": "Chunk", "id": "codeblocks/codeblocks.py#68.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.find_closest_indexed_parent_CodeBlock.get_indexed_blocks.return.blocks", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 150, "span_ids": ["CodeBlock.get_indexed_blocks", "CodeBlock.find_indexed_blocks", "CodeBlock.find_closest_indexed_parent"], "start_line": 1196, "end_line": 1221, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def find_closest_indexed_parent(self) -> Optional[\"CodeBlock\"]:\n        if self.is_indexed:\n            return self\n\n        if self.parent:\n            return self.parent.find_closest_indexed_parent()\n\n        return None\n\n    def find_indexed_blocks(self):\n        indexed_blocks = []\n        for child in self.children:\n            if child.is_indexed:\n                indexed_blocks.append(child)\n            indexed_blocks.extend(child.find_indexed_blocks())\n        return indexed_blocks\n\n    def get_indexed_blocks(self) -> list[\"CodeBlock\"]:\n        blocks = []\n        for child in self.children:\n            if child.is_indexed:\n                blocks.append(child)\n\n            blocks.extend(child.get_indexed_blocks())\n\n        return blocks", "kind": "Chunk", "id": "codeblocks/codeblocks.py#69.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.line_witin_token_context_CodeBlock.tokens_from_line.return.self_tokens_self_previo", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 194, "span_ids": ["CodeBlock.line_witin_token_context", "CodeBlock.tokens_from_line"], "start_line": 1223, "end_line": 1250, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def line_witin_token_context(self, line_number: int, tokens: int) -> bool:\n        if tokens <= 0:\n            return False\n\n        if self.end_line < line_number:\n            if not self.next:\n                return False\n            if self.next.start_line > line_number:\n                return True\n            else:\n                return self.next.line_witin_token_context(\r\n                    line_number, tokens - self.tokens\r\n                )\n        else:\n            if not self.previous:\n                return False\n            elif self.previous.end_line < line_number:\n                return True\n            else:\n                return self.previous.line_witin_token_context(\r\n                    line_number, tokens - self.tokens\r\n                )\n\n    def tokens_from_line(self, line_number: int) -> Optional[int]:\n        if not self.previous or self.previous.end_line < line_number:\n            return self.tokens\n\n        return self.tokens + self.previous.tokens_from_line(line_number)", "kind": "Chunk", "id": "codeblocks/codeblocks.py#70.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.last_block_until_line_CodeBlock.last_block_until_line.if_self_end_line_line_n.else_.if_.else_.return.self_previous_last_block_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 150, "span_ids": ["CodeBlock.last_block_until_line"], "start_line": 1252, "end_line": 1274, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def last_block_until_line(self, line_number: int, tokens: int) -> \"CodeBlock\":\n        if self.end_line < line_number:\n            if (\r\n                not self.next\r\n                or self.next.start_line > line_number\r\n                or self.next.tokens > tokens\r\n            ):\n                return self\n            else:\n                return self.next.last_block_until_line(\r\n                    line_number, tokens - self.tokens\r\n                )\n        else:\n            if (\r\n                not self.previous\r\n                or self.previous.end_line < line_number\r\n                or self.next.tokens > tokens\r\n            ):\n                return self\n            else:\n                return self.previous.last_block_until_line(\r\n                    line_number, tokens - self.tokens\r\n                )", "kind": "Chunk", "id": "codeblocks/codeblocks.py#71.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py_CodeBlock.get_all_span_ids_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\codeblocks.py", "file_name": "codeblocks.py", "file_type": "text/x-python", "category": "test", "tokens": 360, "span_ids": ["CodeBlock.belongs_to_any_span", "CodeBlock.has_span", "CodeBlock.has_lines", "CodeBlock.has_any_span", "CodeBlock.has_content", "CodeBlock.is_within_lines", "CodeBlock.get_all_span_ids"], "start_line": 1276, "end_line": 1319, "community": null}, "content": "class CodeBlock(BaseModel):\n\n    def get_all_span_ids(self, include_self: bool = True) -> set[str]:\n        span_ids = set()\n\n        if include_self and self.belongs_to_span:\n            span_ids.add(self.belongs_to_span.span_id)\n\n        for child in self.children:\n            span_ids.update(child.get_all_span_ids())\n\n        return span_ids\n\n    def has_span(self, span_id: str):\n        return self.has_any_span({span_id})\n\n    def has_any_span(self, span_ids: set[str]):\n        all_span_ids = self.get_all_span_ids(include_self=False)\n        return any([span_id in all_span_ids for span_id in span_ids])\n\n    def belongs_to_any_span(self, span_ids: set[str]):\n        return self.belongs_to_span and self.belongs_to_span.span_id in span_ids\n\n    def has_lines(self, start_line: int, end_line: int):\n        # Returns True if any part of the block is within the provided line range\r\n        return not (self.end_line < start_line or self.start_line > end_line)\n\n    def is_within_lines(self, start_line: int, end_line: int):\n        return self.start_line >= start_line and self.end_line <= end_line\n\n    def has_content(self, query: str, span_id: Optional[str] = None):\n        if (\r\n            self.content\r\n            and query in self.content\r\n            and (\r\n                not span_id\r\n                or (self.belongs_to_span and self.belongs_to_span.span_id == span_id)\r\n            )\r\n        ):\n            return True\n\n        if span_id and not self.has_span(span_id):\n            return False\n\n        return any(child.has_content(query, span_id) for child in self.children)", "kind": "Chunk", "id": "codeblocks/codeblocks.py#72.43"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py_logging_Module.sum_tokens.return.tokens", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py", "file_name": "module.py", "file_type": "text/x-python", "category": "test", "tokens": 286, "span_ids": ["Module.__init__", "Module", "Module.find_span_by_id", "imports", "Module.sum_tokens"], "start_line": 1, "end_line": 43, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom networkx import DiGraph\nfrom pydantic import (\r\n    ConfigDict,\r\n)\n\nfrom moatless.codeblocks import CodeBlock, CodeBlockType\nfrom moatless.codeblocks.codeblocks import BlockSpan, SpanType\n\nlogger = logging.getLogger(__name__)\n\n\nclass Module(CodeBlock):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    file_path: Optional[str] = None\n    content: str = None\n    spans_by_id: dict[str, BlockSpan] = {}\n    language: Optional[str] = None\n    parent: CodeBlock | None = None\n\n    _graph: DiGraph = None  # TODO: Move to central CodeGraph\r\n\n    def __init__(self, **data):\n        data.setdefault(\"type\", CodeBlockType.MODULE)\n        super().__init__(**data)\n\n    def find_span_by_id(self, span_id: str) -> BlockSpan | None:\n        return self.spans_by_id.get(span_id)\n\n    def sum_tokens(self, span_ids: set[str] | None = None):\n        tokens = self.tokens\n        if span_ids:\n            for span_id in span_ids:\n                span = self.spans_by_id.get(span_id)\n                if span:\n                    tokens += span.tokens\n            return tokens\n\n        tokens += sum([child.sum_tokens() for child in self.children])\n        return tokens", "kind": "Chunk", "id": "codeblocks/module.py#73.42"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py_Module.show_spans_Module.show_spans.return.True", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py", "file_name": "module.py", "file_type": "text/x-python", "category": "test", "tokens": 400, "span_ids": ["Module.show_spans"], "start_line": 45, "end_line": 103, "community": null}, "content": "class Module(CodeBlock):\n\n    def show_spans(\r\n        self,\r\n        span_ids: list[str] | None = None,\r\n        show_related: bool = False,\r\n        max_tokens: int = 2000,\r\n    ) -> bool:\n        for span in self.spans_by_id.values():\n            span.visible = False\n\n        checked_span_ids = set()\n        span_ids_to_check = []\n\n        tokens = 0\n        for span_id in span_ids:\n            span = self.spans_by_id.get(span_id)\n            if not span:\n                return False\n\n            tokens += span.tokens\n            checked_span_ids.add(span_id)\n            span_ids_to_check.append(span_id)\n            span.visible = True\n\n        if not show_related:\n            return True\n\n        # Add imports from module\r\n        for span in self.spans.values():\n            if (\r\n                span.span_type == SpanType.INITATION\r\n                and span.span_id not in checked_span_ids\r\n            ):\n                span_ids_to_check.append(span.span_id)\n\n        while span_ids_to_check:\n            span_id = span_ids_to_check.pop(0)\n            related_spans = self.find_related_spans(span_id)\n\n            logger.info(f\"Related spans: {len(related_spans)} for {span_id}\")\n\n            # TODO: Go through priotiized related spans to make sure that the most relevant are added first\r\n            # TODO: Verify span token size\r\n            for span in related_spans:\n                if span.tokens + tokens > max_tokens:\n                    logger.info(\r\n                        f\"Max tokens reached: {span.tokens} + {tokens} > {max_tokens}\"\r\n                    )\n                    return True\n\n                span.visible = True\n                tokens += span.tokens\n\n                if span.span_id not in checked_span_ids:\n                    checked_span_ids.add(span.span_id)\n                    span_ids_to_check.append(span.span_id)\n\n        logger.info(f\"Max tokens reached {tokens} < {max_tokens}\")\n\n        return True", "kind": "Chunk", "id": "codeblocks/module.py#74.58"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py_Module.find_related_span_ids_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\module.py", "file_name": "module.py", "file_type": "text/x-python", "category": "test", "tokens": 328, "span_ids": ["Module.find_related_span_ids"], "start_line": 105, "end_line": 142, "community": null}, "content": "class Module(CodeBlock):\n\n    def find_related_span_ids(self, span_id: Optional[str] = None) -> set[str]:\n        related_span_ids = set()\n\n        blocks = self.find_blocks_by_span_id(span_id)\n        for block in blocks:\r\n            # Find successors (outgoing relationships)\r\n            successors = list(self._graph.successors(block.path_string()))\n            for succ in successors:\n                node_data = self._graph.nodes[succ]\n                if \"block\" in node_data:\n                    span = node_data[\"block\"].belongs_to_span\n                    related_span_ids.add(span.span_id)\n\n            # Find predecessors (incoming relationships)\r\n            predecessors = list(self._graph.predecessors(block.path_string()))\n            for pred in predecessors:\n                node_data = self._graph.nodes[pred]\n                if \"block\" in node_data:\n                    span = node_data[\"block\"].belongs_to_span\n                    related_span_ids.add(span.span_id)\n\n            # Always add parent class initation span\r\n            if block.parent and block.parent.type == CodeBlockType.CLASS:\n                related_span_ids.add(block.belongs_to_span.span_id)\n                for class_child in block.parent.children:\n                    if class_child.belongs_to_span.span_type == SpanType.INITATION:\n                        related_span_ids.add(class_child.belongs_to_span.span_id)\n\n        # Always add module initation span\r\n        for span in self.spans_by_id.values():\n            if (\r\n                span.block_type == CodeBlockType.MODULE\r\n                and span.span_type == SpanType.INITATION\r\n            ):\n                related_span_ids.add(span.span_id)\n\n        return related_span_ids", "kind": "Chunk", "id": "codeblocks/module.py#75.37"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\comment.py_comment_symbols_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\comment.py", "file_name": "comment.py", "file_type": "text/x-python", "category": "test", "tokens": 533, "span_ids": ["get_comment_symbol", "impl"], "start_line": 1, "end_line": 79, "community": null}, "content": "comment_symbols = {\r\n    \"ada\": \"--\",\r\n    \"agda\": \"--\",\r\n    \"apex\": \"//\",\r\n    \"bash\": \"#\",\r\n    \"beancount\": \";\",\r\n    \"cap\u2019n proto\": \"#\",\r\n    \"c\": \"//\",\r\n    \"c++\": \"//\",\r\n    \"c#\": \"//\",\r\n    \"clojure\": \";\",\r\n    \"cmake\": \"#\",\r\n    \"common lisp\": \";\",\r\n    \"css\": \"/* \",  # TDOO ... */\r\n    \"cuda\": \"//\",\r\n    \"dart\": \"//\",\r\n    \"d\": \"//\",\r\n    \"dockerfile\": \"#\",\r\n    \"dot\": \"//\",\r\n    \"elixir\": \"#\",\r\n    \"elm\": \"--\",\r\n    \"emacs lisp\": \";\",\r\n    \"erb / ejs\": \"<%# ... %>\",\r\n    \"erlang\": \"%\",\r\n    \"fish\": \"#\",\r\n    \"fortran\": \"!\",\r\n    \"gitattributes\": \"#\",\r\n    \"gitignore\": \"#\",\r\n    \"gleam\": \"//\",\r\n    \"go\": \"//\",\r\n    \"graphql\": \"#\",\r\n    \"haskell\": \"--\",\r\n    \"html\": \"<!--\",  # TODO:  ... -->\r\n    \"java\": \"//\",\r\n    \"javascript\": \"//\",\r\n    \"json5\": \"//\",\r\n    \"julia\": \"#\",\r\n    \"kotlin\": \"//\",\r\n    \"latex\": \"%\",\r\n    \"lua\": \"--\",\r\n    \"make\": \"#\",\r\n    \"motorola 68000 assembly\": \";\",\r\n    \"nix\": \"#\",\r\n    \"objective-c\": \"//\",\r\n    \"ocaml\": \"(*\",  # TODO ... *)\r\n    \"pascal\": \"{\",  # TODO ... }\r\n    \"perl\": \"#\",\r\n    \"php\": \"//\",\r\n    \"powershell\": \"#\",\r\n    \"protocol buffers\": \"//\",\r\n    \"python\": \"#\",\r\n    \"racket\": \";\",\r\n    \"rego\": \"#\",\r\n    \"restructuredtext\": \"..\",\r\n    \"r\": \"#\",\r\n    \"ruby\": \"#\",\r\n    \"rust\": \"//\",\r\n    \"scala\": \"//\",\r\n    \"scheme\": \";\",\r\n    \"scss\": \"//\",\r\n    \"s-expressions\": \";\",\r\n    \"sql\": \"--\",\r\n    \"swift\": \"//\",\r\n    \"toml\": \"#\",\r\n    \"typescript\": \"//\",\r\n    \"tsx\": \"//\",\r\n    \"verilog\": \"//\",\r\n    \"vhdl\": \"--\",\r\n    \"vue\": \"<!-- \",  # TODO ... -->\r\n    \"yaml\": \"#\",\r\n    \"zig\": \"//\",\r\n}\n\n\ndef get_comment_symbol(language):\n    if language:\n        return comment_symbols.get(language.lower(), None)\n    return \"#\"", "kind": "Chunk", "id": "parser/comment.py#76.78"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\create.py_from_moatless_codeblocks__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\create.py", "file_name": "create.py", "file_type": "text/x-python", "category": "test", "tokens": 176, "span_ids": ["imports", "is_supported", "create_parser_by_ext", "create_parser"], "start_line": 1, "end_line": 26, "community": null}, "content": "from moatless.codeblocks.parser.parser import CodeParser\nfrom moatless.codeblocks.parser.python import PythonParser\nfrom moatless.codeblocks.parser.java import JavaParser\n\n\ndef is_supported(language: str) -> bool:\n    return language and language in [\"python\", \"java\"]\n\n\ndef create_parser_by_ext(ext: str, **kwargs) -> CodeParser | None:\n    if ext == \".py\":\n        return PythonParser(**kwargs)\n    elif ext == \".java\":\n        return JavaParser(**kwargs)\n\n    raise NotImplementedError(f\"Extension {ext} is not supported.\")\n\n\ndef create_parser(language: str, **kwargs) -> CodeParser | None:\n    if language == \"python\":\n        return PythonParser(**kwargs)\n    elif language == \"java\":\n        return JavaParser(**kwargs)\n\n    raise NotImplementedError(f\"Language {language} is not supported.\")", "kind": "Chunk", "id": "parser/create.py#77.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\java.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\java.py", "file_name": "java.py", "file_type": "text/x-python", "category": "test", "tokens": 82, "span_ids": ["JavaParser", "imports", "JavaParser.__init__"], "start_line": 1, "end_line": 13, "community": null}, "content": "import tree_sitter_java as java\nfrom tree_sitter import Language\n\nfrom moatless.codeblocks.parser.parser import CodeParser\n\n\nclass JavaParser(CodeParser):\n    def __init__(self, **kwargs):\n        super().__init__(Language(java.language()), **kwargs)\n        self.queries = []\n        self.queries.extend(self._build_queries(\"java.scm\"))\n        self.gpt_queries = []", "kind": "Chunk", "id": "parser/java.py#78.12"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_logging_find_nested_type.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 420, "span_ids": ["find_type", "find_nested_type", "_find_type", "NodeMatch", "imports"], "start_line": 1, "end_line": 68, "community": null}, "content": "import logging\nimport re\nfrom collections.abc import Callable\nfrom dataclasses import dataclass, field\nfrom importlib import resources\nfrom typing import Optional\n\nimport networkx as nx\nfrom llama_index.core import get_tokenizer\nfrom tree_sitter import Language, Node, Parser\n\nfrom moatless.codeblocks.codeblocks import (\r\n    BlockSpan,\r\n    CodeBlock,\r\n    CodeBlockType,\r\n    CodeBlockTypeGroup,\r\n    Parameter,\r\n    ReferenceScope,\r\n    Relationship,\r\n    RelationshipType,\r\n    SpanType,\r\n)\nfrom moatless.codeblocks.module import Module\nfrom moatless.codeblocks.parser.comment import get_comment_symbol\n\ncommented_out_keywords = [\"rest of the code\", \"existing code\", \"other code\"]\nchild_block_types = [\"ERROR\", \"block\"]\nmodule_types = [\"program\", \"module\"]\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\r\nclass NodeMatch:\n    block_type: CodeBlockType = None\n    identifier_node: Node = None\n    first_child: Node = None\n    last_child: Node = None\n    check_child: Node = None\n    parameters: list[tuple[Node, Node | None]] = field(default_factory=list)\n    relationships: list[tuple[Node, str]] = field(default_factory=list)\n    query: str = None\n\n\ndef _find_type(node: Node, type: str):\n    for i, child in enumerate(node.children):\n        if child.type == type:\n            return i, child\n    return None, None\n\n\ndef find_type(node: Node, types: list[str]):\n    for child in node.children:\n        if child.type in types:\n            return child\n    return None\n\n\ndef find_nested_type(node: Node, type: str, levels: int = -1):\n    if levels == 0:\n        return None\n    if node.type == type:\n        return node\n    for child in node.children:\n        found_node = find_nested_type(child, type, levels - 1)\n        if found_node:\n            return found_node\n    return None", "kind": "Chunk", "id": "parser/parser.py#79.67"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser_CodeParser._extract_node_type.if_match_.else_.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 363, "span_ids": ["CodeParser.language", "CodeParser", "CodeParser.__init__", "CodeParser._extract_node_type"], "start_line": 71, "end_line": 120, "community": null}, "content": "class CodeParser:\n    def __init__(\r\n        self,\r\n        language: Language,\r\n        encoding: str = \"utf8\",\r\n        max_tokens_in_span: int = 500,\r\n        min_tokens_for_docs_span: int = 100,\r\n        index_callback: Callable[[CodeBlock], None] | None = None,\r\n        tokenizer: Callable[[str], list] | None = None,\r\n        apply_gpt_tweaks: bool = False,\r\n        debug: bool = False,\r\n    ):\n        try:\n            self.tree_parser = Parser()\n            self.tree_parser.language = language\n            self.tree_language = language\n        except Exception as e:\n            logger.warning(f\"Could not get parser for language {language}.\")\n            raise e\n        self.apply_gpt_tweaks = apply_gpt_tweaks\n        self.index_callback = index_callback\n        self.debug = debug\n        self.encoding = encoding\n        self.gpt_queries = []\n        self.queries = []\n\n        # TODO: How to handle these in a thread safe way?\r\n        self.spans_by_id = {}\n        self.comments_with_no_span = []\n        self._span_counter = {}\n        self._previous_block = None\n\n        # TODO: Move this to CodeGraph\r\n        self._graph = None\n\n        self.tokenizer = tokenizer or get_tokenizer()\n        self._max_tokens_in_span = max_tokens_in_span\n        self._min_tokens_for_docs_span = min_tokens_for_docs_span\n\n    @property\r\n    def language(self):\n        pass\n\n    def _extract_node_type(self, query: str):\n        pattern = r\"\\(\\s*(\\w+)\"\n        match = re.search(pattern, query)\n        if match:\n            return match.group(1)\n        else:\n            return None", "kind": "Chunk", "id": "parser/parser.py#80.49"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser._build_queries_CodeParser._build_queries.with_.return.parsed_queries", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 154, "span_ids": ["CodeParser._build_queries"], "start_line": 122, "end_line": 143, "community": null}, "content": "class CodeParser:\n\n    def _build_queries(self, query_file: str):\n        with (\r\n            resources.files(\"moatless.codeblocks.parser.queries\")\r\n            .joinpath(query_file)\r\n            .open() as file\r\n        ):\n            query_list = file.read().strip().split(\"\\n\\n\")\n            parsed_queries = []\n            for i, query in enumerate(query_list):\n                try:\n                    node_type = self._extract_node_type(query)\n                    parsed_queries.append(\r\n                        (\r\n                            f\"{query_file}:{i+1}\",\r\n                            node_type,\r\n                            self.tree_language.query(query),\r\n                        )\r\n                    )\n                except Exception as e:\n                    logging.error(f\"Could not parse query {query}:{i+1}\")\n                    raise e\n            return parsed_queries", "kind": "Chunk", "id": "parser/parser.py#81.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.parse_code_CodeParser.parse_code.parameters.self_create_parameters_co", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 308, "span_ids": ["CodeParser.parse_code"], "start_line": 145, "end_line": 183, "community": null}, "content": "class CodeParser:\n\n    def parse_code(\r\n        self,\r\n        content_bytes: bytes,\r\n        node: Node,\r\n        start_byte: int = 0,\r\n        level: int = 0,\r\n        file_path: Optional[str] = None,\r\n        parent_block: CodeBlock | None = None,\r\n        current_span: BlockSpan | None = None,\r\n    ) -> tuple[CodeBlock, Node, BlockSpan]:\n        if node.type == \"ERROR\" or any(\r\n            child.type == \"ERROR\" for child in node.children\r\n        ):\n            node_match = NodeMatch(block_type=CodeBlockType.ERROR)\n            self.debug_log(f\"Found error node {node.type}\")\n        else:\n            node_match = self.find_in_tree(node)\n\n        pre_code = content_bytes[start_byte : node.start_byte].decode(self.encoding)\n        end_line = node.end_point[0]\n\n        if node_match.first_child:\n            end_byte = self.get_previous(node_match.first_child, node)\n        else:\n            end_byte = node.end_byte\n\n        code = content_bytes[node.start_byte : end_byte].decode(self.encoding)\n\n        if node_match.identifier_node:\n            identifier = content_bytes[\r\n                node_match.identifier_node.start_byte : node_match.identifier_node.end_byte\r\n            ].decode(self.encoding)\n        else:\n            identifier = None\n\n        relationships = self.create_references(\r\n            code, content_bytes, identifier, node_match\r\n        )\n        parameters = self.create_parameters(content_bytes, node_match, relationships)\n        # ... other code", "kind": "Chunk", "id": "parser/parser.py#82.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.parse_code.if_parent_block__CodeParser.parse_code.next_node.node_match_first_child", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 812, "span_ids": ["CodeParser.parse_code"], "start_line": 185, "end_line": 291, "community": null}, "content": "class CodeParser:\n\n    def parse_code(\r\n        self,\r\n        content_bytes: bytes,\r\n        node: Node,\r\n        start_byte: int = 0,\r\n        level: int = 0,\r\n        file_path: Optional[str] = None,\r\n        parent_block: CodeBlock | None = None,\r\n        current_span: BlockSpan | None = None,\r\n    ) -> tuple[CodeBlock, Node, BlockSpan]:\n        # ... other code\n\n        if parent_block:\n            code_block = CodeBlock(\r\n                type=node_match.block_type,\r\n                identifier=identifier,\r\n                parent=parent_block,\r\n                previous=self._previous_block,\r\n                parameters=parameters,\r\n                relationships=relationships,\r\n                span_ids=set(),\r\n                start_line=node.start_point[0] + 1,\r\n                end_line=end_line + 1,\r\n                pre_code=pre_code,\r\n                content=code,\r\n                language=self.language,\r\n                tokens=self._count_tokens(code),\r\n                children=[],\r\n                properties={\r\n                    \"query\": node_match.query,\r\n                    \"tree_sitter_type\": node.type,\r\n                },\r\n            )\n\n            self._previous_block.next = code_block\n            self._previous_block = code_block\n\n            self.pre_process(code_block, node_match)\n\n            if code_block.identifier:\n                identifier = code_block.identifier\n            else:\n                if code_block.content:\n                    identifier = code_block.content.split(\"\\n\")[0].strip()[0:25]\n                    identifier = re.sub(r\"\\W+\", \"_\", identifier)\n                else:\n                    identifier = code_block.type.value.lower()\n\n            # Set a unique identifier on each code block\r\n            # TODO: Just count occurrences of the identifier\r\n            existing_identifiers = [\r\n                b.identifier for b in parent_block.children if b.type == code_block.type\r\n            ]\n            if identifier in existing_identifiers:\n                code_block.identifier = (\r\n                    f\"{code_block.identifier}_{len(existing_identifiers)}\"\r\n                )\n            else:\n                code_block.identifier = identifier\n\n            if (\r\n                code_block.type == CodeBlockType.COMMENT\r\n                and current_span\r\n                and current_span.span_type != SpanType.DOCUMENTATION\r\n                and len(current_span.block_paths) > 1\r\n            ):\r\n                # TODO: Find a more robust way to connect comments to the right span\r\n                self.comments_with_no_span.append(code_block)\n            else:\n                new_span = self._create_new_span(\r\n                    current_span=current_span, block=code_block\r\n                )\n                if new_span:\n                    current_span = new_span\n                    self.spans_by_id[current_span.span_id] = current_span\n                    code_block.span_ids.add(current_span.span_id)\n                else:\n                    current_span.end_line = code_block.end_line\n\n                for comment_block in self.comments_with_no_span:\n                    comment_block.belongs_to_span = current_span\n                    current_span.block_paths.append(comment_block.full_path())\n                    current_span.tokens += comment_block.tokens\n\n                current_span.block_paths.append(code_block.full_path())\n                current_span.tokens += code_block.tokens\n\n                code_block.belongs_to_span = current_span\n                code_block.span_ids.add(current_span.span_id)\n\n                self.comments_with_no_span = []\n\n            self._graph.add_node(code_block.path_string(), block=code_block)\n\n            for relationship in relationships:\n                self._graph.add_edge(\r\n                    code_block.path_string(), \".\".join(relationship.path)\r\n                )\n\n        else:\n            current_span = None\n            code_block = Module(\r\n                type=CodeBlockType.MODULE,\r\n                identifier=None,\r\n                file_path=file_path,\r\n                content=\"\",\r\n                spans_by_id={},\r\n                start_line=node.start_point[0] + 1,\r\n                end_line=end_line + 1,\r\n                language=self.language,\r\n                children=[],\r\n                properties={\r\n                    \"query\": node_match.query,\r\n                    \"tree_sitter_type\": node.type,\r\n                },\r\n            )\n            self._previous_block = code_block\n\n        next_node = node_match.first_child\n        # ... other code", "kind": "Chunk", "id": "parser/parser.py#83.106"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.parse_code.self_debug_log__CodeParser.parse_code.return.code_block_next_node_cu", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 754, "span_ids": ["CodeParser.parse_code"], "start_line": 293, "end_line": 385, "community": null}, "content": "class CodeParser:\n\n    def parse_code(\r\n        self,\r\n        content_bytes: bytes,\r\n        node: Node,\r\n        start_byte: int = 0,\r\n        level: int = 0,\r\n        file_path: Optional[str] = None,\r\n        parent_block: CodeBlock | None = None,\r\n        current_span: BlockSpan | None = None,\r\n    ) -> tuple[CodeBlock, Node, BlockSpan]:\n        # ... other code\n\n        self.debug_log(\r\n            f\"\"\"Created code block\r\n    content: {code_block.content[:50]} \r\n    block_type: {code_block.type} \r\n    node_type: {node.type}\r\n    next_node: {next_node.type if next_node else \"none\"}\r\n    first_child: {node_match.first_child}\r\n    last_child: {node_match.last_child}\r\n    start_byte: {start_byte}\r\n    node.start_byte: {node.start_byte}\r\n    node.end_byte: {node.end_byte}\"\"\"\r\n        )\n\n        index = 0\n\n        while next_node:\n            if (\r\n                next_node.children and next_node.type == \"block\"\r\n            ):  # TODO: This should be handled in get_block_definition\r\n                next_node = next_node.children[0]\n\n            self.debug_log(\r\n                f\"next  [{level}]: -> {next_node.type} - {next_node.start_byte}\"\r\n            )\n\n            child_block, child_last_node, child_span = self.parse_code(\r\n                content_bytes,\r\n                next_node,\r\n                start_byte=end_byte,\r\n                level=level + 1,\r\n                parent_block=code_block,\r\n                current_span=current_span,\r\n            )\n\n            if not current_span or child_span.span_id != current_span.span_id:\n                current_span = child_span\n\n            code_block.append_child(child_block)\n\n            index += 1\n\n            if child_last_node:\n                self.debug_log(f\"next  [{level}]: child_last_node -> {child_last_node}\")\n                next_node = child_last_node\n\n            end_byte = next_node.end_byte\n\n            self.debug_log(\r\n                f\"\"\"next  [{level}]\r\n    last_child -> {node_match.last_child}\r\n    next_node -> {next_node}\r\n    next_node.next_sibling -> {next_node.next_sibling}\r\n    end_byte -> {end_byte}\r\n\"\"\"\r\n            )\n            if next_node == node_match.last_child:\n                break\n            elif next_node.next_sibling:\n                next_node = next_node.next_sibling\n            else:\n                next_parent_node = self.get_parent_next(\r\n                    next_node, node_match.check_child or node\r\n                )\n                next_node = None if next_parent_node == next_node else next_parent_node\n\n        self.debug_log(f\"end   [{level}]: {code_block.content}\")\n\n        for comment_block in self.comments_with_no_span:\n            comment_block.belongs_to_span = current_span\n            comment_block.span_ids.add(current_span.span_id)\n            current_span.block_paths.append(comment_block.full_path())\n            current_span.tokens += comment_block.tokens\n\n        self.comments_with_no_span = []\n\n        self.post_process(code_block)\n\n        self.add_to_index(code_block)\n\n        # TODO: Find a way to remove the Space end block\r\n        if level == 0 and not node.parent and node.end_byte > end_byte:\n            space_block = CodeBlock(\r\n                type=CodeBlockType.SPACE,\r\n                identifier=None,\r\n                pre_code=content_bytes[end_byte : node.end_byte].decode(self.encoding),\r\n                parent=code_block,\r\n                start_line=end_line + 1,\r\n                end_line=node.end_point[0] + 1,\r\n                content=\"\",\r\n            )\n            code_block.append_child(space_block)\n\n        return code_block, next_node, current_span", "kind": "Chunk", "id": "parser/parser.py#84.92"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.is_commented_out_code_CodeParser.find_in_tree.if_match_.else_.return.NodeMatch_block_type_Code", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 235, "span_ids": ["CodeParser.find_in_tree", "CodeParser.is_commented_out_code"], "start_line": 387, "end_line": 412, "community": null}, "content": "class CodeParser:\n\n    def is_commented_out_code(self, node: Node):\n        comment = node.text.decode(\"utf8\").strip()\n        return comment.startswith(f\"{get_comment_symbol(self.language)} ...\") or any(\r\n            keyword in comment.lower() for keyword in commented_out_keywords\r\n        )\n\n    def find_in_tree(self, node: Node) -> NodeMatch | None:\n        if self.apply_gpt_tweaks:\n            match = self.find_match_with_gpt_tweaks(node)\n            if match:\n                self.debug_log(\r\n                    f\"find_in_tree() GPT match: {match.block_type} on {node}\"\r\n                )\n                return match\n\n        match = self.find_match(node)\n        if match:\n            self.debug_log(\r\n                f\"find_in_tree() Found match on node type {node.type} with block type {match.block_type}\"\r\n            )\n            return match\n        else:\n            self.debug_log(\r\n                f\"find_in_tree() Found no match on node type {node.type} set block type {CodeBlockType.CODE}\"\r\n            )\n            return NodeMatch(block_type=CodeBlockType.CODE)", "kind": "Chunk", "id": "parser/parser.py#85.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.find_match_with_gpt_tweaks_CodeParser.find_match_with_gpt_tweaks.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 133, "span_ids": ["CodeParser.find_match_with_gpt_tweaks"], "start_line": 414, "end_line": 427, "community": null}, "content": "class CodeParser:\n\n    def find_match_with_gpt_tweaks(self, node: Node) -> NodeMatch | None:\n        for label, node_type, query in self.gpt_queries:\n            if node_type and node.type != node_type and node_type != \"_\":\n                continue\n            match = self._find_match(node, query, label, capture_from_parent=True)\n            if match:\n                self.debug_log(\r\n                    f\"find_match_with_gpt_tweaks() Found match on node {node.type} with query {label}\"\r\n                )\n                if not match.query:\n                    match.query = label\n                return match\n\n        return None", "kind": "Chunk", "id": "parser/parser.py#86.13"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.find_match_CodeParser.find_match.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 130, "span_ids": ["CodeParser.find_match"], "start_line": 429, "end_line": 443, "community": null}, "content": "class CodeParser:\n\n    def find_match(self, node: Node) -> NodeMatch | None:\n        self.debug_log(f\"find_match() node type {node.type}\")\n        for label, node_type, query in self.queries:\n            if node_type and node.type != node_type and node_type != \"_\":\n                continue\n            match = self._find_match(node, query, label)\n            if match:\n                self.debug_log(\r\n                    f\"find_match() Found match on node {node.type} with query {label}\"\r\n                )\n                if not match.query:\n                    match.query = label\n                return match\n\n        return None", "kind": "Chunk", "id": "parser/parser.py#87.14"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser._find_match_CodeParser._find_match.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 591, "span_ids": ["CodeParser._find_match"], "start_line": 445, "end_line": 525, "community": null}, "content": "class CodeParser:\n\n    def _find_match(\r\n        self, node: Node, query, label: str, capture_from_parent: bool = False\r\n    ) -> NodeMatch | None:\n        if capture_from_parent:\n            captures = query.captures(node.parent)\n        else:\n            captures = query.captures(node)\n\n        node_match = NodeMatch()\n\n        if not captures:\n            return None\n\n        root_node = None\n\n        for found_node, tag in captures:\n            self.debug_log(f\"[{label}] Found tag {tag} on node {found_node}\")\n\n            if tag == \"root\" and not root_node and node == found_node:\n                self.debug_log(f\"[{label}] Root node {found_node}\")\n                root_node = found_node\n\n            if not root_node:\n                continue\n\n            if tag == \"no_children\" and found_node.children:\n                return None\n\n            if tag == \"check_child\":\n                self.debug_log(f\"[{label}] Check child {found_node}\")\n                node_match = self.find_match(found_node)\n                if node_match:\n                    node_match.check_child = found_node\n                return node_match\n\n            if tag == \"parse_child\":\n                self.debug_log(f\"[{label}] Parse child {found_node}\")\n\n                child_match = self.find_match(found_node)\n                if child_match:\n                    if child_match.relationships:\n                        self.debug_log(\r\n                            f\"[{label}] Found {len(child_match.relationships)} references on child {found_node}\"\r\n                        )\n                        node_match.relationships = child_match.relationships\n                    if child_match.parameters:\n                        self.debug_log(\r\n                            f\"[{label}] Found {len(child_match.parameters)} parameters on child {found_node}\"\r\n                        )\n                        node_match.parameters.extend(child_match.parameters)\n                    if child_match.first_child:\n                        node_match.first_child = child_match.first_child\n\n            if tag == \"identifier\" and not node_match.identifier_node:\n                node_match.identifier_node = found_node\n\n            if tag == \"child.first\" and not node_match.first_child:\n                node_match.first_child = found_node\n\n            if tag == \"child.last\" and not node_match.last_child:\n                node_match.last_child = found_node\n\n            if tag == \"parameter.identifier\":\n                node_match.parameters.append((found_node, None))\n\n            if tag == \"parameter.type\" and node_match.parameters:\n                node_match.parameters[-1] = (node_match.parameters[-1][0], found_node)\n\n            if root_node and tag.startswith(\"reference\"):\n                node_match.relationships.append((found_node, tag))\n\n            if not node_match.block_type:\n                node_match.block_type = CodeBlockType.from_string(tag)\n\n        if node_match.block_type:\n            self.debug_log(\r\n                f\"[{label}] Return match with type {node_match.block_type} for node {node}\"\r\n            )\n            return node_match\n\n        return None", "kind": "Chunk", "id": "parser/parser.py#88.80"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.create_references_CodeParser.create_references.return.references", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 594, "span_ids": ["CodeParser.create_references"], "start_line": 527, "end_line": 611, "community": null}, "content": "class CodeParser:\n\n    def create_references(self, code, content_bytes, identifier, node_match):\n        references = []\n        if node_match.block_type == CodeBlockType.IMPORT and node_match.relationships:\n            module_nodes = [\r\n                ref for ref in node_match.relationships if ref[1] == \"reference.module\"\r\n            ]\n            if module_nodes:\n                module_reference_id = self.get_content(\r\n                    module_nodes[0][0], content_bytes\r\n                )\n                if len(node_match.relationships) > 1:\n                    for ref_node in node_match.relationships:\n                        if ref_node == module_nodes[0]:\n                            continue\n                        elif ref_node[1] == \"reference.alias\":\n                            reference_id = self.get_content(ref_node[0], content_bytes)\n                            references.append(\r\n                                Relationship(\r\n                                    scope=ReferenceScope.EXTERNAL,\r\n                                    type=RelationshipType.IMPORTS,\r\n                                    identifier=reference_id,\r\n                                    path=[],\r\n                                    external_path=[module_reference_id],\r\n                                )\r\n                            )\n                        else:\n                            reference_id = self.get_content(ref_node[0], content_bytes)\n                            references.append(\r\n                                Relationship(\r\n                                    scope=ReferenceScope.EXTERNAL,\r\n                                    type=RelationshipType.IMPORTS,\r\n                                    identifier=reference_id,\r\n                                    path=[reference_id],\r\n                                    external_path=[module_reference_id],\r\n                                )\r\n                            )\n                else:\n                    references.append(\r\n                        Relationship(\r\n                            scope=ReferenceScope.EXTERNAL,\r\n                            type=RelationshipType.IMPORTS,\r\n                            identifier=module_reference_id,\r\n                            external_path=[module_reference_id],\r\n                        )\r\n                    )\n        else:\n            for reference in node_match.relationships:\n                reference_id = self.get_content(reference[0], content_bytes)\n\n                reference_id_path = reference_id.split(\".\")\n\n                if not reference_id_path:\n                    logger.warning(\r\n                        f\"Empty reference_id_path ({reference_id_path}) for code `{code}` in reference node {reference} with value {reference_id}\"\r\n                    )\n                    continue\n\n                if reference[1] == \"reference.utilizes\":\n                    if node_match.block_type in [\r\n                        CodeBlockType.FUNCTION,\r\n                        CodeBlockType.CLASS,\r\n                    ]:\n                        relationship_type = RelationshipType.DEFINED_BY\n                    else:\n                        relationship_type = RelationshipType.UTILIZES\n                elif reference[1] == \"reference.provides\":\n                    relationship_type = RelationshipType.PROVIDES\n                elif reference[1] == \"reference.calls\":\n                    relationship_type = RelationshipType.CALLS\n                elif reference[1] == \"reference.type\":\n                    relationship_type = RelationshipType.IS_A\n                elif reference[1] == \"reference.imports\":\n                    relationship_type = RelationshipType.IMPORTS\n                else:\n                    relationship_type = RelationshipType.USES\n\n                references.append(\r\n                    Relationship(\r\n                        scope=ReferenceScope.LOCAL,\r\n                        type=relationship_type,\r\n                        identifier=identifier,\r\n                        path=reference_id_path,\r\n                    )\r\n                )\n        return references", "kind": "Chunk", "id": "parser/parser.py#89.84"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.create_parameters_CodeParser.create_parameters.return.parameters", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 141, "span_ids": ["CodeParser.create_parameters"], "start_line": 613, "end_line": 632, "community": null}, "content": "class CodeParser:\n\n    def create_parameters(self, content_bytes, node_match, references):\n        parameters = []\n        for parameter in node_match.parameters:\n            parameter_type = (\r\n                self.get_content(parameter[1], content_bytes) if parameter[1] else None\r\n            )\n            parameter_id = self.get_content(parameter[0], content_bytes)\n\n            parameters.append(Parameter(identifier=parameter_id, type=parameter_type))\n\n            if parameter_type:\n                parameter_type = parameter_type.replace('\"', \"\")\n\n                type_split = parameter_type.split(\".\")\n\n                reference = Relationship(\r\n                    scope=ReferenceScope.LOCAL, identifier=parameter_id, path=type_split\r\n                )\n                references.append(reference)\n        return parameters", "kind": "Chunk", "id": "parser/parser.py#90.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.add_to_index_CodeParser.has_error.return.False", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 275, "span_ids": ["CodeParser.get_previous", "CodeParser.get_parent_next", "CodeParser.pre_process", "CodeParser.has_error", "CodeParser.post_process", "CodeParser.add_to_index"], "start_line": 634, "end_line": 671, "community": null}, "content": "class CodeParser:\n\n    def add_to_index(self, codeblock: CodeBlock):\n        if self.index_callback:\n            self.index_callback(codeblock)\n\n    def pre_process(self, codeblock: CodeBlock, node_match: NodeMatch):\n        pass\n\n    def post_process(self, codeblock: CodeBlock):\n        pass\n\n    def get_previous(self, node: Node, origin_node: Node):\n        if node == origin_node:\n            return node.start_byte\n        if node.prev_sibling:\n            return node.prev_sibling.end_byte\n        elif node.parent:\n            return self.get_previous(node.parent, origin_node)\n        else:\n            return node.start_byte\n\n    def get_parent_next(self, node: Node, orig_node: Node):\n        self.debug_log(f\"get_parent_next: {node.type} - {orig_node.type}\")\n        if node != orig_node:\n            if node.next_sibling:\n                self.debug_log(\r\n                    f\"get_parent_next: node.next_sibling -> {node.next_sibling}\"\r\n                )\n                return node.next_sibling\n            else:\n                return self.get_parent_next(node.parent, orig_node)\n        return None\n\n    def has_error(self, node: Node):\n        if node.type == \"ERROR\":\n            return True\n        if node.children:\n            return any(self.has_error(child) for child in node.children)\n        return False", "kind": "Chunk", "id": "parser/parser.py#91.37"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser.parse_CodeParser.get_content.return.content_bytes_node_start_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 229, "span_ids": ["CodeParser.get_content", "CodeParser.parse"], "start_line": 673, "end_line": 699, "community": null}, "content": "class CodeParser:\n\n    def parse(self, content, file_path: Optional[str] = None) -> Module:\n        if isinstance(content, str):\n            content_in_bytes = bytes(content, self.encoding)\n        elif isinstance(content, bytes):\n            content_in_bytes = content\n        else:\n            raise ValueError(\"Content must be either a string or bytes\")\n\n        # TODO: make thread safe?\r\n        self.spans_by_id = {}\n        self._span_counter = {}\n\n        # TODO: Should me moved to a central CodeGraph\r\n        self._graph = nx.DiGraph()\n\n        tree = self.tree_parser.parse(content_in_bytes)\n        module, _, _ = self.parse_code(\r\n            content_in_bytes, tree.walk().node, file_path=file_path\r\n        )\n        module.spans_by_id = self.spans_by_id\n        module.file_path = file_path\n        module.language = self.language\n        module._graph = self._graph\n        return module\n\n    def get_content(self, node: Node, content_bytes: bytes) -> str:\n        return content_bytes[node.start_byte : node.end_byte].decode(self.encoding)", "kind": "Chunk", "id": "parser/parser.py#92.26"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser._create_new_span_CodeParser._create_new_span._if_current_span_is_from", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 740, "span_ids": ["CodeParser._create_new_span"], "start_line": 701, "end_line": 784, "community": null}, "content": "class CodeParser:\n\n    def _create_new_span(\r\n        self, current_span: BlockSpan | None, block: CodeBlock\r\n    ) -> BlockSpan | None:\n        # Set documentation phase on comments in the start of structure blocks if more than min_tokens_for_docs_span\r\n        # TODO: This is isn't valid in other languages, try to set block type to docstring?\r\n        block_types_with_document_span = [\r\n            CodeBlockType.MODULE\r\n        ]  # TODO: Make this configurable\r\n        if block.type == CodeBlockType.COMMENT and (\r\n            not current_span\r\n            or current_span.block_type in block_types_with_document_span\r\n            and (\r\n                current_span.span_type != SpanType.IMPLEMENTATION\r\n                or current_span.index == 0\r\n            )\r\n        ):\n            span_type = SpanType.DOCUMENTATION\n            span_id = self._create_span_id(block, label=\"docstring\")\n\n        # Set initation phase when block is a class or constructor, and until first function:\r\n        elif block.type in [CodeBlockType.CLASS, CodeBlockType.CONSTRUCTOR] or (\r\n            current_span\r\n            and current_span.block_type\r\n            in [CodeBlockType.CLASS, CodeBlockType.CONSTRUCTOR]\r\n            and current_span.initiating_block.parent != block.parent\r\n            and current_span.span_type != SpanType.IMPLEMENTATION\r\n            and block.type not in [CodeBlockType.FUNCTION]\r\n        ):\n            span_type = SpanType.INITATION\n            span_id = self._create_span_id(block)\n\n        # Set initation phase on imports in module blocks\r\n        elif block.type == CodeBlockType.IMPORT and (\r\n            not current_span or current_span.block_type == CodeBlockType.MODULE\r\n        ):\n            span_type = SpanType.INITATION\n            span_id = self._create_span_id(block, label=\"imports\")\n\n        else:\n            span_type = SpanType.IMPLEMENTATION\n            span_id = self._create_span_id(block)\n\n        # if no curent_span exists, expected to be on Module level\r\n        if not current_span:\n            if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n                return BlockSpan(\r\n                    span_id=span_id,\r\n                    span_type=span_type,\r\n                    start_line=block.start_line,\r\n                    end_line=block.start_line,\r\n                    initiating_block=block,\r\n                    parent_block_path=block.full_path(),\r\n                )\n            else:\n                return BlockSpan(\r\n                    span_id=span_id,\r\n                    span_type=span_type,\r\n                    start_line=block.start_line,\r\n                    end_line=block.start_line,\r\n                    initiating_block=block.parent,\r\n                    parent_block_path=block.parent.full_path(),\r\n                )\n\n        # create a new span on new structures in classes or modules but not functions\r\n        # * if the parent block doesn't have a span\r\n        if (\r\n            block.type.group in [CodeBlockTypeGroup.STRUCTURE]\r\n            and block.parent.type in [CodeBlockType.MODULE, CodeBlockType.CLASS]\r\n            and current_span.parent_block_path == block.parent.full_path()\r\n        ):\n            if len(current_span.parent_block_path) < len(block.full_path()):\r\n                # If there is a current span from the parent block it should be set to is_partial\r\n                current_span.is_partial = True\n\n            return BlockSpan(\r\n                span_id=span_id,\r\n                span_type=span_type,\r\n                start_line=block.start_line,\r\n                end_line=block.start_line,\r\n                initiating_block=block,\r\n                parent_block_path=block.full_path(),\r\n            )\n\n        # if current span is from a child block\r\n        # ... other code", "kind": "Chunk", "id": "parser/parser.py#93.83"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser._create_new_span.if_len_current_span_paren_CodeParser._create_new_span.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 395, "span_ids": ["CodeParser._create_new_span"], "start_line": 785, "end_line": 830, "community": null}, "content": "class CodeParser:\n\n    def _create_new_span(\r\n        self, current_span: BlockSpan | None, block: CodeBlock\r\n    ) -> BlockSpan | None:\n        # ... other code\n        if len(current_span.parent_block_path) > len(block.parent.full_path()):\n            if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n                parent_block_path = block.full_path()\n            else:\n                parent_block_path = block.parent.full_path()\n\n            return BlockSpan(\r\n                span_id=span_id,\r\n                span_type=span_type,\r\n                start_line=block.start_line,\r\n                end_line=block.start_line,\r\n                initiating_block=block,\r\n                parent_block_path=parent_block_path,\r\n            )\n\n        # Create new span if span type has changed\r\n        # if span_type != current_span.span_type:\r\n        #    return BlockSpan(\r\n        #        span_id=span_id,\r\n        #        span_type=span_type,\r\n        #        start_line=block.start_line,\r\n        #        end_line=block.start_line,\r\n        #        initiating_block=current_span.initiating_block,\r\n        #        parent_block_path=current_span.parent_block_path,\r\n        #    )\r\n\n        # Create new span if the current is too large and the parent block is a structure block\r\n        split_on_block_type = [CodeBlockType.MODULE]  # Only split on Module level\r\n        if (\r\n            current_span.tokens + block.sum_tokens() > self._max_tokens_in_span\r\n            and block.parent.type in split_on_block_type\r\n        ):\n            current_span.is_partial = True\n\n            return BlockSpan(\r\n                span_id=span_id,\r\n                span_type=span_type,\r\n                start_line=block.start_line,\r\n                end_line=block.start_line,\r\n                initiating_block=current_span.initiating_block,\r\n                parent_block_path=current_span.parent_block_path,\r\n                is_partial=True,\r\n                index=current_span.index + 1,\r\n            )\n\n        return None", "kind": "Chunk", "id": "parser/parser.py#94.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py_CodeParser._create_span_id_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\parser.py", "file_name": "parser.py", "file_type": "text/x-python", "category": "test", "tokens": 232, "span_ids": ["CodeParser._count_tokens", "CodeParser.debug_log", "CodeParser._create_span_id"], "start_line": 832, "end_line": 864, "community": null}, "content": "class CodeParser:\n\n    def _create_span_id(self, block: CodeBlock, label: Optional[str] = None):\n        if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n            structure_block = block\n        else:\n            structure_block = block.find_type_group_in_parents(\r\n                CodeBlockTypeGroup.STRUCTURE\r\n            )\n\n        span_id = structure_block.path_string()\n        if label and span_id:\n            span_id += f\":{label}\"\n        elif label and not span_id:\n            span_id = label\n        elif not span_id:\n            span_id = \"impl\"\n\n        if span_id in self._span_counter:\n            self._span_counter[span_id] += 1\n            span_id += f\":{self._span_counter[span_id]}\"\n        else:\n            self._span_counter[span_id] = 1\n\n        return span_id\n\n    def _count_tokens(self, content: str):\n        if not self.tokenizer:\n            return 0\n        return len(self.tokenizer(content))\n\n    def debug_log(self, message: str):\n        if self.debug:\n            logger.debug(message)", "kind": "Chunk", "id": "parser/parser.py#95.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\python.py_logging_PythonParser.pre_process.None_1.codeblock_content_lines_0", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\python.py", "file_name": "python.py", "file_type": "text/x-python", "category": "test", "tokens": 379, "span_ids": ["PythonParser.pre_process", "PythonParser.language", "PythonParser", "PythonParser.__init__", "imports"], "start_line": 1, "end_line": 61, "community": null}, "content": "import logging\n\nimport tree_sitter_python as tspython\nfrom tree_sitter import Language\n\nfrom moatless.codeblocks.codeblocks import (\r\n    CodeBlock,\r\n    CodeBlockType,\r\n    ReferenceScope,\r\n    RelationshipType,\r\n    ValidationError,\r\n)\nfrom moatless.codeblocks.parser.parser import (\r\n    CodeParser,\r\n    NodeMatch,\r\n    commented_out_keywords,\r\n)\n\nchild_block_types = [\"ERROR\", \"block\"]\n\nblock_delimiters = [\":\"]\n\nlogger = logging.getLogger(__name__)\n\n\nclass PythonParser(CodeParser):\n    def __init__(self, **kwargs):\n        language = Language(tspython.language())\n\n        super().__init__(language, **kwargs)\n\n        self.queries = []\n        self.queries.extend(self._build_queries(\"python.scm\"))\n\n        if self.apply_gpt_tweaks:\n            self.gpt_queries.extend(self._build_queries(\"python_gpt.scm\"))\n\n    @property\r\n    def language(self):\n        return \"python\"\n\n    def pre_process(self, codeblock: CodeBlock, node_match: NodeMatch):\n        if (\r\n            codeblock.type == CodeBlockType.FUNCTION\r\n            and codeblock.identifier == \"__init__\"\r\n        ):\n            codeblock.type = CodeBlockType.CONSTRUCTOR\n\n        # Handle line breaks after assignment without \\\r\n        if (\r\n            codeblock.type == CodeBlockType.ASSIGNMENT\r\n            and codeblock.content_lines[0].strip().endswith(\"=\")\r\n            and node_match.check_child\r\n            and node_match.first_child\r\n            and node_match.check_child.start_point[0]\r\n            < node_match.first_child.start_point[0]\r\n        ):\n            logger.warning(\r\n                f\"Parsed block with type ASSIGNMENT with line break but no ending \\\\: {codeblock.content_lines[0]}\"\r\n            )\n            codeblock.content_lines[0] = codeblock.content_lines[0] + \" \\\\\"", "kind": "Chunk", "id": "parser/python.py#96.60"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\python.py_PythonParser.post_process_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\codeblocks\\parser\\python.py", "file_name": "python.py", "file_type": "text/x-python", "category": "test", "tokens": 582, "span_ids": ["PythonParser.is_outcommented_code", "PythonParser.post_process"], "start_line": 63, "end_line": 136, "community": null}, "content": "class PythonParser(CodeParser):\n\n    def post_process(self, codeblock: CodeBlock):\n        if codeblock.type == CodeBlockType.COMMENT and self.is_outcommented_code(\r\n            codeblock.content\r\n        ):\n            codeblock.type = CodeBlockType.COMMENTED_OUT_CODE\n\n        if codeblock.type == CodeBlockType.ASSIGNMENT:\n            for reference in codeblock.relationships:\n                reference.type = RelationshipType.TYPE\n\n        new_references = []\n        for reference in codeblock.relationships:\r\n            # Set parent class path as reference path on self\r\n            if reference.path and reference.path[0] == \"self\":\n                class_block = codeblock.find_type_in_parents(CodeBlockType.CLASS)\n                if class_block:\n                    reference.scope = ReferenceScope.CLASS\n                    if len(reference.path) > 1:\n                        reference.path = class_block.full_path() + reference.path[1:2]\n                        reference.identifier = codeblock.identifier\n\n            # Set parent classes super class path as reference path on super()\r\n            # TODO: make a solution where this can be derived even further (by checking import)\r\n            if reference.path and reference.path[0] == \"super()\":\n                class_block = codeblock.find_type_in_parents(CodeBlockType.CLASS)\n                if class_block:\n                    is_a_rel = [\r\n                        rel\r\n                        for rel in class_block.relationships\r\n                        if rel.type == RelationshipType.IS_A\r\n                    ]\n                    if is_a_rel:\n                        super_class = codeblock.module.find_by_path(is_a_rel[0].path)\n\n                        if super_class:\n                            reference.path = (\r\n                                super_class.full_path() + reference.path[1:2]\r\n                            )\n                            reference.identifier = super_class.identifier\n\n        codeblock.relationships.extend(new_references)\n\n        if (\r\n            codeblock.type in [CodeBlockType.CLASS, CodeBlockType.FUNCTION]\r\n            and len(codeblock.children) == 1\r\n            and codeblock.children[0].type == CodeBlockType.COMMENTED_OUT_CODE\r\n        ):\n            codeblock.type = CodeBlockType.COMMENTED_OUT_CODE\n\n        function_names = set()\n        class_names = set()\n        for child in codeblock.children:\n            if child.type == CodeBlockType.FUNCTION:\n                if child.identifier in function_names:\n                    child.validation_errors.append(\r\n                        ValidationError(\r\n                            error=f\"Duplicate function name: {child.identifier}\"\r\n                        )\r\n                    )\n                function_names.add(child.identifier)\n            if child.type == CodeBlockType.CLASS:\n                if child.identifier in class_names:\n                    child.validation_errors.append(\r\n                        ValidationError(\r\n                            error=f\"Duplicate class name: {child.identifier}\"\r\n                        )\r\n                    )\n                class_names.add(child.identifier)\n\n    def is_outcommented_code(self, comment):\n        return comment.startswith(\"# ...\") or any(\r\n            keyword in comment.lower() for keyword in commented_out_keywords\r\n        )", "kind": "Chunk", "id": "parser/python.py#97.73"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 34, "span_ids": ["imports"], "start_line": 1, "end_line": 4, "community": null}, "content": "from moatless.edit.clarify import ClarifyCodeChange\nfrom moatless.edit.edit import EditCode\nfrom moatless.edit.plan import PlanToCode", "kind": "Chunk", "id": "edit/__init__.py#98.3"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_logging_LineNumberClarification.reject.Field_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 223, "span_ids": ["imports", "LineNumberClarification"], "start_line": 1, "end_line": 30, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field, PrivateAttr\n\nfrom moatless.codeblocks import CodeBlockType\nfrom moatless.codeblocks.codeblocks import BlockSpan, CodeBlockTypeGroup\nfrom moatless.edit.prompt import CLARIFY_CHANGE_SYSTEM_PROMPT\nfrom moatless.repository import CodeFile\nfrom moatless.state import ActionResponse, AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    FileWithSpans,\r\n    Message,\r\n)\nfrom moatless.utils.tokenizer import count_tokens\n\nlogger = logging.getLogger(\"ClarifyCodeChange\")\n\n\nclass LineNumberClarification(ActionRequest):\n    scratch_pad: str = Field(..., description=\"Thoughts on which lines to select\")\n    start_line: int = Field(\r\n        ..., description=\"The start line of the code to be updated.\"\r\n    )\n\n    end_line: int = Field(..., description=\"The end line of the code to be updated.\")\n    reject: Optional[bool] = Field(\r\n        None, description=\"Whether the request should be rejected.\"\r\n    )", "kind": "Chunk", "id": "edit/clarify.py#99.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange_ClarifyCodeChange._file_context_str.PrivateAttr_None_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 187, "span_ids": ["ClarifyCodeChange"], "start_line": 33, "end_line": 48, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n    instructions: str = Field(..., description=\"The instructions for the code change.\")\n    file_path: str = Field(..., description=\"The path to the file to be updated.\")\n    span_id: str = Field(..., description=\"The ID of the span to be updated.\")\n\n    start_line: Optional[int] = Field(None, description=\"The start line of the code to be updated.\")\n    end_line: Optional[int] = Field(None, description=\"The end line of the code to be updated.\")\n\n    max_tokens_in_edit_prompt: int = Field(\r\n        500,\r\n        description=\"The maximum number of tokens in a span to show the edit prompt.\",\r\n    )\n\n    _file: CodeFile | None = PrivateAttr(None)\n    _span: BlockSpan | None = PrivateAttr(None)\n    _file_context_str: Optional[str] = PrivateAttr(None)", "kind": "Chunk", "id": "edit/clarify.py#100.15"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange.init_ClarifyCodeChange.init.self._file_context_str.file_context_create_promp", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 260, "span_ids": ["ClarifyCodeChange.init"], "start_line": 50, "end_line": 78, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n\n    def init(self):\n        self._file = self.file_repo.get_file(self.file_path)\n        self._span = self._file.module.find_span_by_id(self.span_id)\n\n        file_context = self.create_file_context(\r\n            [FileWithSpans(file_path=self.file_path, span_ids=[self.span.span_id])]\r\n        )\n\n        # Include all function/class signatures if the block is a class\r\n        if self.span.initiating_block.type == CodeBlockType.CLASS:\n            for child in self.span.initiating_block.children:\n                if (\r\n                    child.type.group == CodeBlockTypeGroup.STRUCTURE\r\n                    and child.belongs_to_span\r\n                    and child.belongs_to_span.span_id != self._span.span_id\r\n                ):\n                    file_context.add_span_to_context(\r\n                        file_path=self.file_path,\r\n                        span_id=child.belongs_to_span.span_id,\r\n                        tokens=1,\r\n                    )  # TODO: Change so 0 can be set and mean \"only signature\"\r\n\n        self._file_context_str = file_context.create_prompt(\r\n            show_line_numbers=True,\r\n            show_span_ids=False,\r\n            exclude_comments=False,\r\n            show_outcommented_code=True,\r\n            outcomment_code_comment=\"... other code\",\r\n        )", "kind": "Chunk", "id": "edit/clarify.py#101.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange._execute_action_ClarifyCodeChange._execute_action.return.ActionResponse_transition", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 251, "span_ids": ["ClarifyCodeChange._execute_action"], "start_line": 80, "end_line": 113, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n\n    def _execute_action(self, request: LineNumberClarification) -> ActionResponse:\n        logger.info(\r\n            f\"{self}: Got line number clarification: {request.start_line} - {request.end_line}\"\r\n        )\n\n        if request.reject:\n            return ActionResponse.transition(\r\n                trigger=\"reject\", output={\"message\": request.scratch_pad}\r\n            )\n\n        retry_message = self._verify_line_numbers(request)\n        if retry_message:\n            return ActionResponse.retry(retry_message)\n\n        if request.end_line - request.start_line < 4:\n            start_line, end_line = self.get_line_span(\r\n                request.start_line, request.end_line, self.max_tokens_in_edit_prompt\r\n            )\n        else:\n            start_line, end_line = request.start_line, request.end_line\n\n        if request.scratch_pad:\n            self.instructions += \"\\n\\n\" + request.scratch_pad\n\n        return ActionResponse.transition(\r\n            trigger=\"edit_code\",\r\n            output={\r\n                \"instructions\": self.instructions,\r\n                \"file_path\": self.file_path,\r\n                \"span_id\": self.span_id,\r\n                \"start_line\": start_line,\r\n                \"end_line\": end_line,\r\n            },\r\n        )", "kind": "Chunk", "id": "edit/clarify.py#102.33"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange.required_fields_ClarifyCodeChange.span.return.self__span", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 128, "span_ids": ["ClarifyCodeChange.span", "ClarifyCodeChange.action_type", "ClarifyCodeChange.required_fields", "ClarifyCodeChange.file"], "start_line": 115, "end_line": 130, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n\n    @classmethod\r\n    def required_fields(cls) -> set[str]:\n        return {\"instructions\", \"file_path\", \"span_id\"}\n\n    def action_type(self) -> type[BaseModel] | None:\n        return LineNumberClarification\n\n    @property\r\n    def file(self) -> CodeFile:\n        assert self._file is not None, \"File has not been set\"\n        return self._file\n\n    @property\r\n    def span(self) -> BlockSpan:\n        assert self._span is not None, \"Span has not been set\"\n        return self._span", "kind": "Chunk", "id": "edit/clarify.py#103.15"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange._verify_line_numbers_ClarifyCodeChange.messages.return.messages", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 688, "span_ids": ["ClarifyCodeChange._verify_line_numbers", "ClarifyCodeChange.system_prompt", "ClarifyCodeChange.messages"], "start_line": 132, "end_line": 198, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n\n    def _verify_line_numbers(\r\n        self, line_numbers: LineNumberClarification\r\n    ) -> Optional[str]:\n        logger.info(\r\n            f\"{self}: Verifying line numbers: {line_numbers.start_line} - {line_numbers.end_line}. \"\r\n            f\"To span with line numbers: {self.span.start_line} - {self.span.end_line}\"\r\n        )\n\n        if (\r\n            line_numbers.start_line <= self.span.start_line\r\n            and line_numbers.end_line >= self.span.end_line\r\n        ):\n            return f\"The provided line numbers {line_numbers.start_line} - {line_numbers.end_line} covers the whole code span. You must specify line numbers of only lines you want to change.\"\n\n        span_block = self.span.initiating_block\n\n        # The LLM sometimes refer to only the lines of the class/function signature when it's intention is to edit lines\r\n        if span_block.type.group == CodeBlockTypeGroup.STRUCTURE:\n            last_block_content_line = span_block.children[0].start_line - 1\n\n            logger.info(\r\n                f\"{self}: Checking if the line numbers only covers a class/function signature to \"\r\n                f\"{self.span.initiating_block.path_string()} ({span_block.start_line} - {last_block_content_line})\"\r\n            )\n            if (\r\n                line_numbers.start_line == span_block.start_line\r\n                and last_block_content_line >= line_numbers.end_line\r\n                and self.span.initiating_block.sum_tokens()\r\n                > self.max_tokens_in_edit_prompt\r\n            ):\n                clarify_msg = f\"The line numbers {line_numbers.start_line} - {line_numbers.end_line} only covers to the signature of the {self.span.initiating_block.type.value}.\"\n                logger.info(f\"{self}: {clarify_msg}. Ask for clarification.\")\n                # TODO: Ask if this was intentional instead instructing the LLM\r\n                return f\"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change.\"\n\n        code_lines = self.file.content.split(\"\\n\")\n        lines_to_replace = code_lines[\r\n            line_numbers.start_line - 1 : line_numbers.end_line\r\n        ]\n\n        edit_block_code = \"\\n\".join(lines_to_replace)\n\n        tokens = count_tokens(edit_block_code)\n        if tokens > self.max_tokens_in_edit_prompt:\n            clarify_msg = f\"Lines {line_numbers.start_line} - {line_numbers.end_line} has {tokens} tokens, which is higher than the maximum allowed {self.max_tokens_in_edit_prompt} tokens in completion\"\n            logger.info(f\"{self} {clarify_msg}. Ask for clarification.\")\n            return f\"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change. If this is not possible you should reject the request.\"\n\n        return None\n\n    def system_prompt(self) -> str:\n        return CLARIFY_CHANGE_SYSTEM_PROMPT\n\n    def messages(self) -> list[Message]:\n        if not self._file_context_str:\n            self.init()\n\n        messages = [\r\n            Message(\r\n                role=\"user\",\r\n                content=f\"<instructions>\\n{self.instructions}\\n</instructions>\\n<code>\\n{self._file_context_str}\\n</code>\",\r\n            )\r\n        ]\n\n        messages.extend(self.retry_messages())\n\n        return messages", "kind": "Chunk", "id": "edit/clarify.py#104.66"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py_ClarifyCodeChange.get_line_span_ClarifyCodeChange.get_line_span.return.start_line_end_line", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 602, "span_ids": ["ClarifyCodeChange.get_line_span"], "start_line": 200, "end_line": 266, "community": null}, "content": "class ClarifyCodeChange(AgenticState):\n\n    def get_line_span(\r\n        self,\r\n        start_line: int,\r\n        end_line: int,\r\n        max_tokens: int,\r\n    ) -> tuple[Optional[int], Optional[int]]:\n        \"\"\"\r\n        Find the span that covers the lines from start_line to end_line\r\n        \"\"\"\n\n        logger.info(\r\n            f\"Get span to change in {self.file_path} from {start_line} to {end_line}\"\r\n        )\n\n        start_block = self.file.module.find_first_by_start_line(start_line)\n        assert (\r\n            start_block is not None\r\n        ), f\"No block found in {self.file_path} that starts at line {start_line}\"\n\n        if start_block.type.group == CodeBlockTypeGroup.STRUCTURE and (\r\n            not end_line or start_block.end_line > end_line\r\n        ):\n            struture_block = start_block\n        else:\n            struture_block = start_block.find_type_group_in_parents(\r\n                CodeBlockTypeGroup.STRUCTURE\r\n            )\n\n        assert (\r\n            struture_block is not None\r\n        ), f\"No structure bock found for {start_block.path_string()}\"\n\n        if struture_block.sum_tokens() < max_tokens:\n            logger.info(\r\n                f\"Return block [{struture_block.path_string()}] ({struture_block.start_line} - {struture_block.end_line}) with {struture_block.sum_tokens()} tokens that covers the provided line span ({start_line} - {end_line})\"\r\n            )\n            return struture_block.start_line, struture_block.end_line\n\n        if not end_line:\n            end_line = start_line\n\n        original_lines = self.file.content.split(\"\\n\")\n        if struture_block.end_line - end_line < 5:\n            logger.info(\r\n                f\"Set parent block [{struture_block.path_string()}] end line {struture_block.end_line} as it's {struture_block.end_line - end_line} lines from the end of the file\"\r\n            )\n            end_line = struture_block.end_line\n        else:\n            end_line = _get_post_end_line_index(\r\n                end_line, struture_block.end_line, original_lines\r\n            )\n            logger.info(f\"Set end line to {end_line} from the end of the parent block\")\n\n        if start_line - struture_block.start_line < 5:\n            logger.info(\r\n                f\"Set parent block [{struture_block.path_string()}] start line {struture_block.start_line} as it's {start_line - struture_block.start_line} lines from the start of the file\"\r\n            )\n            start_line = struture_block.start_line\n        else:\n            start_line = _get_pre_start_line(\r\n                start_line, struture_block.start_line, original_lines\r\n            )\n            logger.info(\r\n                f\"Set start line to {start_line} from the start of the parent block\"\r\n            )\n\n        return start_line, end_line", "kind": "Chunk", "id": "edit/clarify.py#105.66"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py__get_pre_start_line__get_pre_start_line.raise_ValueError_No_non_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 278, "span_ids": ["_get_pre_start_line"], "start_line": 269, "end_line": 299, "community": null}, "content": "def _get_pre_start_line(\r\n    start_line: int, min_start_line: int, content_lines: list[str], max_lines: int = 4\r\n) -> int:\n    if start_line > len(content_lines):\n        raise ValueError(\r\n            f\"start_line {start_line} is out of range ({len(content_lines)}).\"\r\n        )\n\n    if start_line - min_start_line < max_lines:\n        return min_start_line\n\n    start_line_index = start_line - 1\n    start_search_index = max(0, start_line_index - 1)\n    end_search_index = max(min_start_line, start_line_index - max_lines)\n\n    non_empty_indices = []\n\n    for idx in range(start_search_index, end_search_index - 1, -1):\n        if content_lines[idx].strip() != \"\":\n            non_empty_indices.append(idx)\n\n    # Check if any non-empty line was found within the search range\r\n    if non_empty_indices:\n        return non_empty_indices[-1] + 1\n\n    # If no non-empty lines were found, check the start_line itself\r\n    if content_lines[start_line_index].strip() != \"\":\n        return start_line_index + 1\n\n    # If the start_line is also empty, raise an exception\r\n    raise ValueError(\"No non-empty line found within 3 lines above the start_line.\")", "kind": "Chunk", "id": "edit/clarify.py#106.30"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py__get_post_end_line_index_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\clarify.py", "file_name": "clarify.py", "file_type": "text/x-python", "category": "test", "tokens": 275, "span_ids": ["_get_post_end_line_index"], "start_line": 302, "end_line": 331, "community": null}, "content": "def _get_post_end_line_index(\r\n    end_line: int, max_end_line: int, content_lines: list[str], max_lines: int = 4\r\n) -> int:\n    if end_line < 1 or end_line > len(content_lines):\n        raise IndexError(\"end_line is out of range.\")\n\n    if max_end_line - end_line < max_lines:\n        return max_end_line\n\n    end_line_index = end_line - 1\n    start_search_index = min(len(content_lines) - 1, end_line_index + 1)\n    end_search_index = min(max_end_line - 1, end_line_index + max_lines)\n\n    non_empty_indices = []\n\n    for idx in range(start_search_index, end_search_index + 1):\n        if content_lines[idx].strip() != \"\":\n            non_empty_indices.append(idx)\n\n    # Check if any non-empty line was found within the search range\r\n    if non_empty_indices:\n        return non_empty_indices[-1] + 1\n\n    # If no non-empty lines were found, check the end_line itself\r\n    if content_lines[end_line_index].strip() != \"\":\n        return end_line_index + 1\n\n    # If the end_line is also empty, raise an exception\r\n    raise ValueError(\"No non-empty line found within 3 lines after the end_line.\")", "kind": "Chunk", "id": "edit/clarify.py#107.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_logging_CodeChange.rejected.Field_description_W", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 663, "span_ids": ["imports", "CodeChange", "impl:9"], "start_line": 1, "end_line": 85, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field, PrivateAttr\n\nfrom moatless.state import AgenticState, Finished\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    AssistantMessage,\r\n    Content,\r\n    Message,\r\n    UserMessage,\r\n    VerificationError,\r\n)\n\nlogger = logging.getLogger(__name__)\n\nROLE_PROMPT = \"You are autonomous AI assisistant with superior programming skills.\"\n\nMAIN_OBJECTIVE_PROMPT = \"The main objective is to solve a bigger task specified by the user, this is wrapped in a <main_objective> tag.\"\n\nSEARCH_REPLACE_PROMPT = \"\"\"Your task is to solve a smaller task within the main objective. This task is wrapped in a <task> tag.\r\n\r\nThe surrounding code context is wrapped in a <file_context> tag.\r\n\r\nThe code to that should be modified is wrapped in a <search> tag, like this:\r\n<search>\r\n{{CODE}}\r\n</search>\r\n\r\nYour task is to update the code inside the <search> tags based on the current task.\r\n\r\nWhen updating the code, please adhere to the following important rules:\r\n- Fully implement the requested change, but do not make any other changes that were not directly asked for\r\n- Do not add any comments describing your changes \r\n- Indentation and formatting should be the same in the replace code as in the search code\r\n- Ensure the modified code is complete - do not leave any TODOs, placeholder, or missing pieces\r\n- Keep any existing placeholder comments in the <search> block (e.g. # ... other code) - do not remove or implement them\r\n\r\nAfter updating the code, please format your response like this:\r\n\r\n<replace>\r\nput the updated code here\r\n</replace>\r\n\r\nONLY return the code that was inside the original <search> tags, but with the requested modifications made. \r\nDo not include any of the surrounding code.\r\n\r\nIf all code in the search tag should be removed you can return an empty <replace> tag like this:\r\n<replace>\r\n</replace>\r\n\r\nIf you can't do any changes and want to reject the instructions return the rejection reason wrapped in a <reject> tag, like this:\r\n<reject>\r\n{{REASON}}\r\n</reject>\r\n\r\nHere is an example of what the user's request might look like:\r\n\r\n<search>\r\nfrom flask import Flask \r\n</search>\r\n\r\nAnd here is how you should format your response:\r\n\r\n<replace>\r\nimport math\r\nfrom flask import Flask\r\n</replace>\r\n\r\nRemember, only put the updated version of the code from inside the <search> tags in your response, wrapped in <replace>\r\ntags. DO NOT include any other surrounding code than the code in the <search> tag! DO NOT leave out any code that was inside the <search> tag!\r\n\"\"\"\n\n\nCHAIN_OF_THOUGHT_PROMPT = \"Please provide your thoughts on the code change, if any, in the tag <scratch_pad>, and then the code change itself.\"\n\n\nclass CodeChange(ActionRequest):\n    scratch_pad: Optional[str] = Field(\r\n        default=None, description=\"The thoughts on the code change.\"\r\n    )\n    replace: str = Field(..., description=\"The code to replace the existing code with.\")\n    rejected: bool = Field(..., description=\"Whether the code change was rejected.\")", "kind": "Chunk", "id": "edit/edit.py#108.84"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_EditCode_EditCode.init.self._code_to_replace._n_join_lines_to_replac", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 342, "span_ids": ["EditCode", "EditCode.init"], "start_line": 88, "end_line": 116, "community": null}, "content": "class EditCode(AgenticState):\n    instructions: str = Field(..., description=\"The instructions for the code change.\")\n    file_path: str = Field(..., description=\"The path to the file to be updated.\")\n    span_id: Optional[str] = Field(None, description=\"The ID of the span to be updated.\")\n    start_line: int = Field(..., description=\"The start line of the code to be updated.\")\n    end_line: int = Field(..., description=\"The end line of the code to be updated.\")\n\n    show_initial_message: bool = Field(True, description=\"Whether to show the initial message.\")\n    show_file_context: bool = Field(True, description=\"Whether to show the file context.\")\n    verify: bool = Field(True, description=\"Whether to verify the code change.\")\n    chain_of_thought: bool = Field(False, description=\"Whether to use chain of thought reasoning.\")\n\n    max_prompt_file_tokens: int = Field(\r\n        4000,\r\n        description=\"The maximum number of tokens in the file context to show in the prompt.\",\r\n    )\n\n    _code_to_replace: Optional[str] = PrivateAttr(default=None)\n    _retry: int = PrivateAttr(default=0)\n    _messages: list[Message] = PrivateAttr(default_factory=list)\n\n    def init(self):\n        file = self.file_context.get_file(self.file_path)\n        if not file:\n            raise ValueError(f\"File not found: {self.file_path}\")\n\n        code_lines = file.file.content.split(\"\\n\")\n        lines_to_replace = code_lines[self.start_line - 1 : self.end_line]\n        self._code_to_replace = \"\\n\".join(lines_to_replace)", "kind": "Chunk", "id": "edit/edit.py#109.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_EditCode._execute_action_EditCode._execute_action.update_result.file_update_content_by_li", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 341, "span_ids": ["EditCode._execute_action"], "start_line": 118, "end_line": 161, "community": null}, "content": "class EditCode(AgenticState):\n\n    def _execute_action(self, content: Content) -> ActionResponse:\n        self._messages.append(AssistantMessage(content=content.content))\n\n        scratch_pad = None\n\n        if \"<scratch_pad>\" in content.content:\n            scratch_pad = content.content.split(\"<scratch_pad>\")[1].split(\r\n                \"</scratch_pad>\"\r\n            )[0]\n\n        if \"<reject>\" in content.content:\n            rejection_message = content.content.split(\"<reject>\")[1].split(\"</reject>\")[\r\n                0\r\n            ]\n            return ActionResponse.transition(\r\n                \"reject\",\r\n                output={\"message\": rejection_message},\r\n            )\n\n        msg_split = content.content.split(\"<replace>\")\n        if len(msg_split) == 1:\n            if not self._add_prepared_response:\n                logger.warning(\r\n                    f\"No <replace> tag found in response without prepped tag: {msg_split[0]}\"\r\n                )\n                return ActionResponse.retry(\r\n                    \"You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function.\"\r\n                )\n\n            replacement_code = msg_split[0]\n        else:\n            if msg_split[0] and not scratch_pad:\n                scratch_pad = msg_split[0]\n\n            if \"</replace>\" in msg_split[1]:\n                replacement_code = msg_split[1].split(\"</replace>\")[0]\n            else:\n                replacement_code = msg_split[1]\n\n        file = self.file_context.get_file(self.file_path)\n\n        update_result = file.update_content_by_line_numbers(\r\n            self.start_line - 1, self.end_line, replacement_code\r\n        )\n        # ... other code", "kind": "Chunk", "id": "edit/edit.py#110.43"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_EditCode._execute_action.if_update_result_diff_and_EditCode._execute_action.return.ActionResponse_retry_resp", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 757, "span_ids": ["EditCode._execute_action"], "start_line": 163, "end_line": 263, "community": null}, "content": "class EditCode(AgenticState):\n\n    def _execute_action(self, content: Content) -> ActionResponse:\n        # ... other code\n\n        if update_result.diff and update_result.updated:\n            logger.info(\r\n                f\"Updated file {self.file_path} with diff:\\n{update_result.diff}\"\r\n            )\n\n            message = f\"Applied the change to {self.file_path}.\"\n\n            if scratch_pad:\n                message += f\"\\n\\n<scratch_pad>\\n{scratch_pad}</scratch_pad>\"\n\n            original_verification_errors = []\n            if self.verify:\n                logger.info(f\"Verifying original code in {self.file_path}.\")\n                original_verification_errors = self.workspace.verify(file.file)\n\n            self.file_repo.save_file(file_path=file.file_path)\n\n            verification_errors = []\n            if self.verify:\n                logger.info(f\"Verifying updated code in {self.file_path}.\")\n                verification_errors_in_update = self.workspace.verify(file.file)\n\n                if len(verification_errors_in_update) > len(\r\n                    original_verification_errors\r\n                ):\n                    logger.info(\r\n                        f\"Found {len(verification_errors_in_update)} verification errors in updated code. Which differs from the original {len(original_verification_errors)}.\"\r\n                    )\n\n                    for error in verification_errors_in_update:\n                        logger.info(\r\n                            f\"Verification error: {error.code}, {error.message}\"\r\n                        )\n                else:\n                    logger.info(\r\n                        f\"Found {len(verification_errors_in_update)} verification errors in updated code.\"\r\n                    )\n\n                original_error_set = set(\r\n                    (msg.code, msg.message) for msg in original_verification_errors\r\n                )\n\n                updated_error_set = set(\r\n                    (msg.code, msg.message) for msg in verification_errors_in_update\r\n                )\n                added_messages_set = updated_error_set - original_error_set\n\n                verification_errors = [\r\n                    VerificationError(\r\n                        code=msg.code,\r\n                        file_path=file.file_path,\r\n                        message=msg.message,\r\n                        line=msg.line,\r\n                    )\r\n                    for msg in verification_errors_in_update\r\n                    if (msg.code, msg.message) in added_messages_set\r\n                ]\n\n                for error in verification_errors:\n                    logger.info(\r\n                        f\"New verification error: {error.code}, {error.message}\"\r\n                    )\n\n            return ActionResponse.transition(\r\n                \"finish\",\r\n                output={\r\n                    \"message\": message,\r\n                    \"diff\": update_result.diff,\r\n                    \"verification_errors\": verification_errors,\r\n                },\r\n            )\n\n        if self._retry > 2:\n            logger.warning(f\"Failed after {self._retry} retries. Will reject change.\")\n            message = \"\"\n            if scratch_pad:\n                message += f\"<scratch_pad>\\n{scratch_pad}</scratch_pad>\\n\\n\"\n            message = \"Failed to apply changes. Please try again.\"\n            return ActionResponse.transition(\"reject\", output={\"message\": message})\n\n        if update_result.diff:\n            logger.warning(f\"Diff was not applied:\\n{update_result.diff}\")\n            response_message = (\r\n                f\"The following diff was not applied:\\n {update_result.diff}. \\n\"\r\n                f\"Errors:\\n{update_result.error}\\n\"\r\n                f\"Make sure that you return the unchanged code in the replace tag exactly as it is. \"\r\n                f\"If you want to reject the instructions, use the reject function.\"\r\n            )\n\n            self._retry += 1\n\n        else:\n            logger.info(f\"No changes found in {self.file_path}.\")\n            response_message = (\r\n                \"The code in the replace tag is the same as in the search. Use the reject function if you \"\r\n                \"can't do any changes and want to reject the instructions.\"\r\n            )\n\n            self._retry += 1\n\n        return ActionResponse.retry(response_message)", "kind": "Chunk", "id": "edit/edit.py#111.100"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_EditCode.required_fields_EditCode.system_prompt.return.system_prompt", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 153, "span_ids": ["EditCode.system_prompt", "EditCode.finish", "EditCode.required_fields"], "start_line": 265, "end_line": 286, "community": null}, "content": "class EditCode(AgenticState):\n\n    @classmethod\r\n    def required_fields(cls) -> set[str]:\n        return {\"instructions\", \"file_path\", \"span_id\", \"start_line\", \"end_line\"}\n\n    def finish(self, message: str):\n        self.transition_to(Finished(message=message))\n\n    def system_prompt(self) -> str:\n        system_prompt = ROLE_PROMPT\n\n        if self.show_initial_message:\n            system_prompt += \"\\n\\n\"\n            system_prompt += MAIN_OBJECTIVE_PROMPT\n\n        system_prompt += \"\\n\\n\"\n        system_prompt += SEARCH_REPLACE_PROMPT\n\n        if self.chain_of_thought:\n            system_prompt += \"\\n\\n\"\n            system_prompt += CHAIN_OF_THOUGHT_PROMPT\n\n        return system_prompt", "kind": "Chunk", "id": "edit/edit.py#112.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py_EditCode.messages_EditCode.stop_words.return._replace_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\edit.py", "file_name": "edit.py", "file_type": "text/x-python", "category": "test", "tokens": 383, "span_ids": ["EditCode.stop_words", "EditCode.action_type", "EditCode._add_prepared_response", "EditCode.messages"], "start_line": 288, "end_line": 339, "community": null}, "content": "class EditCode(AgenticState):\n\n    def messages(self) -> list[Message]:\n        if not self._code_to_replace:\n            self.init()\n\n        content = \"\"\n        if self.show_initial_message:\n            content = f\"<main_objective>\\n{self.initial_message}\\n</main_objective>\\n\\n\"\n\n        content += f\"<instructions>\\n{self.instructions}\\n</instructions>\\n\"\n\n        if self.show_file_context:\n            file_context_str = self.file_context.create_prompt(\r\n                show_line_numbers=False,\r\n                show_span_ids=False,\r\n                exclude_comments=False,\r\n                show_outcommented_code=True,\r\n                outcomment_code_comment=\"... other code\",\r\n            )\n        else:\n            file_context = self.create_file_context()\n            file_context.add_span_to_context(self.file_path, self.span_id)\n            file_context.expand_context_with_init_spans()\n            file_context.expand_context_with_related_spans(self.max_prompt_file_tokens)\n            file_context_str = file_context.create_prompt(\r\n                show_line_numbers=False,\r\n                show_span_ids=False,\r\n                exclude_comments=False,\r\n                show_outcommented_code=True,\r\n                outcomment_code_comment=\"... other code\",\r\n            )\n        content += f\"<file_context>\\n{file_context_str}\\n</file_context>\\n\"\n\n        content += f\"<search>\\n{self._code_to_replace}\\n</search>\"\n\n        messages = [UserMessage(content=content)]\n\n        messages.extend(self.retry_messages())\n\n        if self._add_prepared_response:\n            messages.append(AssistantMessage(content=\"<replace>\"))\n\n        return messages\n\n    @property\r\n    def _add_prepared_response(self):\n        return \"claude\" in self.model and not self.chain_of_thought\n\n    def action_type(self) -> type[BaseModel] | None:\n        return None\n\n    def stop_words(self):\n        return [\"</replace>\"]", "kind": "Chunk", "id": "edit/edit.py#113.51"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_logging_logger.logging_getLogger_PlanTo", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 143, "span_ids": ["imports"], "start_line": 1, "end_line": 23, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom pydantic import ConfigDict, Field, PrivateAttr\n\nfrom moatless.codeblocks import CodeBlockType\nfrom moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line\nfrom moatless.edit.prompt import (\r\n    CODER_FINAL_SYSTEM_PROMPT,\r\n    CODER_SYSTEM_PROMPT,\r\n    SELECT_SPAN_SYSTEM_PROMPT,\r\n)\nfrom moatless.state import AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    AssistantMessage,\r\n    Message,\r\n    UserMessage,\r\n)\nfrom moatless.verify.lint import VerificationError\n\nlogger = logging.getLogger(\"PlanToCode\")", "kind": "Chunk", "id": "edit/plan.py#114.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_ApplyChange_ApplyChange.model_config.ConfigDict_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 211, "span_ids": ["ApplyChange"], "start_line": 26, "end_line": 57, "community": null}, "content": "class ApplyChange(ActionRequest):\n    \"\"\"\r\n    Request to apply a change to the code.\r\n    \"\"\"\n\n    scratch_pad: str = Field(..., description=\"Your thoughts on the code change.\")\n\n    action: str = Field(\r\n        ...,\r\n        description=\"The action to take, possible values are 'modify', 'review', 'finish', 'reject'\",\r\n    )\n\n    instructions: Optional[str] = Field(\r\n        None, description=\"Instructions to do the code change.\"\r\n    )\n    file_path: Optional[str] = Field(\r\n        None, description=\"The file path of the code to be updated.\"\r\n    )\n    span_id: Optional[str] = Field(\r\n        None, description=\"The span id of the code to be updated.\"\r\n    )\n\n    reject: Optional[str] = Field(\r\n        None, description=\"Reject the request and explain why.\"\r\n    )\n    finish: Optional[str] = Field(\r\n        None, description=\"Finish the request and explain why\"\r\n    )\n\n    model_config = ConfigDict(\r\n        extra=\"allow\",\r\n    )", "kind": "Chunk", "id": "edit/plan.py#115.31"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode_PlanToCode.init.if_not_self__expanded_con.self._expanded_context.True", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 404, "span_ids": ["PlanToCode.init", "PlanToCode"], "start_line": 60, "end_line": 121, "community": null}, "content": "class PlanToCode(AgenticState):\n    message: Optional[str] = Field(\r\n        None,\r\n        description=\"Message to the coder\",\r\n    )\n\n    # TODO: Move to a new state handling changes\r\n    diff: Optional[str] = Field(\r\n        None,\r\n        description=\"The diff of a previous code change.\",\r\n    )\n\n    # TODO: Move to a new state handling lint problems\r\n    verification_errors: list[VerificationError] | None = Field(\r\n        None,\r\n        description=\"The lint errors of the previous code change.\",\r\n    )\n\n    max_prompt_file_tokens: int = Field(\r\n        4000,\r\n        description=\"The maximum number of tokens in the file context to show in the prompt.\",\r\n    )\n\n    max_tokens_in_edit_prompt: int = Field(\r\n        500,\r\n        description=\"The maximum number of tokens in a span to show the edit prompt.\",\r\n    )\n\n    expand_context_with_related_spans: bool = Field(\r\n        True,\r\n        description=\"Whether to expand the context with related spans.\",\r\n    )\n\n    allow_hallucinated_spans: bool = Field(\r\n        False,\r\n        description=\"Whether to allow spans that exists but aren't found in the file context.\",\r\n    )\n\n    finish_on_review: bool = Field(\r\n        False, description=\"Whether to finish the task if a review is requested.\"\r\n    )\n\n    include_message_history: bool = Field(\r\n        True,\r\n        description=\"Whether to include the message history in the prompt.\",\r\n    )\n\n    _expanded_context: bool = PrivateAttr(False)\n\n    def init(self):\n        if not self._expanded_context:\n            self.file_context.expand_context_with_init_spans()\n\n            if (\r\n                self.expand_context_with_related_spans\r\n                and len(self.get_previous_states(self)) == 0\r\n            ):\n                self.file_context.expand_context_with_related_spans(\r\n                    max_tokens=self.max_prompt_file_tokens\r\n                )\n                self.file_context.expand_small_classes(max_tokens=1000)\n            self._expanded_context = True", "kind": "Chunk", "id": "edit/plan.py#116.61"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode._execute_action_PlanToCode.action_type.return.ApplyChange", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 219, "span_ids": ["PlanToCode.action_type", "PlanToCode._execute_action"], "start_line": 123, "end_line": 152, "community": null}, "content": "class PlanToCode(AgenticState):\n\n    def _execute_action(self, action: ApplyChange) -> ActionResponse:\n        if action.action == \"review\":\n            if self.diff and self.finish_on_review:\n                logger.info(\"Review suggested after diff, will finish\")\n                return ActionResponse.transition(\r\n                    trigger=\"finish\", output={\"message\": \"Finish on suggested review.\"}\r\n                )\n            else:\n                return ActionResponse.retry(\r\n                    \"Review isn't possible. If the change is done you can finish or reject the task.\"\r\n                )\n\n        if action.action == \"finish\":\n            return ActionResponse.transition(\r\n                trigger=\"finish\", output={\"message\": action.finish}\r\n            )\n        elif action.reject:\n            return ActionResponse.transition(\r\n                trigger=\"reject\", output={\"message\": action.reject}\r\n            )\n\n        elif action.file_path and action.span_id:\n            return self._request_for_change(action)\n\n        return ActionResponse.retry(\r\n            \"You must either provide an apply_change action or finish.\"\r\n        )\n\n    def action_type(self) -> type[ApplyChange]:\n        return ApplyChange", "kind": "Chunk", "id": "edit/plan.py#117.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode._request_for_change_PlanToCode._request_for_change._If_span_is_for_a_class_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 542, "span_ids": ["PlanToCode._request_for_change"], "start_line": 154, "end_line": 213, "community": null}, "content": "class PlanToCode(AgenticState):\n\n    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:\n        logger.info(\r\n            f\"request_for_change(file_path={rfc.file_path}, span_id={rfc.span_id})\"\r\n        )\n\n        if not rfc.instructions:\n            return ActionResponse.retry(\r\n                f\"Please provide instructions for the code change.\"\r\n            )\n\n        context_file = self.file_context.get_file(rfc.file_path)\n        if not context_file:\n            logger.warning(\r\n                f\"request_for_change: File {rfc.file_path} is not found in the file context.\"\r\n            )\n\n            files_str = \"\"\n            for file in self.file_context.files:\n                files_str += f\" * {file.file_path}\\n\"\n\n            return ActionResponse.retry(\r\n                f\"File {rfc.file_path} is not found in the file context. \"\r\n                f\"You can only request changes to files that are in file context:\\n{files_str}\"\r\n            )\n\n        block_span = context_file.get_block_span(rfc.span_id)\n        if not block_span and context_file.file.supports_codeblocks:\n            spans = self.file_context.get_spans(rfc.file_path)\n            span_ids = [span.span_id for span in spans]\n\n            span_not_in_context = context_file.file.module.find_span_by_id(rfc.span_id)\n            if span_not_in_context and self.allow_hallucinated_spans:\n                logger.info(\r\n                    f\"{self}: Span {rfc.span_id} is not found in the context. Will add it.\"\r\n                )\n                block_span = span_not_in_context\n                self.file_context.add_span_to_context(\r\n                    file_path=rfc.file_path, span_id=block_span.span_id\r\n                )\n\n            # Check if the LLM is referring to a parent span shown in the prompt\r\n            if (\r\n                span_not_in_context\r\n                and span_not_in_context.initiating_block.has_any_span(set(span_ids))\r\n            ):\n                logger.info(\r\n                    f\"{self}: Use span {rfc.span_id} as it's a parent span of a span in the context.\"\r\n                )\n                block_span = span_not_in_context\n\n            if not block_span:\n                span_str = \", \".join(span_ids)\n                logger.warning(\r\n                    f\"{self}: Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n                return ActionResponse.retry(\r\n                    f\"Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n\n        # If span is for a class block, consider the whole class\r\n        # ... other code", "kind": "Chunk", "id": "edit/plan.py#118.59"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode._request_for_change.if_block_span__PlanToCode._request_for_change.return.ActionResponse_transition", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 477, "span_ids": ["PlanToCode._request_for_change"], "start_line": 214, "end_line": 268, "community": null}, "content": "class PlanToCode(AgenticState):\n\n    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:\n        # ... other code\n        if block_span:\n            start_line = block_span.start_line\n            if block_span.initiating_block.type == CodeBlockType.CLASS:\n                tokens = block_span.initiating_block.sum_tokens()\n                end_line = block_span.initiating_block.end_line\n                logger.info(\r\n                    f\"{self}: Span {rfc.span_id} is a class block. Consider the whole class ({block_span.initiating_block.start_line} - {end_line}) with {tokens} tokens.\"\r\n                )\n            else:\n                tokens = block_span.tokens\n                end_line = block_span.end_line\n\n        else:\n            span = context_file.get_span(rfc.span_id)\n            if not span:\n                spans = self.file_context.get_spans(rfc.file_path)\n                span_ids = [span.span_id for span in spans]\n                span_str = \", \".join(span_ids)\n                return ActionResponse.retry(\r\n                    f\"Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n\n            content_lines = context_file.file.content.split(\"\\n\")\n            start_line = _get_pre_start_line(span.start_line, 1, content_lines)\n            end_line = _get_post_end_line_index(\r\n                span.end_line, len(content_lines), content_lines\r\n            )\n\n            # TODO: Support token count in files without codeblock support\r\n            tokens = 0\n\n        if tokens > self.max_tokens_in_edit_prompt:\n            logger.info(\r\n                f\"{self}: Span has {tokens} tokens, which is higher than the maximum allowed \"\r\n                f\"{self.max_tokens_in_edit_prompt} tokens. Ask for clarification.\"\r\n            )\n            return ActionResponse.transition(\r\n                trigger=\"edit_code\",\r\n                output={\r\n                    \"instructions\": rfc.instructions,\r\n                    \"file_path\": rfc.file_path,\r\n                    \"span_id\": rfc.span_id,\r\n                },\r\n            )\n\n        return ActionResponse.transition(\r\n            trigger=\"edit_code\",\r\n            output={\r\n                \"instructions\": rfc.instructions,\r\n                \"file_path\": rfc.file_path,\r\n                \"span_id\": rfc.span_id,\r\n                \"start_line\": start_line,\r\n                \"end_line\": end_line,\r\n            },\r\n        )", "kind": "Chunk", "id": "edit/plan.py#119.54"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode.system_prompt_PlanToCode.to_message.return.response_msg", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 188, "span_ids": ["PlanToCode.to_message", "PlanToCode.system_prompt"], "start_line": 270, "end_line": 292, "community": null}, "content": "class PlanToCode(AgenticState):\n\n    def system_prompt(self) -> str:\n        return (\r\n            CODER_SYSTEM_PROMPT + SELECT_SPAN_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT\r\n        )\n\n    def to_message(self) -> str:\n        response_msg = \"\"\n\n        if self.message:\n            response_msg += self.message\n\n        if self.diff:\n            response_msg += f\"\\n\\n<diff>\\n{self.diff}\\n</diff>\"\n\n        if self.verification_errors:\n            lint_str = \"\"\n            for lint_message in self.verification_errors:\n                lint_str += f\" * {lint_message.code}: {lint_message.message} (line {lint_message.line})\\n\"\n\n            if lint_str:\n                response_msg += f\"\\n\\nThe following lint errors was introduced after this change:\\n<lint_errors>\\n{lint_str}\\n</lint_errors>\"\n\n        return response_msg", "kind": "Chunk", "id": "edit/plan.py#120.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py_PlanToCode.messages_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan.py", "file_name": "plan.py", "file_type": "text/x-python", "category": "test", "tokens": 248, "span_ids": ["PlanToCode.messages"], "start_line": 294, "end_line": 335, "community": null}, "content": "class PlanToCode(AgenticState):\n\n    def messages(self) -> list[Message]:\n        self.init()\n\n        messages: list[Message] = []\n\n        if self.initial_message:\n            content = f\"<issue>\\n{self.initial_message}\\n</issue>\\n\"\n        else:\n            content = \"\"\n\n        previous_states = self.get_previous_states(self)\n\n        for previous_state in previous_states:\n            new_message = previous_state.to_message()\n            if new_message and not content:\n                content = new_message\n            elif new_message:\n                content += f\"\\n\\n{new_message}\"\n\n            messages.append(UserMessage(content=content))\n            messages.append(\r\n                AssistantMessage(\r\n                    action=previous_state.last_action.request,\r\n                )\r\n            )\n            content = \"\"\n\n        content += self.to_message()\n        file_context_str = self.file_context.create_prompt(\r\n            show_span_ids=True,\r\n            exclude_comments=True,\r\n            show_outcommented_code=True,\r\n            outcomment_code_comment=\"... rest of the code\",\r\n        )\n\n        content += f\"\\n\\n<file_context>\\n{file_context_str}\\n</file_context>\"\n\n        messages.append(UserMessage(content=content))\n        messages.extend(self.retry_messages())\n\n        return messages", "kind": "Chunk", "id": "edit/plan.py#121.41"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_logging_logger.logging_getLogger_PlanTo", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 153, "span_ids": ["imports"], "start_line": 1, "end_line": 24, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom pydantic import ConfigDict, Field\n\nfrom moatless.codeblocks.codeblocks import CodeBlockTypeGroup\nfrom moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line\nfrom moatless.edit.prompt import (\r\n    CODER_FINAL_SYSTEM_PROMPT,\r\n    CODER_SYSTEM_PROMPT,\r\n    SELECT_LINES_SYSTEM_PROMPT,\r\n)\nfrom moatless.state import AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    AssistantMessage,\r\n    Message,\r\n    UserMessage,\r\n)\nfrom moatless.utils.tokenizer import count_tokens\nfrom moatless.verify.lint import VerificationError\n\nlogger = logging.getLogger(\"PlanToCode\")", "kind": "Chunk", "id": "edit/plan_lines.py#122.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_ApplyChange_ApplyChange.model_config.ConfigDict_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 200, "span_ids": ["ApplyChange"], "start_line": 27, "end_line": 56, "community": null}, "content": "class ApplyChange(ActionRequest):\n    \"\"\"\r\n    Request to apply a change to the code.\r\n    \"\"\"\n\n    thoughts: str = Field(..., description=\"Your thoughts on the code change.\")\n\n    instructions: Optional[str] = Field(\r\n        None, description=\"Instructions to do the code change.\"\r\n    )\n    file_path: Optional[str] = Field(\r\n        None, description=\"The file path of the code to be updated.\"\r\n    )\n    start_line: Optional[int] = Field(\r\n        None, description=\"The start line of the code to be updated.\"\r\n    )\n    end_line: Optional[int] = Field(\r\n        None, description=\"The end line of the code to be updated.\"\r\n    )\n\n    reject: Optional[str] = Field(\r\n        ..., description=\"Reject the request and explain why.\"\r\n    )\n    finish: Optional[str] = Field(\r\n        None, description=\"Finish the request and explain why\"\r\n    )\n\n    model_config = ConfigDict(\r\n        extra=\"allow\",\r\n    )", "kind": "Chunk", "id": "edit/plan_lines.py#123.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_PlanToCodeWithLines_PlanToCodeWithLines.action_type.return.ApplyChange", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 433, "span_ids": ["PlanToCodeWithLines._execute_action", "PlanToCodeWithLines.init", "PlanToCodeWithLines.action_type", "PlanToCodeWithLines"], "start_line": 59, "end_line": 128, "community": null}, "content": "class PlanToCodeWithLines(AgenticState):\n    message: Optional[str] = Field(\r\n        None,\r\n        description=\"Message to the coder\",\r\n    )\n\n    # TODO: Move to a new state handling changes\r\n    diff: Optional[str] = Field(\r\n        None,\r\n        description=\"The diff of a previous code change.\",\r\n    )\n\n    # TODO: Move to a new state handling lint problems\r\n    verification_errors: list[VerificationError] | None = Field(\r\n        None,\r\n        description=\"The verification errors from the previous code change.\",\r\n    )\n\n    max_tokens_in_edit_prompt: int = Field(\r\n        500,\r\n        description=\"The maximum number of tokens in a span to show the edit prompt.\",\r\n    )\n\n    expand_context_with_related_spans: bool = Field(\r\n        True,\r\n        description=\"Whether to expand the context with related spans.\",\r\n    )\n\n    include_message_history: bool = Field(\r\n        True,\r\n        description=\"Whether to include the message history in the prompt.\",\r\n    )\n\n    def init(self):\n        # TODO: Make addition to context customizable??\r\n\n        for error in self.verification_errors:\n            self.file_context.add_file(\r\n                file_path=error.file_path\r\n            )  # TODO: BY line number!\r\n\n        self.file_context.expand_context_with_init_spans()\n\n        if (\r\n            self.expand_context_with_related_spans\r\n            and len(self.get_previous_states(self)) == 0\r\n        ):\n            self.file_context.expand_context_with_related_spans(max_tokens=4000)\n\n    def _execute_action(self, action: ApplyChange) -> ActionResponse:\n        if action.finish:\n            self.file_context.save()\n\n            return ActionResponse.transition(\r\n                trigger=\"finish\", output={\"message\": action.finish}\r\n            )\n        elif action.reject:\n            return ActionResponse.transition(\r\n                trigger=\"reject\", output={\"message\": action.reject}\r\n            )\n\n        elif action.file_path:\n            return self._request_for_change(action)\n\n        return ActionResponse.retry(\r\n            \"You must either provide an apply_change action or finish.\"\r\n        )\n\n    def action_type(self) -> type[ApplyChange]:\n        return ApplyChange", "kind": "Chunk", "id": "edit/plan_lines.py#124.69"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_PlanToCodeWithLines._request_for_change_PlanToCodeWithLines._request_for_change.return.ActionResponse_transition", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 853, "span_ids": ["PlanToCodeWithLines._request_for_change"], "start_line": 130, "end_line": 220, "community": null}, "content": "class PlanToCodeWithLines(AgenticState):\n\n    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:\n        logger.info(f\"request_for_change(file_path={rfc.file_path}\")\n\n        context_file = self.file_context.get_file(rfc.file_path)\n        if not context_file:\n            logger.warning(\r\n                f\"request_for_change: File {rfc.file_path} is not found in the file context.\"\r\n            )\n\n            files_str = \"\"\n            for file in self.file_context.files:\n                files_str += f\" * {file.file_path}\\n\"\n\n            return ActionResponse.retry(\r\n                f\"File {rfc.file_path} is not found in the file context. \"\r\n                f\"You can only request changes to files that are in file context:\\n{files_str}\"\r\n            )\n\n        if (\r\n            not rfc.start_line\r\n            and context_file.module.sum_tokens() > self.max_tokens_in_edit_prompt\r\n        ):\n            return ActionResponse.retry(\r\n                f\"The file {rfc.file_path} is to big to edit in one go, please provide start and end line numbers to specify the part of the code that needs to be updated.\"\r\n            )\n\n        block = context_file.module.find_first_by_start_line(rfc.start_line)\n\n        if block.type.group == CodeBlockTypeGroup.STRUCTURE:\n            structure_block = block\n        else:\n            structure_block = block.find_type_group_in_parents(\r\n                CodeBlockTypeGroup.STRUCTURE\r\n            )\n\n        if structure_block.sum_tokens() < self.max_tokens_in_edit_prompt:\n            return ActionResponse.transition(\r\n                trigger=\"edit_code\",\r\n                output={\r\n                    \"instructions\": rfc.instructions,\r\n                    \"file_path\": rfc.file_path,\r\n                    \"start_line\": structure_block.start_line,\r\n                    \"end_line\": structure_block.end_line,\r\n                },\r\n            )\n\n        last_structure_block_signature_line = structure_block.children[0].start_line - 1\n        logger.info(\r\n            f\"{self}: Checking if the line numbers only covers a class/function signature to \"\r\n            f\"{structure_block.path_string()} ({structure_block.start_line} - {last_structure_block_signature_line})\"\r\n        )\n        if (\r\n            rfc.start_line == block.start_line\r\n            and last_structure_block_signature_line >= rfc.end_line\r\n        ):\n            clarify_msg = f\"The line numbers {rfc.start_line} - {rfc.end_line} only covers to the signature of the {block.type.value}.\"\n            logger.info(f\"{self}: {clarify_msg}. Ask for clarification.\")\n            # TODO: Ask if this was intentional instead instructing the LLM\r\n            return ActionResponse.retry(\r\n                f\"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change.\"\r\n            )\n\n        code_lines = context_file.file.content.split(\"\\n\")\n        lines_to_replace = code_lines[rfc.start_line - 1 : rfc.end_line]\n\n        edit_block_code = \"\\n\".join(lines_to_replace)\n\n        tokens = count_tokens(edit_block_code)\n        if tokens > self.max_tokens_in_edit_prompt:\n            clarify_msg = f\"Lines {rfc.start_line} - {rfc.end_line} has {tokens} tokens, which is higher than the maximum allowed {self.max_tokens_in_edit_prompt} tokens in completion\"\n            logger.info(f\"{self} {clarify_msg}. Ask for clarification.\")\n            return ActionResponse.retry(\r\n                f\"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change. If this is not possible you should reject the request.\"\r\n            )\n\n        start_line = _get_pre_start_line(\r\n            rfc.start_line, structure_block.start_line, code_lines\r\n        )\n        end_line = _get_post_end_line_index(\r\n            rfc.end_line, structure_block.end_line, code_lines\r\n        )\n\n        return ActionResponse.transition(\r\n            trigger=\"edit_code\",\r\n            output={\r\n                \"instructions\": rfc.instructions,\r\n                \"file_path\": rfc.file_path,\r\n                \"start_line\": start_line,\r\n                \"end_line\": end_line,\r\n            },\r\n        )", "kind": "Chunk", "id": "edit/plan_lines.py#125.90"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_PlanToCodeWithLines.system_prompt_PlanToCodeWithLines.to_message.return.response_msg", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 204, "span_ids": ["PlanToCodeWithLines.system_prompt", "PlanToCodeWithLines.to_message"], "start_line": 222, "end_line": 245, "community": null}, "content": "class PlanToCodeWithLines(AgenticState):\n\n    def system_prompt(self) -> str:\n        return (\r\n            CODER_SYSTEM_PROMPT + SELECT_LINES_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT\r\n        )\n\n    def to_message(self) -> str:\n        response_msg = \"\"\n\n        if self.message:\n            response_msg += self.message\n\n        if self.diff:\n            response_msg += f\"\\n\\n<diff>\\n{self.diff}\\n</diff>\"\n\n        if self.verification_errors:\n            lint_str = \"\"\n            for lint_message in self.verification_errors:\n                if lint_message.code[0] in [\"E\", \"F\"]:\n                    lint_str += f\" * {lint_message.code}: {lint_message.message} (line {lint_message.line})\\n\"\n\n            if lint_str:\n                response_msg += f\"\\n\\nThe following lint errors was introduced after this change:\\n<lint_errors>\\n{lint_str}\\n</lint_errors>\"\n\n        return response_msg", "kind": "Chunk", "id": "edit/plan_lines.py#126.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py_PlanToCodeWithLines.messages_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\plan_lines.py", "file_name": "plan_lines.py", "file_type": "text/x-python", "category": "test", "tokens": 228, "span_ids": ["PlanToCodeWithLines.messages"], "start_line": 247, "end_line": 284, "community": null}, "content": "class PlanToCodeWithLines(AgenticState):\n\n    def messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        content = self.initial_message or \"\"\n\n        previous_states = self.get_previous_states(self)\n\n        for previous_state in previous_states:\n            new_message = previous_state.to_message()\n            if new_message and not content:\n                content = new_message\n            elif new_message:\n                content += f\"\\n\\n{new_message}\"\n\n            messages.append(UserMessage(content=content))\n            messages.append(\r\n                AssistantMessage(\r\n                    action=previous_state.last_action.request,\r\n                )\r\n            )\n            content = \"\"\n\n        content += self.to_message()\n        file_context_str = self.file_context.create_prompt(\r\n            show_span_ids=False,\r\n            show_line_numbers=True,\r\n            exclude_comments=True,\r\n            show_outcommented_code=True,\r\n            outcomment_code_comment=\"... rest of the code\",\r\n        )\n\n        content += f\"\\n\\n<file_context>\\n{file_context_str}\\n</file_context>\"\n\n        messages.append(UserMessage(content=content))\n        messages.extend(self.retry_messages())\n\n        return messages", "kind": "Chunk", "id": "edit/plan_lines.py#127.37"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\prompt.py_CODER_SYSTEM_PROMPT_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\prompt.py", "file_name": "prompt.py", "file_type": "text/x-python", "category": "test", "tokens": 556, "span_ids": ["impl"], "start_line": 1, "end_line": 52, "community": null}, "content": "CODER_SYSTEM_PROMPT = \"\"\"You are an autonomous AI assistant with superior programming skills.\r\n\r\nYour task is to update the code based on a reported issue wraped in the tag <issue>. \r\nThe files relevant to the issue is provided in the tag <file_context>.\r\n\r\nTo get started, carefully review the issue and the file context to understand the changes that need to be made.\r\n\"\"\"\n\nCODER_FINAL_SYSTEM_PROMPT = \"\"\"\r\nAfter receiving the git diff with the updated code, confirm the changes and proceed to the next instruction if applicable.\r\n\r\nUse the finish action when the fix of the issue have been properly implemented.\r\n\r\nIMPORTANT:\r\n * Stick to implementing the requirements exactly as specified, without additional changes or suggestions. \r\n * Limit code changes to only the specific files included in the current context. Don't modify other files or create new ones.\r\n * DO NOT suggest changes in surrounding code not DIRECTLY connected to the task. When you solved the issue in the code you're finsihed!\r\n * DO NOT suggest changes in code that are not in <file_context>.\r\n * DO NOT suggest code reviews! \r\n * Tests are not in scope. Do not search for tests or suggest writing tests.\r\n * When you are confident that all changes are correct, you can finish the task without further verification.\r\n\"\"\"\n\nSELECT_SPAN_SYSTEM_PROMPT = \"\"\"\r\nThe code is separated into code spans; you can update one span at a time.\r\nBefore each code change, you first need to request permission to make the change.\r\nYou do this by using the `ApplyChange` function, which will verify the change and if approved it will do the change and return a git diff and the updated file context.\r\n\r\nWhen requesting permission for a change, include the following details:\r\n\r\n * The instructions of the specific change you intend to make.\r\n * The code span you intend to update.\r\n\"\"\"\n\nSELECT_LINES_SYSTEM_PROMPT = \"\"\"You can update one section of the code at a time.\r\n\r\nBefore each code change, you first need to request permission to make the change.\r\nYou do this by using the `ApplyChange` function, which will verify the change and if approved it will do the change and return a git diff and the updated file context.\r\n\r\nWhen requesting permission for a change, include the following details:\r\n\r\n * The instructions of the specific change you intend to make.\r\n * The start and end line numbers of the code you intend to update.\r\n\"\"\"\n\nCLARIFY_CHANGE_SYSTEM_PROMPT = \"\"\"You are autonomous AI assisistant with superior programming skills.\r\n\r\nPlease read the instruction and code carefully. Identify the specific lines in the code that need to be modified to fulfill the instruction.\r\n\r\nYou should specify the start and end line numbers using this function `specify_lines`.  You can only specify one contiguous range of lines.\r\n\"\"\"", "kind": "Chunk", "id": "edit/prompt.py#128.51"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_logging_IncludeSpan.function_name.Field_None_description_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 211, "span_ids": ["imports", "IncludeSpan"], "start_line": 1, "end_line": 30, "community": null}, "content": "import logging\nfrom typing import Type, Optional, List\n\nfrom pydantic import Field, ConfigDict, PrivateAttr\n\nfrom moatless.codeblocks import CodeBlockType\nfrom moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line\nfrom moatless.edit.prompt import (\r\n    CODER_SYSTEM_PROMPT,\r\n    SELECT_SPAN_SYSTEM_PROMPT,\r\n    CODER_FINAL_SYSTEM_PROMPT,\r\n)\nfrom moatless.state import AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    Message,\r\n    UserMessage,\r\n    AssistantMessage,\r\n    CodeChange,\r\n)\nfrom moatless.verify.lint import VerificationError\n\nlogger = logging.getLogger(\"PlanToCode\")\n\n\nclass IncludeSpan(ActionRequest):\n    file_path: Optional[str] = Field(None, description=\"Find by file path.\")\n    class_name: Optional[str] = Field(None, description=\"Find by class name.\")\n    function_name: Optional[str] = Field(None, description=\"Find by function name.\")", "kind": "Chunk", "id": "edit/review.py#129.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ApplyChange_ApplyChange.model_config.ConfigDict_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 240, "span_ids": ["ApplyChange"], "start_line": 33, "end_line": 68, "community": null}, "content": "class ApplyChange(ActionRequest):\n    \"\"\"\r\n    Request to apply a change to the code.\r\n    \"\"\"\n\n    scratch_pad: str = Field(..., description=\"Your thoughts on the code change.\")\n\n    action: str = Field(\r\n        ...,\r\n        description=\"The action to take, possible values are 'modify', 'review', 'include', 'finish', 'reject'\",\r\n    )\n\n    instructions: Optional[str] = Field(\r\n        None, description=\"Instructions to do the code change.\"\r\n    )\n    file_path: Optional[str] = Field(\r\n        None, description=\"The file path of the code to be updated.\"\r\n    )\n    span_id: Optional[str] = Field(\r\n        None, description=\"The span id of the code to be updated.\"\r\n    )\n\n    include_spans: Optional[List[IncludeSpan]] = Field(\r\n        None, description=\"Find spans to include.\"\r\n    )\n\n    reject: Optional[str] = Field(\r\n        None, description=\"Reject the request and explain why.\"\r\n    )\n    finish: Optional[str] = Field(\r\n        None, description=\"Finish the request and explain why\"\r\n    )\n\n    model_config = ConfigDict(\r\n        extra=\"allow\",\r\n    )", "kind": "Chunk", "id": "edit/review.py#130.35"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ApplyChanges_ApplyChanges.model_config.ConfigDict_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 161, "span_ids": ["ApplyChanges"], "start_line": 71, "end_line": 96, "community": null}, "content": "class ApplyChanges(ActionRequest):\n    \"\"\"\r\n    Request to apply a change to the code.\r\n    \"\"\"\n\n    scratch_pad: str = Field(..., description=\"Your thoughts on the code change.\")\n\n    action: str = Field(\r\n        ...,\r\n        description=\"The action to take, possible values are 'modify', 'review', 'include', 'finish', 'reject'\",\r\n    )\n\n    changes: Optional[List[CodeChange]] = Field(\r\n        None, description=\"The changes to apply.\"\r\n    )\n\n    reject: Optional[str] = Field(\r\n        None, description=\"Reject the request and explain why.\"\r\n    )\n    finish: Optional[str] = Field(\r\n        None, description=\"Finish the request and explain why\"\r\n    )\n\n    model_config = ConfigDict(\r\n        extra=\"allow\",\r\n    )", "kind": "Chunk", "id": "edit/review.py#131.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode_ReviewCode.init.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 373, "span_ids": ["ReviewCode", "ReviewCode.init"], "start_line": 99, "end_line": 156, "community": null}, "content": "class ReviewCode(AgenticState):\n    message: Optional[str] = Field(\r\n        None,\r\n        description=\"Message to the coder\",\r\n    )\n\n    # TODO: Move to a new state handling changes\r\n    diff: Optional[str] = Field(\r\n        None,\r\n        description=\"The diff of a previous code change.\",\r\n    )\n\n    max_prompt_file_tokens: int = Field(\r\n        4000,\r\n        description=\"The maximum number of tokens in the file context to show in the prompt.\",\r\n    )\n\n    max_tokens_in_edit_prompt: int = Field(\r\n        500,\r\n        description=\"The maximum number of tokens in a span to show the edit prompt.\",\r\n    )\n\n    allow_hallucinated_spans: bool = Field(\r\n        False,\r\n        description=\"Allow hallucinated spans to be used in the edit prompt.\",\r\n    )\n\n    finish_on_review: bool = Field(\r\n        False, description=\"Whether to finish the task if a review is requested.\"\r\n    )\n\n    finish_on_no_errors: bool = Field(\r\n        False,\r\n        description=\"Whether to finish the task if no verification errors are found.\",\r\n    )\n\n    include_message_history: bool = Field(\r\n        True,\r\n        description=\"Whether to include the message history in the prompt.\",\r\n    )\n\n    _verification_errors: List[VerificationError] = PrivateAttr(default_factory=list)\n\n    def init(self) -> Optional[ActionResponse]:\n        self._verification_errors = self.workspace.verify()\n\n        self.file_context.reset_verification_errors()\n\n        for verification_error in self._verification_errors:\n            logger.info(f\"Verification error: {verification_error}\")\n            self.file_context.add_verification_error(verification_error)\n\n        if self.finish_on_no_errors and not self._verification_errors:\n            return ActionResponse.transition(\r\n                trigger=\"finish\", output={\"message\": \"No errors to review.\"}\r\n            )\n\n        return None", "kind": "Chunk", "id": "edit/review.py#132.57"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode._execute_action_ReviewCode.action_type.return.ApplyChange", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 678, "span_ids": ["ReviewCode.action_type", "ReviewCode._execute_action"], "start_line": 158, "end_line": 246, "community": null}, "content": "class ReviewCode(AgenticState):\n\n    def _execute_action(self, action: ApplyChange) -> ActionResponse:\n        if action.action == \"review\":\n            if self.diff and self.finish_on_review:\n                logger.info(f\"Review suggested after diff, will finish\")\n                return ActionResponse.transition(\r\n                    trigger=\"finish\", output={\"message\": \"Finish on suggested review.\"}\r\n                )\n            else:\n                return ActionResponse.retry(\r\n                    \"Review isn't possible. If the change is done you can finish or reject the task.\"\r\n                )\n\n        if action.include_spans:\n            found_response = \"\"\n            not_found_response = \"\"\n            for include_span in action.include_spans:\n                logger.info(\r\n                    f\"include_span(file_path={include_span.file_path}, class_name={include_span.class_name}, function_name={include_span.function_name})\"\r\n                )\n\n                if not include_span.class_name and not include_span.function_name:\n                    return ActionResponse.retry(\r\n                        \"You must provide either a class name or a function name or both.\"\r\n                    )\n\n                search_response = self.workspace.code_index.find_by_name(\r\n                    class_names=[include_span.class_name],\r\n                    function_names=[include_span.function_name],\r\n                )\n                if len(search_response.hits) == 1:\n                    found_response += f\" * {search_response.hits[0].file_path}\\n\"\n                    for span in search_response.hits[0].spans:\n                        self.file_context.add_span_to_context(\r\n                            file_path=search_response.hits[0].file_path,\r\n                            span_id=span.span_id,\r\n                        )\n                        found_response += f\"   - {span}\\n\"\n                elif len(search_response.hits) > 1 and include_span.file_path:\n                    file_name = include_span.file_path.split(\"/\")[-1]\n                    for hit in search_response.hits:\n                        if file_name in hit.file_path:\n                            found_response += f\" * {hit.file_path}\\n\"\n                            for span in hit.spans:\n                                self.file_context.add_span_to_context(\r\n                                    file_path=hit.file_path,\r\n                                    span_id=span.span_id,\r\n                                )\n                                found_response += f\"   - {span}\\n\"\n                else:\n                    if include_span.file_path:\n                        not_found_response += f\"{include_span.file_path}\"\n\n                    if include_span.class_name:\n                        not_found_response += f\" class: {include_span.class_name}\"\n\n                    if include_span.function_name:\n                        not_found_response += f\" function: {include_span.function_name}\"\n\n            response = \"\"\n            if found_response:\n                response += f\"Found the following spans:\\n{found_response}\"\n\n            if not_found_response:\n                response += (\r\n                    f\"\\nCouldn't find the following spans:\\n{not_found_response}\"\r\n                )\n\n            return ActionResponse.retry(response)\n\n        if action.finish:\n            self.file_context.save()\n\n            return ActionResponse.transition(\r\n                trigger=\"finish\", output={\"message\": action.finish}\r\n            )\n        elif action.reject:\n            return ActionResponse.transition(\r\n                trigger=\"reject\", output={\"message\": action.reject}\r\n            )\n\n        elif action.file_path and action.span_id:\n            return self._request_for_change(action)\n\n        return ActionResponse.retry(\r\n            \"You must either provide an apply_change action or finish.\"\r\n        )\n\n    def action_type(self) -> Type[ApplyChange]:\n        return ApplyChange", "kind": "Chunk", "id": "edit/review.py#133.88"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode._request_for_change_ReviewCode._request_for_change.if_block_span_.else_.tokens.0", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 806, "span_ids": ["ReviewCode._request_for_change"], "start_line": 248, "end_line": 332, "community": null}, "content": "class ReviewCode(AgenticState):\n\n    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:\n        logger.info(\r\n            f\"request_for_change(file_path={rfc.file_path}, span_id={rfc.span_id})\"\r\n        )\n\n        context_file = self.file_context.get_file(rfc.file_path)\n        if not context_file:\n            logger.warning(\r\n                f\"request_for_change: File {rfc.file_path} is not found in the file context.\"\r\n            )\n\n            files_str = \"\"\n            for file in self.file_context.files:\n                files_str += f\" * {file.file_path}\\n\"\n\n            return ActionResponse.retry(\r\n                f\"File {rfc.file_path} is not found in the file context. \"\r\n                f\"You can only request changes to files that are in file context:\\n{files_str}. You can try to add them by using the include_span action.\"\r\n            )\n\n        block_span = context_file.get_block_span(rfc.span_id)\n        if not block_span and context_file.file.supports_codeblocks:\n            spans = self.file_context.get_spans(rfc.file_path)\n            span_ids = [span.span_id for span in spans]\n\n            span_not_in_context = context_file.file.module.find_span_by_id(rfc.span_id)\n            if span_not_in_context and self.allow_hallucinated_spans:\n                logger.info(\r\n                    f\"{self}: Span {rfc.span_id} is not found in the context. Will add it.\"\r\n                )\n                block_span = span_not_in_context\n                self.file_context.add_span_to_context(\r\n                    file_path=rfc.file_path, span_id=block_span.span_id\r\n                )\n\n            # Check if the LLM is referring to a parent span shown in the prompt\r\n            if (\r\n                span_not_in_context\r\n                and span_not_in_context.initiating_block.has_any_span(set(span_ids))\r\n            ):\n                logger.info(\r\n                    f\"{self}: Use span {rfc.span_id} as it's a parent span of a span in the context.\"\r\n                )\n                block_span = span_not_in_context\n\n            if not block_span:\n                span_str = \", \".join(span_ids)\n                logger.warning(\r\n                    f\"{self}: Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n                return ActionResponse.retry(\r\n                    f\"Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n\n        # If span is for a class block, consider the whole class\r\n        if block_span:\n            start_line = block_span.start_line\n            if block_span.initiating_block.type == CodeBlockType.CLASS:\n                tokens = block_span.initiating_block.sum_tokens()\n                end_line = block_span.initiating_block.end_line\n                logger.info(\r\n                    f\"{self}: Span {rfc.span_id} is a class block. Consider the whole class ({block_span.initiating_block.start_line} - {end_line}) with {tokens} tokens.\"\r\n                )\n            else:\n                tokens = block_span.tokens\n                end_line = block_span.end_line\n\n        else:\n            span = context_file.get_span(rfc.span_id)\n            if not span:\n                spans = self.file_context.get_spans(rfc.file_path)\n                span_ids = [span.span_id for span in spans]\n                span_str = \", \".join(span_ids)\n                return ActionResponse.retry(\r\n                    f\"Span not found: {rfc.span_id}. Available spans: {span_str}\"\r\n                )\n\n            content_lines = context_file.file.content.split(\"\\n\")\n            start_line = _get_pre_start_line(span.start_line, 1, content_lines)\n            end_line = _get_post_end_line_index(\r\n                span.end_line, len(content_lines), content_lines\r\n            )\n\n            # TODO: Support token count in files without codeblock support\r\n            tokens = 0\n        # ... other code", "kind": "Chunk", "id": "edit/review.py#134.84"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode._request_for_change.if_tokens_self_max_toke_ReviewCode._request_for_change.return.ActionResponse_transition", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 197, "span_ids": ["ReviewCode._request_for_change"], "start_line": 334, "end_line": 357, "community": null}, "content": "class ReviewCode(AgenticState):\n\n    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:\n        # ... other code\n\n        if tokens > self.max_tokens_in_edit_prompt:\n            logger.info(\r\n                f\"{self}: Span has {tokens} tokens, which is higher than the maximum allowed \"\r\n                f\"{self.max_tokens_in_edit_prompt} tokens. Ask for clarification.\"\r\n            )\n            return ActionResponse.transition(\r\n                trigger=\"edit_code\",\r\n                output={\r\n                    \"instructions\": rfc.instructions,\r\n                    \"file_path\": rfc.file_path,\r\n                    \"span_id\": rfc.span_id,\r\n                },\r\n            )\n\n        return ActionResponse.transition(\r\n            trigger=\"edit_code\",\r\n            output={\r\n                \"instructions\": rfc.instructions,\r\n                \"file_path\": rfc.file_path,\r\n                \"span_id\": rfc.span_id,\r\n                \"start_line\": start_line,\r\n                \"end_line\": end_line,\r\n            },\r\n        )", "kind": "Chunk", "id": "edit/review.py#135.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode.system_prompt_ReviewCode.to_message.return.response_msg", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 181, "span_ids": ["ReviewCode.system_prompt", "ReviewCode.to_message"], "start_line": 359, "end_line": 382, "community": null}, "content": "class ReviewCode(AgenticState):\n\n    def system_prompt(self) -> str:\n        return (\r\n            CODER_SYSTEM_PROMPT + SELECT_SPAN_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT\r\n        )\n\n    def to_message(self) -> str:\n        response_msg = \"\"\n\n        if self.message:\n            response_msg += self.message\n\n        if self.diff:\n            response_msg += f\"\\n\\n<diff>\\n{self.diff}\\n</diff>\"\n\n        error_str = \"\"\n        for verification_error in self._verification_errors:\n            error_str += f\" * {verification_error.code}: {verification_error.message} (file: {verification_error.file_path}, line {verification_error.line})\\n\"\n\n        if error_str:\n            response_msg += (\r\n                f\"\\n\\nThe following verification errors was found:\\n\\n{error_str}\\n\"\r\n            )\n\n        return response_msg", "kind": "Chunk", "id": "edit/review.py#136.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py_ReviewCode.messages_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\edit\\review.py", "file_name": "review.py", "file_type": "text/x-python", "category": "test", "tokens": 251, "span_ids": ["ReviewCode.messages"], "start_line": 384, "end_line": 424, "community": null}, "content": "class ReviewCode(AgenticState):\n\n    def messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        if self.initial_message:\n            content = f\"<main_objective>\\n{self.initial_message}\\n</main_objective>\"\n        else:\n            content = \"\"\n\n        previous_states = self.get_previous_states(self)\n\n        for previous_state in previous_states:\n            new_message = previous_state.to_message()\n            if new_message and not content:\n                content = new_message\n            elif new_message:\n                content += f\"\\n\\n{new_message}\"\n\n            messages.append(UserMessage(content=content))\n            messages.append(\r\n                AssistantMessage(\r\n                    action=previous_state.last_action.request,\r\n                )\r\n            )\n            content = \"\"\n\n        content += self.to_message()\n        file_context_str = self.file_context.create_prompt(\r\n            show_span_ids=True,\r\n            show_line_numbers=True,\r\n            exclude_comments=False,\r\n            show_outcommented_code=True,\r\n            outcomment_code_comment=\"... rest of the code\",\r\n        )\n\n        content += f\"\\n\\n<file_context>\\n{file_context_str}\\n</file_context>\"\n\n        messages.append(UserMessage(content=content))\n        messages.extend(self.retry_messages())\n\n        return messages", "kind": "Chunk", "id": "edit/review.py#137.40"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_json_CurrentPromptSpan.tokens.0", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 223, "span_ids": ["RankedFileSpan", "imports", "CurrentPromptSpan", "ContextSpan"], "start_line": 1, "end_line": 40, "community": null}, "content": "import json\nimport logging\nfrom dataclasses import dataclass\nfrom typing import Optional, List, Dict, Set\n\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic.v1 import PrivateAttr\n\nfrom moatless.codeblocks import CodeBlockType\nfrom moatless.codeblocks.codeblocks import (\r\n    BlockSpan,\r\n    CodeBlock,\r\n    CodeBlockTypeGroup,\r\n    SpanMarker,\r\n    SpanType,\r\n)\nfrom moatless.repository import CodeFile, FileRepository, UpdateResult\nfrom moatless.types import FileWithSpans\n\nlogger = logging.getLogger(__name__)\n\n\nclass RankedFileSpan(BaseModel):\n    file_path: str\n    span_id: str\n    rank: int = 0\n    tokens: int = 0\n\n\nclass ContextSpan(BaseModel):\n    span_id: str\n    start_line: Optional[int] = None\n    end_line: Optional[int] = None\n    tokens: Optional[int] = None\n\n\n@dataclass\r\nclass CurrentPromptSpan:\n    span_id: Optional[str] = None\n    tokens: int = 0", "kind": "Chunk", "id": "moatless/file_context.py#138.39"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile_ContextFile.span_ids.return._span_span_id_for_span_in", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 159, "span_ids": ["ContextFile.span_ids", "ContextFile", "ContextFile.file_path", "ContextFile.__init__", "ContextFile.module", "ContextFile.model_dump", "ContextFile.content"], "start_line": 43, "end_line": 70, "community": null}, "content": "class ContextFile(BaseModel):\n    file: CodeFile\n    spans: List[ContextSpan] = []\n    show_all_spans: bool = False\n\n    def __init__(self, **data):\n        super().__init__(**data)\n\n    def model_dump(self, **kwargs):\n        data = super().model_dump(**kwargs, exclude={\"file\"})\n        data[\"file_path\"] = self.file.file_path\n        return data\n\n    @property\r\n    def file_path(self):\n        return self.file.file_path\n\n    @property\r\n    def module(self):\n        return self.file.module\n\n    @property\r\n    def content(self):\n        return self.file.content\n\n    @property\r\n    def span_ids(self):\n        return {span.span_id for span in self.spans}", "kind": "Chunk", "id": "moatless/file_context.py#139.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.to_prompt_ContextFile.to_prompt.return.f_self_file_path_n_n", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 223, "span_ids": ["ContextFile.to_prompt"], "start_line": 72, "end_line": 102, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def to_prompt(\r\n        self,\r\n        show_span_ids=False,\r\n        show_line_numbers=False,\r\n        exclude_comments=False,\r\n        show_outcommented_code=False,\r\n        outcomment_code_comment: str = \"...\",\r\n    ):\n        if self.file.supports_codeblocks:\n            if (\r\n                not self.show_all_spans\r\n                and self.span_ids is not None\r\n                and len(self.span_ids) == 0\r\n            ):\n                logger.warning(\r\n                    f\"No span ids provided for {self.file_path}, return empty\"\r\n                )\n                return \"\"\n\n            code = self._to_prompt(\r\n                code_block=self.module,\r\n                show_span_id=show_span_ids,\r\n                show_line_numbers=show_line_numbers,\r\n                outcomment_code_comment=outcomment_code_comment,\r\n                show_outcommented_code=show_outcommented_code,\r\n                exclude_comments=exclude_comments,\r\n            )\n        else:\n            code = self._to_prompt_with_line_spans(show_span_id=show_span_ids)\n\n        return f\"{self.file_path}\\n```\\n{code}\\n```\\n\"", "kind": "Chunk", "id": "moatless/file_context.py#140.30"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile._find_span_ContextFile._within_span.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 132, "span_ids": ["ContextFile._find_span", "ContextFile._within_span"], "start_line": 104, "end_line": 122, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def _find_span(self, codeblock: CodeBlock) -> Optional[ContextSpan]:\n        if not codeblock.belongs_to_span:\n            return None\n\n        for span in self.spans:\n            if codeblock.belongs_to_span.span_id == span.span_id:\n                return span\n\n        return None\n\n    def _within_span(self, line_no: int) -> Optional[ContextSpan]:\n        for span in self.spans:\n            if (\r\n                span.start_line\r\n                and span.end_line\r\n                and span.start_line <= line_no <= span.end_line\r\n            ):\n                return span\n        return None", "kind": "Chunk", "id": "moatless/file_context.py#141.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile._to_prompt_with_line_spans_ContextFile._to_prompt_with_line_spans.return.prompt_content", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 164, "span_ids": ["ContextFile._to_prompt_with_line_spans"], "start_line": 124, "end_line": 146, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def _to_prompt_with_line_spans(self, show_span_id: bool = False) -> str:\n        content_lines = self.content.split(\"\\n\")\n\n        if not self.span_ids:\n            return self.content\n\n        prompt_content = \"\"\n        outcommented = True\n        for i, line in enumerate(content_lines):\n            line_no = i + 1\n\n            span = self._within_span(line_no)\n            if span:\n                if outcommented and show_span_id:\n                    prompt_content += f\"<span id={span.span_id}>\\n\"\n\n                prompt_content += line + \"\\n\"\n                outcommented = False\n            elif not outcommented:\n                prompt_content += \"... other code\\n\"\n                outcommented = True\n\n        return prompt_content", "kind": "Chunk", "id": "moatless/file_context.py#142.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile._to_prompt_ContextFile._to_prompt.return.contents", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 735, "span_ids": ["ContextFile._to_prompt"], "start_line": 148, "end_line": 251, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def _to_prompt(\r\n        self,\r\n        code_block: CodeBlock,\r\n        current_span: Optional[CurrentPromptSpan] = None,\r\n        show_outcommented_code: bool = True,\r\n        outcomment_code_comment: str = \"...\",\r\n        show_span_id: bool = False,\r\n        show_line_numbers: bool = False,\r\n        exclude_comments: bool = False,\r\n    ):\n        if current_span is None:\n            current_span = CurrentPromptSpan()\n        contents = \"\"\n\n        outcommented_block = None\n        for _i, child in enumerate(code_block.children):\n            if exclude_comments and child.type.group == CodeBlockTypeGroup.COMMENT:\n                continue\n\n            show_new_span_id = False\n            show_child = False\n            child_span = self._find_span(child)\n\n            if child_span:\n                if child_span.span_id != current_span.span_id:\n                    show_child = True\n                    show_new_span_id = show_span_id\n                    current_span = CurrentPromptSpan(child_span.span_id)\n                elif not child_span.tokens:\n                    show_child = True\n                else:\r\n                    # Count all tokens in child block if it's not a structure (function or class) or a 'compound' (like an 'if' or 'for' clause)\r\n                    if (\r\n                        child.type.group == CodeBlockTypeGroup.IMPLEMENTATION\r\n                        and child.type\r\n                        not in [CodeBlockType.COMPOUND, CodeBlockType.DEPENDENT_CLAUSE]\r\n                    ):\n                        child_tokens = child.sum_tokens()\n                    else:\n                        child_tokens = child.tokens\n\n                    if current_span.tokens + child_tokens <= child_span.tokens:\n                        show_child = True\n\n                    current_span.tokens += child_tokens\n\n            elif (\r\n                not child.belongs_to_span or child.belongs_to_any_span not in self.spans\r\n            ) and child.has_any_span(self.span_ids):\n                show_child = True\n\n                if (\r\n                    child.belongs_to_span\r\n                    and current_span.span_id != child.belongs_to_span.span_id\r\n                ):\n                    show_new_span_id = show_span_id\n                    current_span = CurrentPromptSpan(child.belongs_to_span.span_id)\n\n            if self.show_all_spans:\n                show_child = True\n\n            if show_child:\n                if outcommented_block:\n                    contents += outcommented_block._to_prompt_string(\r\n                        show_line_numbers=show_line_numbers\r\n                    )\n\n                outcommented_block = None\n\n                contents += child._to_prompt_string(\r\n                    show_span_id=show_new_span_id,\r\n                    show_line_numbers=show_line_numbers,\r\n                    span_marker=SpanMarker.TAG,\r\n                )\n                contents += self._to_prompt(\r\n                    code_block=child,\r\n                    exclude_comments=exclude_comments,\r\n                    show_outcommented_code=show_outcommented_code,\r\n                    outcomment_code_comment=outcomment_code_comment,\r\n                    show_span_id=show_span_id,\r\n                    current_span=current_span,\r\n                    show_line_numbers=show_line_numbers,\r\n                )\n            elif show_outcommented_code and not outcommented_block:\n                outcommented_block = child.create_commented_out_block(\r\n                    outcomment_code_comment\r\n                )\n                outcommented_block.start_line = child.start_line\n\n        if (\r\n            outcomment_code_comment\r\n            and outcommented_block\r\n            and child.type\r\n            not in [\r\n                CodeBlockType.COMMENT,\r\n                CodeBlockType.COMMENTED_OUT_CODE,\r\n                CodeBlockType.SPACE,\r\n            ]\r\n        ):\n            contents += outcommented_block._to_prompt_string(\r\n                show_line_numbers=show_line_numbers\r\n            )\n\n        return contents", "kind": "Chunk", "id": "moatless/file_context.py#143.103"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.context_size_ContextFile.add_spans.for_span_id_in_span_ids_.self_add_span_span_id_to", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 140, "span_ids": ["ContextFile.add_spans", "ContextFile.context_size"], "start_line": 253, "end_line": 273, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def context_size(self):\n        if self.file.supports_codeblocks:\n            if self.span_ids is None:\n                return self.module.sum_tokens()\n            else:\n                tokens = 0\n                for span_id in self.span_ids:\n                    span = self.module.find_span_by_id(span_id)\n                    if span:\n                        tokens += span.tokens\n                return tokens\n        else:\n            return 0  # TODO: Support context size...\r\n\n    def add_spans(\r\n        self,\r\n        span_ids: Set[str],\r\n        tokens: Optional[int] = None,\r\n    ):\n        for span_id in span_ids:\n            self.add_span(span_id, tokens)", "kind": "Chunk", "id": "moatless/file_context.py#144.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.add_span_ContextFile.add_span.if_existing_span_.else_.if_span_.else_.logger_info_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 136, "span_ids": ["ContextFile.add_span"], "start_line": 275, "end_line": 293, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def add_span(\r\n        self,\r\n        span_id: str,\r\n        tokens: Optional[int] = None,\r\n    ):\n        existing_span = next(\r\n            (span for span in self.spans if span.span_id == span_id), None\r\n        )\n\n        if existing_span:\n            existing_span.tokens = tokens\n        else:\n            span = self.module.find_span_by_id(span_id)\n            if span:\n                self.spans.append(ContextSpan(span_id=span_id, tokens=tokens))\n            else:\n                logger.info(\r\n                    f\"Could not find span with id {span_id} in file {self.file_path}\"\r\n                )", "kind": "Chunk", "id": "moatless/file_context.py#145.18"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.add_line_span_ContextFile.add_line_span.if_module_.else_.logger_warning_f_Could_no", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 119, "span_ids": ["ContextFile.add_line_span"], "start_line": 295, "end_line": 306, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def add_line_span(self, start_line: int, end_line: int):\n        module = self.file.module\n\n        logger.info(f\"Adding line span {start_line} - {end_line} to {self.file_path}\")\n        if module:\n            block = module.find_first_by_start_line(start_line)\n            structure_block = block.structure_block()\n            self.spans.append(\r\n                ContextSpan(span_id=structure_block.belongs_to_span.span_id)\r\n            )\n        else:\n            logger.warning(f\"Could not find module for file {self.file_path}\")", "kind": "Chunk", "id": "moatless/file_context.py#146.11"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.remove_span_ContextFile.get_span.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 258, "span_ids": ["ContextFile.get_block_span", "ContextFile.get_spans", "ContextFile.remove_span", "ContextFile.get_span"], "start_line": 308, "end_line": 340, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def remove_span(self, span_id: str):\n        self.spans = [span for span in self.spans if span.span_id != span_id]\n\n    def get_spans(self) -> List[BlockSpan]:\n        block_spans = []\n        for span in self.spans:\n            if not self.file.supports_codeblocks:\n                continue\n\n            block_span = self.module.find_span_by_id(span.span_id)\n            if block_span:\n                block_spans.append(block_span)\n        return block_spans\n\n    def get_block_span(self, span_id: str) -> Optional[BlockSpan]:\n        if not self.file.supports_codeblocks:\n            return None\n        for span in self.spans:\n            if span.span_id == span_id:\n                block_span = self.module.find_span_by_id(span_id)\n                if block_span:\n                    return block_span\n                else:\n                    logger.warning(\r\n                        f\"Could not find span with id {span_id} in file {self.file_path}\"\r\n                    )\n        return None\n\n    def get_span(self, span_id: str) -> Optional[ContextSpan]:\n        for span in self.spans:\n            if span.span_id == span_id:\n                return span\n        return None", "kind": "Chunk", "id": "moatless/file_context.py#147.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.update_content_by_line_numbers_ContextFile.update_content_by_line_numbers.return.update_result", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 116, "span_ids": ["ContextFile.update_content_by_line_numbers"], "start_line": 342, "end_line": 355, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def update_content_by_line_numbers(\r\n        self, start_line_index: int, end_line_index: int, replacement_content: str\r\n    ) -> UpdateResult:\n        update_result = self.file.update_content_by_line_numbers(\r\n            start_line_index, end_line_index, replacement_content\r\n        )\n\n        if update_result.new_span_ids:\n            logger.info(\r\n                f\"Adding new spans: {update_result.new_span_ids} to {self.file_path}\"\r\n            )\n            self.add_spans(update_result.new_span_ids)\n\n        return update_result", "kind": "Chunk", "id": "moatless/file_context.py#148.13"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.expand_context_with_init_spans_ContextFile.expand_context_with_init_spans.for_span_id_in_self_span_.if_span_and_span_initiati.for_child_in_span_initiat.if_.self_add_span_child_belon", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 195, "span_ids": ["ContextFile.expand_context_with_init_spans"], "start_line": 357, "end_line": 378, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def expand_context_with_init_spans(self):\n        init_spans = set()\n        if not self.file.supports_codeblocks:\n            return\n\n        for child in self.module.children:\n            if (\r\n                child.type == CodeBlockType.IMPORT\r\n                and child.belongs_to_span.span_type == SpanType.INITATION\r\n                and child.belongs_to_span.span_id not in init_spans\r\n            ):\n                self.add_span(child.belongs_to_span.span_id)\n\n        for span_id in self.span_ids:\n            span = self.module.find_span_by_id(span_id)\n            if span and span.initiating_block.type == CodeBlockType.CLASS:\n                for child in span.initiating_block.children:\n                    if (\r\n                        child.belongs_to_span.span_type == SpanType.INITATION\r\n                        and child.belongs_to_span.span_id not in init_spans\r\n                    ):\n                        self.add_span(child.belongs_to_span.span_id)", "kind": "Chunk", "id": "moatless/file_context.py#149.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_ContextFile.expand_small_classes_ContextFile.expand_small_classes.if_len_self_spans_1_.if_.for_span_id_in_span_initi.self_add_span_span_id_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 158, "span_ids": ["ContextFile.expand_small_classes"], "start_line": 380, "end_line": 397, "community": null}, "content": "class ContextFile(BaseModel):\n\n    def expand_small_classes(self, max_tokens: int):\n        \"\"\"\r\n        Expand small classes with no other spans selected if the context allows it.\r\n\r\n        TODO: This a temporary solution, should be handled by asking the LLM to specify spans in the Identify step.\r\n        \"\"\"\n        if not self.file.supports_codeblocks:\n            return\n\n        if len(self.spans) == 1:\n            span = self.module.find_span_by_id(self.spans[0].span_id)\n            if (\r\n                span\r\n                and span.initiating_block.type == CodeBlockType.CLASS\r\n                and span.initiating_block.sum_tokens() < max_tokens\r\n            ):\n                for span_id in span.initiating_block.get_all_span_ids():\n                    self.add_span(span_id)", "kind": "Chunk", "id": "moatless/file_context.py#150.17"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext_FileContext.from_dict.return.instance", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 347, "span_ids": ["FileContext.from_dir", "FileContext.__init__", "FileContext", "FileContext.from_dict", "FileContext.from_json"], "start_line": 400, "end_line": 438, "community": null}, "content": "class FileContext(BaseModel):\n    _repo: FileRepository = PrivateAttr()\n    _file_context: Dict[str, ContextFile] = PrivateAttr(default_factory=dict)\n    _max_tokens: int = PrivateAttr(default=4000)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def __init__(self, repo: FileRepository, **data):\n        super().__init__(**data)\n        self._repo = repo\n        if \"_file_context\" not in self.__dict__:\n            self.__dict__[\"_file_context\"] = {}\n        if \"_max_tokens\" not in self.__dict__:\n            self.__dict__[\"_max_tokens\"] = data.get(\"max_tokens\", 4000)\n\n    @classmethod\r\n    def from_dir(cls, repo_dir: str, max_tokens: int = 4000):\n        repo = FileRepository(repo_dir)\n        instance = cls(max_tokens=max_tokens, repo=repo)\n        return instance\n\n    @classmethod\r\n    def from_json(cls, repo_dir: str, json_data: str):\n        \"\"\"\r\n        Create a FileContext instance from JSON data.\r\n\r\n        :param repo_dir: The repository directory path.\r\n        :param json_data: A JSON string representing the FileContext data.\r\n        :return: A new FileContext instance.\r\n        \"\"\"\n        data = json.loads(json_data)\n        return cls.from_dict(repo_dir, data)\n\n    @classmethod\r\n    def from_dict(cls, repo_dir: str, data: Dict):\n        repo = FileRepository(repo_dir)\n        instance = cls(max_tokens=data.get(\"max_tokens\", 4000), repo=repo)\n        instance.load_files_from_dict(data.get(\"files\", []))\n        return instance", "kind": "Chunk", "id": "moatless/file_context.py#151.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.load_files_from_dict_FileContext.load_files_from_dict.for_file_data_in_files_.self__file_context_file_p", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 116, "span_ids": ["FileContext.load_files_from_dict"], "start_line": 440, "end_line": 449, "community": null}, "content": "class FileContext(BaseModel):\n\n    def load_files_from_dict(self, files: list[dict]):\n        for file_data in files:\n            file_path = file_data[\"file_path\"]\n            show_all_spans = file_data.get(\"show_all_spans\", False)\n            spans = [ContextSpan(**span) for span in file_data.get(\"spans\", [])]\n            self._file_context[file_path] = ContextFile(\r\n                file=self._repo.get_file(file_path),\r\n                spans=spans,\r\n                show_all_spans=show_all_spans,\r\n            )", "kind": "Chunk", "id": "moatless/file_context.py#152.9"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.model_dump_FileContext.add_line_span_to_context.if_context_file_.else_.logger_warning_f_Could_no", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 785, "span_ids": ["FileContext.remove_file", "FileContext.restore_from_snapshot", "FileContext.add_file_with_lines", "FileContext.add_spans_to_context", "FileContext.files", "FileContext.add_span_to_context", "FileContext.to_files_with_spans", "FileContext.add_line_span_to_context", "FileContext.model_dump", "FileContext.snapshot", "FileContext.exists", "FileContext.add_files_with_spans", "FileContext.get_file", "FileContext.add_file"], "start_line": 451, "end_line": 548, "community": null}, "content": "class FileContext(BaseModel):\n\n    def model_dump(self, **kwargs):\n        if \"exclude_none\" not in kwargs:\n            kwargs[\"exclude_none\"] = True\n\n        files = [\r\n            file.model_dump(**kwargs)\r\n            for file in self.__dict__[\"_file_context\"].values()\r\n        ]\n        return {\"max_tokens\": self.__dict__[\"_max_tokens\"], \"files\": files}\n\n    def snapshot(self):\n        dict = self.model_dump()\n        del dict[\"max_tokens\"]\n        return dict\n\n    def restore_from_snapshot(self, snapshot: dict):\n        self._file_context = {}\n        self.load_files_from_dict(snapshot.get(\"files\", []))\n\n    def to_files_with_spans(self) -> List[FileWithSpans]:\n        return [\r\n            FileWithSpans(file_path=file_path, span_ids=list(file.span_ids))\r\n            for file_path, file in self._file_context.items()\r\n        ]\n\n    def add_files_with_spans(self, files_with_spans: List[FileWithSpans]):\n        for file_with_spans in files_with_spans:\n            self.add_spans_to_context(\r\n                file_with_spans.file_path, set(file_with_spans.span_ids)\r\n            )\n\n    def add_file(self, file_path: str, show_all_spans: bool = False):\n        if file_path not in self._file_context:\n            self._file_context[file_path] = ContextFile(\r\n                file=self._repo.get_file(file_path),\r\n                spans=[],\r\n                show_all_spans=show_all_spans,\r\n            )\n\n    def add_file_with_lines(\r\n        self, file_path: str, start_line: int, end_line: Optional[int] = None\r\n    ):\n        end_line = end_line or start_line\n        if file_path not in self._file_context:\n            self._file_context[file_path] = ContextFile(\r\n                file=self._repo.get_file(file_path), spans=[]\r\n            )\n\n        self._file_context[file_path].add_line_span(start_line, end_line)\n\n    def remove_file(self, file_path: str):\n        if file_path in self._file_context:\n            del self._file_context[file_path]\n\n    def exists(self, file_path: str):\n        return file_path in self._file_context\n\n    @property\r\n    def files(self):\n        return list(self._file_context.values())\n\n    def get_file(\r\n        self, file_path: str, add_if_not_found: bool = False\r\n    ) -> Optional[ContextFile]:\n        context_file = self._file_context.get(file_path)\n        if not context_file and add_if_not_found:\n            file = self._repo.get_file(file_path)\n            if file:\n                context_file = ContextFile(file=file, spans=[])\n                self._file_context[file_path] = context_file\n\n        return context_file\n\n    def add_spans_to_context(\r\n        self,\r\n        file_path: str,\r\n        span_ids: Set[str],\r\n        tokens: Optional[int] = None,\r\n    ):\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            context_file.add_spans(span_ids, tokens)\n        else:\n            logger.warning(f\"Could not find file {file_path} in the repository\")\n\n    def add_span_to_context(\r\n        self, file_path: str, span_id: str, tokens: Optional[int] = None\r\n    ):\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            context_file.add_span(span_id, tokens)\n\n    def add_line_span_to_context(self, file_path: str, start_line: int, end_line: int):\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            context_file.add_line_span(start_line, end_line)\n        else:\n            logger.warning(f\"Could not find file {file_path} in the repository\")", "kind": "Chunk", "id": "moatless/file_context.py#153.97"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.remove_span_from_context_FileContext.has_span.return.False", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 273, "span_ids": ["FileContext.remove_spans_from_context", "FileContext.has_span", "FileContext.get_spans", "FileContext.remove_span_from_context", "FileContext.get_span"], "start_line": 550, "end_line": 582, "community": null}, "content": "class FileContext(BaseModel):\n\n    def remove_span_from_context(\r\n        self, file_path: str, span_id: str, remove_file: bool = False\r\n    ):\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            context_file.remove_span(span_id)\n\n            if not context_file.spans and remove_file:\n                self.remove_file(file_path)\n\n    def remove_spans_from_context(\r\n        self, file_path: str, span_ids: List[str], remove_file: bool = False\r\n    ):\n        for span_id in span_ids:\n            self.remove_span_from_context(file_path, span_id, remove_file)\n\n    def get_spans(self, file_path: str) -> List[BlockSpan]:\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            return context_file.get_spans()\n        return []\n\n    def get_span(self, file_path: str, span_id: str) -> Optional[BlockSpan]:\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            return context_file.get_block_span(span_id)\n        return None\n\n    def has_span(self, file_path: str, span_id: str):\n        context_file = self.get_context_file(file_path)\n        if context_file:\n            return span_id in context_file.span_ids\n        return False", "kind": "Chunk", "id": "moatless/file_context.py#154.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.add_ranked_spans_FileContext.add_ranked_spans.logger_info_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 547, "span_ids": ["FileContext.add_ranked_spans"], "start_line": 584, "end_line": 653, "community": null}, "content": "class FileContext(BaseModel):\n\n    def add_ranked_spans(\r\n        self,\r\n        ranked_spans: List[RankedFileSpan],\r\n        decay_rate: float = 1.05,\r\n        min_tokens: int = 50,\r\n    ):\n        if not ranked_spans:\n            logger.info(\"No ranked spans provided\")\n            return\n\n        sum_tokens = sum(span.tokens for span in ranked_spans)\n        if sum_tokens < self._max_tokens:\n            logger.info(\r\n                f\"Adding all {len(ranked_spans)} spans with {sum_tokens} tokens\"\r\n            )\n            for span in ranked_spans:\n                self.add_span_to_context(span.file_path, span.span_id)\n            return\n\n        ranked_spans.sort(key=lambda x: x.rank)\n\n        base_tokens_needed = sum(min(span.tokens, min_tokens) for span in ranked_spans)\n\n        # Filter out the lowest ranking spans if necessary\r\n        while base_tokens_needed > self._max_tokens and ranked_spans:\n            removed_span = ranked_spans.pop()\n            base_tokens_needed -= min(removed_span.tokens, min_tokens)\n\n        if not ranked_spans:\n            raise ValueError(\r\n                \"Not enough tokens to meet the minimum token requirement for any span\"\r\n            )\n\n        remaining_tokens = self._max_tokens - base_tokens_needed\n\n        # Calculate total weights using exponential decay\r\n        total_weight = sum([decay_rate ** (-span.rank) for span in ranked_spans])\n\n        # Assign tokens based on the weight and the span's token count\r\n        tokens_distribution = []\n        for span in ranked_spans:\n            weight = decay_rate ** (-span.rank)\n            allocated_tokens = min(\r\n                span.tokens,\r\n                min_tokens + int(remaining_tokens * (weight / total_weight)),\r\n            )\n            tokens_distribution.append((span, allocated_tokens))\n\n        # Adjust tokens for spans with the same rank\r\n        rank_groups = {}\n        for span, tokens in tokens_distribution:\n            if span.rank not in rank_groups:\n                rank_groups[span.rank] = []\n            rank_groups[span.rank].append((span, tokens))\n\n        final_tokens_distribution = []\n        for _rank, group in rank_groups.items():\n            for span, tokens in group:\n                adjusted_tokens = min(span.tokens, tokens)\n                final_tokens_distribution.append((span, adjusted_tokens))\n\n        # Distribute tokens and add spans to the context\r\n        sum_tokens = 0\n        for span, tokens in final_tokens_distribution:\n            self.add_span_to_context(span.file_path, span.span_id, tokens)\n            sum_tokens += tokens\n\n        logger.info(\r\n            f\"Added {len(final_tokens_distribution)} spans with {sum_tokens} tokens\"\r\n        )", "kind": "Chunk", "id": "moatless/file_context.py#155.69"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.expand_context_with_init_spans_FileContext.expand_context_with_related_spans.return.spans", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 318, "span_ids": ["FileContext.expand_context_with_related_spans", "FileContext.expand_context_with_init_spans", "FileContext.expand_small_classes"], "start_line": 655, "end_line": 701, "community": null}, "content": "class FileContext(BaseModel):\n\n    def expand_context_with_init_spans(self):\n        for file in self._file_context.values():\n            file.expand_context_with_init_spans()\n\n    def expand_small_classes(self, max_tokens: int):\n        for file in self._file_context.values():\n            file.expand_small_classes(max_tokens)\n\n    def expand_context_with_related_spans(\r\n        self, max_tokens: int, set_tokens: bool = False\r\n    ):\n        # Add related spans if context allows it\r\n        if self.context_size() > max_tokens:\n            return\n\n        spans = []\n        for file in self._file_context.values():\n            if not file.file.supports_codeblocks:\n                continue\n            if not file.span_ids:\n                continue\n\n            for span in file.spans:\n                spans.append((file, span))\n\n        spans.sort(key=lambda x: x[1].tokens or 0, reverse=True)\n\n        for file, span in spans:\n            span_id = span.span_id\n            related_span_ids = file.module.find_related_span_ids(span_id)\n\n            for related_span_id in related_span_ids:\n                if related_span_id in file.span_ids:\n                    continue\n\n                related_span = file.module.find_span_by_id(related_span_id)\n\n                tokens = max(related_span.tokens, span.tokens or 0)\n                if tokens + self.context_size() > max_tokens:\n                    return spans\n\n                if set_tokens:\n                    file.add_span(related_span_id, tokens=tokens)\n                else:\n                    file.add_span(related_span_id)\n\n        return spans", "kind": "Chunk", "id": "moatless/file_context.py#156.46"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.get_context_file_FileContext.strip_line_breaks_only.return.text_lstrip_n_r_rstri", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 192, "span_ids": ["FileContext.save_file", "FileContext.save", "FileContext.reset", "FileContext.context_size", "FileContext.strip_line_breaks_only", "FileContext.get_context_file"], "start_line": 703, "end_line": 727, "community": null}, "content": "class FileContext(BaseModel):\n\n    def get_context_file(self, file_path: str) -> Optional[ContextFile]:\n        if file_path not in self._file_context:\n            file = self._repo.get_file(file_path)\n            if not file:\n                return None\n            self._file_context[file_path] = ContextFile(\r\n                file=self._repo.get_file(file_path), spans=[]\r\n            )\n\n        return self._file_context[file_path]\n\n    def context_size(self):\n        return sum(file.context_size() for file in self._file_context.values())\n\n    def save_file(self, file_path: str, updated_content: Optional[str] = None):\n        self._repo.save_file(file_path, updated_content)\n\n    def save(self):\n        self._repo.save()\n\n    def reset(self):\n        self._file_context = {}\n\n    def strip_line_breaks_only(self, text):\n        return text.lstrip(\"\\n\\r\").rstrip(\"\\n\\r\")", "kind": "Chunk", "id": "moatless/file_context.py#157.24"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py_FileContext.create_prompt_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\file_context.py", "file_name": "file_context.py", "file_type": "text/x-python", "category": "test", "tokens": 127, "span_ids": ["FileContext.create_prompt"], "start_line": 729, "end_line": 748, "community": null}, "content": "class FileContext(BaseModel):\n\n    def create_prompt(\r\n        self,\r\n        show_span_ids=False,\r\n        show_line_numbers=False,\r\n        exclude_comments=False,\r\n        show_outcommented_code=False,\r\n        outcomment_code_comment: str = \"...\",\r\n    ):\n        file_context_content = \"\"\n        for file in self._file_context.values():\n            content = file.to_prompt(\r\n                show_span_ids,\r\n                show_line_numbers,\r\n                exclude_comments,\r\n                show_outcommented_code,\r\n                outcomment_code_comment,\r\n            )\n            file_context_content += \"\\n\\n\" + content\n        return self.strip_line_breaks_only(file_context_content)", "kind": "Chunk", "id": "moatless/file_context.py#158.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 32, "span_ids": ["imports"], "start_line": 1, "end_line": 4, "community": null}, "content": "from moatless.find.search import SearchCode\nfrom moatless.find.identify import IdentifyCode\nfrom moatless.find.decide import DecideRelevance", "kind": "Chunk", "id": "find/__init__.py#159.3"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py_logging_MAYBE_FINISH_SYSTEM_PROMPT._You_will_be_provided_a", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py", "file_name": "decide.py", "file_type": "text/x-python", "category": "test", "tokens": 403, "span_ids": ["imports"], "start_line": 1, "end_line": 45, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom moatless.find import SearchCode\nfrom moatless.state import AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    Message,\r\n    UserMessage,\r\n)\n\nlogger = logging.getLogger(__name__)\n\n\nMAYBE_FINISH_SYSTEM_PROMPT = \"\"\"You will be provided a reported issue and the file context containing existing code from the project's git repository. \r\nYour task is to make a decision if the code related to a reported issue is provided in the file context. \r\n\r\n# Input Structure:\r\n\r\n* <issue>: Contains the reported issue.\r\n* <file_context>: The file context.\r\n\r\nInstructions:\r\n\r\n * Analyze the Issue:\r\n   * Review the reported issue to understand what functionality or bug fix is being requested.\r\n\r\n * Analyze File Context:\r\n  * Examine the provided file context to identify if the relevant code for the reported issue is present.\r\n  * If the issue suggests that code should be implemented and doesn't yet exist in the code, consider the task completed if relevant code is found that would be modified to implement the new functionality.\r\n  * If relevant code in the file context points to other parts of the codebase not included, note these references.\r\n\r\n * Make a Decision:\r\n  * Decide if the relevant code is found in the file context.\r\n  * If you believe all existing relevant code is identified, mark the task as complete.\r\n  * If the specific method or code required to fix the issue is not present, still mark the task as complete as long as the relevant class or area for modification is identified.\r\n  * If you believe more relevant code can be identified, mark the task as not complete and provide your suggestions on how to find the relevant code.\r\n\r\nImportant:\r\n * You CANNOT change the codebase. DO NOT modify or suggest changes to any code.\r\n * Your task is ONLY to determine if the file context is complete. Do not go beyond this scope.\r\n\"\"\"", "kind": "Chunk", "id": "find/decide.py#160.44"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py_Decision_Decision.search_suggestions.Field_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py", "file_name": "decide.py", "file_type": "text/x-python", "category": "test", "tokens": 142, "span_ids": ["Decision"], "start_line": 48, "end_line": 68, "community": null}, "content": "class Decision(ActionRequest):\n    \"\"\"Provide your decision if all relevant file context is provided.\"\"\"\n\n    scratch_pad: str = Field(\r\n        description=\"Your thoughts on if the spans where relevant or not and if you found all relevant spans and can finish..\"\r\n    )\n\n    relevant: bool = Field(\r\n        default=False,\r\n        description=\"Set to true if the relevant code have been identified.\",\r\n    )\n\n    complete: bool = Field(\r\n        default=False,\r\n        description=\"Set to true if all the relevant code have been identified.\",\r\n    )\n\n    search_suggestions: Optional[str] = Field(\r\n        None,\r\n        description=\"Suggestions on how to find the relevant code not found in the file context.\",\r\n    )", "kind": "Chunk", "id": "find/decide.py#161.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py_DecideRelevance_DecideRelevance._last_scratch_pad.if_previous_states_and_pr.else_.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py", "file_name": "decide.py", "file_type": "text/x-python", "category": "test", "tokens": 377, "span_ids": ["DecideRelevance._relevant_count", "DecideRelevance._last_scratch_pad", "DecideRelevance.system_prompt", "DecideRelevance", "DecideRelevance.action_type", "DecideRelevance._execute_action"], "start_line": 71, "end_line": 126, "community": null}, "content": "class DecideRelevance(AgenticState):\n    expand_context: bool = Field(\r\n        False,\r\n        description=\"If true, the file context will be expanded with additional context.\",\r\n    )\n    finish_after_relevant_count: int = Field(\r\n        2,\r\n        description=\"Finish the task after this many relevant decisions have been made but not complete.\",\r\n    )\n    max_prompt_file_tokens: int = Field(\r\n        4000,\r\n        description=\"The maximum number of tokens to include in the file context prompt.\",\r\n    )\n\n    def _execute_action(self, action: Decision) -> ActionResponse:\n        if action.complete and action.relevant:\n            return ActionResponse.transition(\"finish\")\n\n        if (\r\n            action.relevant\r\n            and self._relevant_count() >= self.finish_after_relevant_count\r\n        ):\n            return ActionResponse.transition(\"finish\")\n\n        return ActionResponse.transition(\r\n            \"search\",\r\n            output={\"message\": action.search_suggestions},\r\n        )\n\n    def _relevant_count(self) -> int:\n        \"\"\"\r\n        Count the number of times a decision was made that the file context was relevant.\r\n        \"\"\"\n        relevant_count = 0\n        previous_states = self.get_previous_states(self)\n        for previous_state in previous_states:\n            if (\r\n                previous_state.last_action\r\n                and previous_state.last_action.request.relevant\r\n            ):\n                relevant_count += 1\n        return relevant_count\n\n    def action_type(self) -> type[BaseModel] | None:\n        return Decision\n\n    def system_prompt(self) -> str:\n        return MAYBE_FINISH_SYSTEM_PROMPT\n\n    def _last_scratch_pad(self):\n        previous_states = self.get_previous_states()\n        if previous_states and previous_states[-1].last_action:\n            last_action = previous_states[-1].last_action\n            return last_action.request.scratch_pad\n        else:\n            return None", "kind": "Chunk", "id": "find/decide.py#162.55"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py_DecideRelevance.messages_DecideRelevance.messages.return.messages", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\decide.py", "file_name": "decide.py", "file_type": "text/x-python", "category": "test", "tokens": 218, "span_ids": ["DecideRelevance.messages"], "start_line": 128, "end_line": 166, "community": null}, "content": "class DecideRelevance(AgenticState):\n\n    def messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        if self.expand_context:\n            self.file_context.expand_context_with_init_spans()\n            self.file_context.expand_context_with_related_spans(\r\n                max_tokens=self.max_prompt_file_tokens\r\n            )\n            self.file_context.expand_small_classes(\r\n                max_tokens=self.max_prompt_file_tokens\r\n            )\n\n        file_context_str = self.file_context.create_prompt(\r\n            show_span_ids=False,\r\n            show_line_numbers=False,\r\n            exclude_comments=True,\r\n            show_outcommented_code=True,\r\n            outcomment_code_comment=\"... rest of the code\",\r\n        )\n\n        content = f\"\"\"<issue>\r\n{self.initial_message}\r\n</issue>\r\n\"\"\"\n\n        scratch_pad = self._last_scratch_pad()\n        if scratch_pad:\n            content += f\"\"\"<scratch_pad>\r\n{scratch_pad}\r\n</scratch_pad>\"\"\"\n\n        content += f\"\"\"\r\n<file_context>\r\n{file_context_str}\r\n</file_context>\r\n\"\"\"\n\n        messages.append(UserMessage(content=content))\n        return messages", "kind": "Chunk", "id": "find/decide.py#163.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\find_code_snippet.py_logging_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\find_code_snippet.py", "file_name": "find_code_snippet.py", "file_type": "text/x-python", "category": "test", "tokens": 224, "span_ids": ["imports", "find_code_snippet_in_files"], "start_line": 1, "end_line": 37, "community": null}, "content": "import logging\nimport os\n\nlogger = logging.getLogger(__name__)\n\nignored_dirs = [\"target\", \"node_modules\", \".git\", \".idea\"]\n\n\ndef find_code_snippet_in_files(repo_dir: str, code_snippet: str):\n    occurrences = []\n\n    for root, _dirs, files in os.walk(repo_dir):\n        for file in files:\n            if any(dir in root for dir in ignored_dirs):\n                continue\n\n            file_path = os.path.join(root, file)\n            if not file_path.endswith(\".java\"):\n                continue\n            try:\n                with open(file_path, encoding=\"utf-8\") as f:\n                    for line_number, line in enumerate(f, start=1):\n                        if code_snippet.lower() in line.lower():\n                            relative_path = os.path.relpath(file_path, repo_dir)\n                            occurrences.append(\r\n                                (\r\n                                    relative_path,\r\n                                    line_number,\r\n                                    line.strip(),\r\n                                )\r\n                            )\n            except Exception as e:\n                if \"invalid\" not in str(e):\n                    logger.error(f\"Could not read file {file_path}: {e}\")\n\n    return occurrences", "kind": "Chunk", "id": "find/find_code_snippet.py#164.36"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py_fnmatch_Identify.identified_spans.Field_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py", "file_name": "identify.py", "file_type": "text/x-python", "category": "test", "tokens": 548, "span_ids": ["Identify", "imports"], "start_line": 1, "end_line": 64, "community": null}, "content": "import fnmatch\nimport logging\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom moatless.file_context import RankedFileSpan\nfrom moatless.state import AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    FileWithSpans,\r\n    Message,\r\n    UserMessage,\r\n)\n\nlogger = logging.getLogger(__name__)\n\n\nIDENTIFY_SYSTEM_PROMPT = \"\"\"You are an autonomous AI assistant tasked with finding relevant code in an existing \r\ncodebase based on a reported issue. Your task is to identify the relevant code spans in the provided search \r\nresults and decide whether the search task is complete.\r\n\r\n# Input Structure:\r\n\r\n* <issue>: Contains the reported issue.\r\n* <file_context>: Contains the context of already identified files and code spans.\r\n* <search_results>: Contains the new search results with code divided into \"code spans\".\r\n\r\n# Your Task:\r\n\r\n1. Analyze User Instructions:\r\nCarefully read the reported issue within the <issue> tag.\r\n\r\n2. Review Current Context:\r\nExamine the current file context provided in the <file_context> tag to understand already identified relevant files.\r\n\r\n3. Process New Search Results:\r\n3.1. Thoroughly analyze each code span in the <search_results> tag.\r\n3.2. Match the code spans with the key elements, functions, variables, or patterns identified in the reported issue.\r\n3.3. Evaluate the relevance of each code span based on how well it aligns with the reported issue and current file context.\r\n3.4. If the issue suggests new functions or classes, identify the existing code that might be relevant to be able to implement the new functionality.\r\n3.5. Review entire sections of code, not just isolated spans, to ensure you have a complete understanding before making a decision. It's crucial to see all code in a section to accurately determine relevance and completeness.\r\n3.6. Verify if there are references to other parts of the codebase that might be relevant but not found in the search results. \r\n3.7. Identify and extract relevant code spans based on the reported issue. \r\n\r\n4. Respond Using the Function:\r\nUse the Identify function to provide your response.\r\n\r\nThink step by step and write out your thoughts in the scratch_pad field.\r\n\"\"\"\n\n\nclass Identify(ActionRequest):\n    \"\"\"Identify if the provided search result is relevant to the reported issue.\"\"\"\n\n    scratch_pad: str = Field(\r\n        description=\"Your thoughts on how to identify the relevant code and why.\"\r\n    )\n\n    identified_spans: Optional[list[FileWithSpans]] = Field(\r\n        default=None,\r\n        description=\"Files and code spans in the search results identified as relevant to the reported issue.\",\r\n    )", "kind": "Chunk", "id": "find/identify.py#165.63"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py_IdentifyCode_IdentifyCode.model_dump.return.super_model_dump_kwar", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py", "file_name": "identify.py", "file_type": "text/x-python", "category": "test", "tokens": 117, "span_ids": ["IdentifyCode.model_dump", "IdentifyCode"], "start_line": 67, "end_line": 83, "community": null}, "content": "class IdentifyCode(AgenticState):\n    ranked_spans: Optional[list[RankedFileSpan]] = Field(\r\n        default=None, description=\"Ranked file spans from the search results.\"\r\n    )\n\n    expand_context: bool = Field(\r\n        default=False,\r\n        description=\"Whether to expand the search result with relevant code spans.\",\r\n    )\n\n    max_prompt_file_tokens: int = Field(\r\n        default=4000,\r\n        description=\"The maximum number of tokens to include in the prompt.\",\r\n    )\n\n    def model_dump(self, **kwargs):\n        return super().model_dump(**kwargs)", "kind": "Chunk", "id": "find/identify.py#166.16"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py_IdentifyCode._execute_action_IdentifyCode.system_prompt.return.IDENTIFY_SYSTEM_PROMPT", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py", "file_name": "identify.py", "file_type": "text/x-python", "category": "test", "tokens": 229, "span_ids": ["IdentifyCode.action_type", "IdentifyCode.system_prompt", "IdentifyCode._execute_action"], "start_line": 85, "end_line": 112, "community": null}, "content": "class IdentifyCode(AgenticState):\n\n    def _execute_action(self, action: Identify) -> ActionResponse:\n        if action.identified_spans:\n            self.file_context.add_files_with_spans(action.identified_spans)\n\n            span_count = sum([len(file.span_ids) for file in action.identified_spans])\n            logger.info(\r\n                f\"Identified {span_count} spans in {len(action.identified_spans)} files. Current file context size is {self.file_context.context_size()} tokens.\"\r\n            )\n\n            return ActionResponse.transition(\"finish\")\n        else:\n            logger.info(\"No spans identified.\")\n\n        message = f\"The search returned {len(self.ranked_spans)} results. But unfortunately, I didn't find any of the search results relevant to the query.\"\n\n        message += \"\\n\\n\"\n        message += action.scratch_pad\n\n        return ActionResponse.transition(\r\n            \"search\",\r\n            output={\"message\": message},\r\n        )\n\n    def action_type(self) -> type[BaseModel] | None:\n        return Identify\n\n    def system_prompt(self) -> str:\n        return IDENTIFY_SYSTEM_PROMPT", "kind": "Chunk", "id": "find/identify.py#167.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py_IdentifyCode.messages_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\identify.py", "file_name": "identify.py", "file_type": "text/x-python", "category": "test", "tokens": 395, "span_ids": ["is_test_pattern", "IdentifyCode.messages"], "start_line": 114, "end_line": 181, "community": null}, "content": "class IdentifyCode(AgenticState):\n\n    def messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        file_context = self.create_file_context(max_tokens=self.max_prompt_file_tokens)\n        file_context.add_ranked_spans(self.ranked_spans)\n\n        if file_context.files:\n            file_context.expand_context_with_init_spans()\n\n            if self.expand_context:\n                file_context.expand_context_with_related_spans(\r\n                    max_tokens=self.max_prompt_file_tokens, set_tokens=True\r\n                )\n                file_context.expand_small_classes(\r\n                    max_tokens=self.max_prompt_file_tokens\r\n                )\n\n            search_result_str = file_context.create_prompt(\r\n                show_span_ids=True,\r\n                show_line_numbers=False,\r\n                exclude_comments=True,\r\n                show_outcommented_code=True,\r\n                outcomment_code_comment=\"... rest of the code\",\r\n            )\n        else:\n            search_result_str = \"No new search results found.\"\n\n        if self.file_context.files:\n            file_context_str = self.file_context.create_prompt(\r\n                show_span_ids=True,\r\n                show_line_numbers=False,\r\n                exclude_comments=True,\r\n                show_outcommented_code=True,\r\n                outcomment_code_comment=\"... rest of the code\",\r\n            )\n        else:\n            file_context_str = \"No relevant code identified yet.\"\n\n        content = f\"\"\"<issue>\r\n{self.initial_message}\r\n</issue>\r\n\r\n<file_context>\r\n{file_context_str}\r\n</file_context>\r\n\r\n<search_results>\r\n{search_result_str}\r\n</search_results>\r\n\"\"\"\n\n        messages.append(UserMessage(content=content))\n        return messages\n\n\ndef is_test_pattern(file_pattern: str):\n    test_patterns = [\"test_*.py\", \"/tests/\"]\n    for pattern in test_patterns:\n        if pattern in file_pattern:\n            return True\n\n    if file_pattern.startswith(\"test\"):\n        return True\n\n    test_patterns = [\"test_*.py\"]\n\n    return any(fnmatch.filter([file_pattern], pattern) for pattern in test_patterns)", "kind": "Chunk", "id": "find/identify.py#168.67"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_fnmatch_SEARCH_FUNCTIONS_FEW_SHOT_OPENAI_FUNC._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 735, "span_ids": ["imports"], "start_line": 1, "end_line": 108, "community": null}, "content": "import fnmatch\nimport logging\nfrom typing import Optional\n\nimport instructor\nfrom pydantic import BaseModel, Field, model_validator, ValidationError\n\nfrom moatless.file_context import RankedFileSpan\nfrom moatless.index.types import SearchCodeHit\nfrom moatless.state import ActionResponse, AgenticState\nfrom moatless.types import (\r\n    ActionRequest,\r\n    AssistantMessage,\r\n    Message,\r\n    UserMessage,\r\n)\nfrom moatless.utils.llm_utils import instructor_mode_by_model\n\nlogger = logging.getLogger(__name__)\n\n\nSEARCH_SYSTEM_PROMPT = \"\"\"You are an autonomous AI assistant.\r\nYour task is to locate the code relevant to an issue.\r\n\r\n# Instructions:\r\n\r\n1. Understand The Issue:\r\nRead the <issue> tag to understand the issue.\r\n\r\n2. Review Current File Context:\r\nExamine the <file_context> tag to see which files and code spans have already been identified.\r\nIf you believe that all relevant files have been identified, you can finish the search by setting complete to true.\r\n\r\n3. Consider the Necessary Search Parameters:\r\nDetermine if specific file types, directories, function or class names or code patterns are mentioned in the issue.\r\nIf you can you should always try to specify the search parameters as accurately as possible.\r\nYou can do more than one search request at the same time so you can try different search parameters to cover all possible relevant code.\r\n\r\n4. Ensure At Least One Search Parameter:\r\nMake sure that at least one of query, code_snippet, class_name, or function_name is provided.\r\n\r\n5. Formulate the Search function:\r\nSet at least one of the search paramaters `query`, `code_snippet`, `class_name` or `function_name`.\r\n\r\n\r\n\r\n\"\"\"\n\n\nSEARCH_FUNCTIONS_FEW_SHOT_OPENAI_FUNC = \"\"\"\r\n6. Execute the Search function:\r\nUse the Search function with the search parameters and your thoughts on how to approach this task.\r\n\r\nThink step by step and write out your thoughts in the thoughts field.\r\n\r\nExamples:\r\n\r\nUser:\r\nThe file uploader intermittently fails with \"TypeError: cannot unpack non-iterable NoneType object\". This issue appears sporadically during high load conditions..\r\n\r\nAI Assistant:\r\nfunctions.Search({\r\n    query: \"File upload process to fix intermittent 'TypeError: cannot unpack non-iterable NoneType object'\",\r\n    file_pattern: \"**/uploader/**/*.py\"\r\n)\r\n\r\nUser:\r\nThere's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.\r\n\r\nAI Assistant:\r\nfunctions.Search({\r\n    class_names: [\"PaymentProcessor\"]\r\n)\r\n\r\nUser:\r\nThe generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.\r\n\r\nAI Assistant:\r\nfunctions.Search({\r\n    function_names: [\"generate_report\"],\r\n    file_pattern: \"**/reports/**/*.py\"\r\n)\r\n\r\nUser:\r\nThe extract_data function in HTMLParser throws an \"AttributeError: 'NoneType' object has no attribute 'find'\" error when parsing certain HTML pages.\r\n\r\nAI Assistant:\r\nfunctions.Search({\r\n    class_names: [\"HTMLParser\"],\r\n    function_names: [\"extract_data\"]\r\n)\r\n\r\nUser:\r\nThe database connection setup is missing SSL configuration, causing insecure connections.\r\n\r\nHere's the stack trace of the error:\r\n\r\nFile \"/opt/app/db_config/database.py\", line 45, in setup_connection\r\n    engine = create_engine(DATABASE_URL)\r\nFile \"/opt/app/db_config/database.py\", line 50, in <module>\r\n    connection = setup_connection()\r\n\r\nAI Assistant:\r\nfunctions.Search({\r\n    code_snippet: \"engine = create_engine(DATABASE_URL)\",\r\n    file_pattern: \"db_config/database.py\"\r\n)\r\n\"\"\"", "kind": "Chunk", "id": "find/search.py#169.107"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SEARCH_FUNCTIONS_FEW_SHOT_SEARCH_FUNCTIONS_FEW_SHOT._6_Execute_the_Search_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 372, "span_ids": ["impl:7"], "start_line": 110, "end_line": 162, "community": null}, "content": "SEARCH_FUNCTIONS_FEW_SHOT = \"\"\"6. Execute the Search function:\r\nUse the Search function with the search parameters and your thoughts on how to approach this task.\r\n\r\nThink step by step and write out your thoughts in the scratch_pad field.\r\n\r\nExamples:\r\n\r\nUser:\r\nThe file uploader intermittently fails with \"TypeError: cannot unpack non-iterable NoneType object\". This issue appears sporadically during high load conditions..\r\n\r\nSearch parameters:\r\n    query: \"File upload process to fix intermittent 'TypeError: cannot unpack non-iterable NoneType object'\",\r\n    file_pattern: \"**/uploader/**/*.py\"\r\n\r\n\r\nUser:\r\nThere's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.\r\n\r\nSearch parameters:\r\n    class_names: [\"PaymentProcessor\"]\r\n\r\n\r\nUser:\r\nThe generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.\r\n\r\nSearch parameters:\r\n    function_names: [\"generate_report\"]\r\n    file_pattern: \"**/reports/**/*.py\"\r\n\r\n\r\nUser:\r\nThe extract_data function in HTMLParser throws an \"AttributeError: 'NoneType' object has no attribute 'find'\" error when parsing certain HTML pages.\r\n\r\nSearch parameters:\r\n    class_names: [\"HTMLParser\"]\r\n    function_names: [\"extract_data\"]\r\n\r\n\r\nUser:\r\nThe database connection setup is missing SSL configuration, causing insecure connections.\r\n\r\nHere's the stack trace of the error:\r\n\r\nFile \"/opt/app/db_config/database.py\", line 45, in setup_connection\r\n    engine = create_engine(DATABASE_URL)\r\nFile \"/opt/app/db_config/database.py\", line 50, in <module>\r\n    connection = setup_connection()\r\n\r\nSearch parameters:\r\n    code_snippet: \"engine = create_engine(DATABASE_URL)\",\r\n    file_pattern: \"db_config/database.py\"\r\n\r\n\"\"\"", "kind": "Chunk", "id": "find/search.py#170.52"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SEARCH_JSON_FEW_SHOT_IGNORE_TEST_PROMPT._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 617, "span_ids": ["impl:11", "impl:7"], "start_line": 164, "end_line": 231, "community": null}, "content": "SEARCH_JSON_FEW_SHOT = \"\"\"6. Execute the Search:\r\nExecute the search by providing the search parameters and your thoughts on how to approach this task in a JSON object. \r\n\r\nThink step by step and write out your thoughts in the scratch_pad field.\r\n\r\nExamples:\r\n\r\nUser:\r\nThe file uploader intermittently fails with \"TypeError: cannot unpack non-iterable NoneType object\". This issue appears sporadically during high load conditions..\r\n\r\nAssistant:\r\n{\r\n \"scratch_pad\": \"The error indicates that a variable expected to be iterable is None, which might be happening due to race conditions or missing checks under high load. Investigate the file upload logic to ensure all necessary checks are in place and improve concurrency handling.\",\r\n \"file_pattern\": \"**/uploader/**/*.py\",\r\n \"query\": \"TypeError: cannot unpack non-iterable NoneType object\"\r\n}\r\n\r\nUser:\r\nThere's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.\r\n\r\nAssistant:\r\n{\r\n  \"scratch_pad\": \"Missing transaction logs can cause significant issues in tracking payments. The problem may be related to how the logging mechanism handles transaction states or errors. Investigate the PaymentProcessor class, focusing on the transaction logging part.\",\r\n  \"class_name\": \"PaymentProcessor\",\r\n  \"query\": \"transactions fail to log correctly\"\r\n}\r\n\r\nUser:\r\nThe generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.\r\n\r\nAssistant:\r\n{\r\n  \"scratch_pad\": \"Incomplete reports suggest that the function might be encountering edge cases or unhandled exceptions that disrupt the report generation. Reviewing the function's logic and error handling in the reporting module is necessary.\",\r\n  \"function_name\": \"generate_report\",\r\n  \"file_pattern\": \"**/reports/**/*.py\",\r\n}\r\n\r\nUser:\r\nThe extract_data function in HTMLParser throws an \"AttributeError: 'NoneType' object has no attribute 'find'\" error when parsing certain HTML pages.\r\n\r\nAssistant:\r\n{\r\n  \"scratch_pad\": \"The error occurs when 'find' is called on a NoneType object, suggesting that the HTML structure might not match expected patterns. \",\r\n  \"class_name\": \"HTMLParser\",\r\n  \"function_name\": \"extract_data\",\r\n}\r\n\r\n\r\nUser:\r\nThe database connection setup is missing SSL configuration, causing insecure connections.\r\n\r\nHere's the stack trace of the error:\r\n\r\nFile \"/opt/app/db_config/database.py\", line 45, in setup_connection\r\n    engine = create_engine(DATABASE_URL)\r\nFile \"/opt/app/db_config/database.py\", line 50, in <module>\r\n    connection = setup_connection()\r\n\r\nAssistant:\r\n{\r\n  \"scratch_pad\": \"The missing SSL configuration poses a security risk by allowing unencrypted connections. Find the code snippet `engine = create_engine(DATABASE_URL)` provided in the issue.\",\r\n  \"code_snippet\": \"engine = create_engine(DATABASE_URL)\",\r\n}\r\n\"\"\"\n\nIGNORE_TEST_PROMPT = (\r\n    \"Test files are not in the search scope. Ignore requests to search for tests. \"\r\n)", "kind": "Chunk", "id": "find/search.py#171.67"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SearchRequest_SearchRequest.validate_search_requests.return.self", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 235, "span_ids": ["SearchRequest", "SearchRequest.validate_search_requests", "SearchRequest.has_search_attributes"], "start_line": 234, "end_line": 272, "community": null}, "content": "class SearchRequest(BaseModel):\n    file_pattern: Optional[str] = Field(\r\n        default=None,\r\n        description=\"A glob pattern to filter search results to specific file types or directories. \",\r\n    )\n\n    query: Optional[str] = Field(\r\n        default=None,\r\n        description=\"A semantic similarity search query. Use natural language to describe what you are looking for.\",\r\n    )\n\n    code_snippet: Optional[str] = Field(\r\n        default=None,\r\n        description=\"Specific code snippet to that should be exactly matched.\",\r\n    )\n\n    class_names: list[str] = Field(\r\n        default=[], description=\"Specific class names to include in the search.\"\r\n    )\n\n    function_names: list[str] = Field(\r\n        default=[], description=\"Specific function names to include in the search.\"\r\n    )\n\n    def has_search_attributes(self):\n        return any(\r\n            [\r\n                self.query,\r\n                self.code_snippet,\r\n                self.class_names,\r\n                self.function_names,\r\n            ]\r\n        )\n\n    @model_validator(mode='after')\r\n    def validate_search_requests(self):\n        if not self.has_search_attributes:\n            raise ValueError(\"A search request must have at least one attribute set.\")\n        return self", "kind": "Chunk", "id": "find/search.py#172.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_Search_Search.validate_search_requests.return.self", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 150, "span_ids": ["Search.validate_search_requests", "Search"], "start_line": 274, "end_line": 295, "community": null}, "content": "class Search(ActionRequest):\n    \"\"\"Take action to search for code, identify found and finish up.\"\"\"\n\n    scratch_pad: str = Field(\r\n        description=\"Scratch pad for the search. Use this to write down your thoughts on how to approach the search.\"\r\n    )\n\n    search_requests: list[SearchRequest] = Field(\r\n        default=[],\r\n        description=\"List of search requests.\",\r\n    )\n\n    complete: Optional[bool] = Field(\r\n        default=False, description=\"Set to true when the search is complete.\"\r\n    )\n\n    @model_validator(mode='after')\r\n    def validate_search_requests(self):\n        if not self.complete:\n            if not self.search_requests:\n                raise ValueError(\"At least one search request must exist.\")\n        return self", "kind": "Chunk", "id": "find/search.py#173.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SearchCode_SearchCode.support_test_files.False", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 166, "span_ids": ["SearchCode"], "start_line": 298, "end_line": 324, "community": null}, "content": "class SearchCode(AgenticState):\n    message: Optional[str] = Field(\r\n        None,\r\n        description=\"Message to the search\",\r\n    )\n\n    max_search_results: int = Field(\r\n        25,\r\n        description=\"The maximum number of search results.\",\r\n    )\n\n    max_retries_with_any_file_context: int = Field(\r\n        3,\r\n        description=\"The maximum number of retries when there are identified files in file context.\",\r\n    )\n\n    include_message_history: bool = Field(\r\n        True,\r\n        description=\"Include message history from previous iterations\",\r\n    )\n\n    provide_initial_context: bool = True\n    initial_context_tokens: int = 4000\n    initial_search_results: int = 50\n    initial_context_spans_per_file: int = 5\n\n    support_test_files: bool = False", "kind": "Chunk", "id": "find/search.py#174.26"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SearchCode._execute_action_SearchCode._execute_action.return.ActionResponse_transition", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 373, "span_ids": ["SearchCode._execute_action"], "start_line": 326, "end_line": 380, "community": null}, "content": "class SearchCode(AgenticState):\n\n    def _execute_action(self, action: Search) -> ActionResponse:\n        if action.complete:\n            return ActionResponse.transition(\r\n                \"finish\",\r\n                output={\r\n                    \"message\": action.scratch_pad,\r\n                },\r\n            )\n\n        if isinstance(action, Search):\n            for request in action.search_requests:\n                if (\r\n                    not self.support_test_files\r\n                    and request.file_pattern\r\n                    and is_test_pattern(request.file_pattern)\r\n                ):\n                    return self._retry(\"It's not possible to search for test files.\")\n\n        message = \"\"\n        search_result: list[SearchCodeHit] = []\n        for search_request in action.search_requests:\n            search_response = self.workspace.code_index.search(\r\n                file_pattern=search_request.file_pattern,\r\n                query=search_request.query,\r\n                code_snippet=search_request.code_snippet,\r\n                class_names=search_request.class_names,\r\n                function_names=search_request.function_names,\r\n                max_results=int(self.max_search_results / len(action.search_requests)),\r\n            )\n            search_result.extend(search_response.hits)\n            message += \"\\n\" + search_response.message\n\n        logger.info(f\"Found {len(search_result)} hits.\")\n\n        ranked_spans = []\n        for hit in search_result:\n            for span in hit.spans:\n                ranked_spans.append(\r\n                    RankedFileSpan(\r\n                        file_path=hit.file_path,\r\n                        span_id=span.span_id,\r\n                        rank=span.rank,\r\n                        tokens=span.tokens,\r\n                    )\r\n                )\n\n        if len(ranked_spans) == 0:\n            logger.info(\"No search results found. Will retry.\")\n            message = \"\\n\\nUnfortunately, I didn't find any relevant results.\"\n            return self._retry(message)\n\n        return ActionResponse.transition(\r\n            trigger=\"did_search\",\r\n            output={\"ranked_spans\": ranked_spans},\r\n        )", "kind": "Chunk", "id": "find/search.py#175.54"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SearchCode._retry_SearchCode.system_prompt.return.system_prompt", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 223, "span_ids": ["SearchCode.action_type", "SearchCode.system_prompt", "SearchCode._retry"], "start_line": 382, "end_line": 410, "community": null}, "content": "class SearchCode(AgenticState):\n\n    def _retry(self, message: str) -> ActionResponse:\n        if (\r\n            self.retries() > self.max_retries_with_any_file_context\r\n            and self.file_context.files\r\n        ):\n            logger.info(\r\n                \"Exceeded max retries, will finish as there are identified files in the file context. Transitioning to finish.\"\r\n            )\n            return ActionResponse.transition(\"finish\")\n        else:\n            return ActionResponse.retry(message)\n\n    def action_type(self) -> type[BaseModel] | None:\n        return Search\n\n    def system_prompt(self) -> str:\n        system_prompt = SEARCH_SYSTEM_PROMPT\n\n        instructor_mode = instructor_mode_by_model(self.model)\n        if instructor_mode == instructor.Mode.JSON:\n            system_prompt += SEARCH_JSON_FEW_SHOT\n        elif self.model.startswith(\"openai\"):\n            system_prompt += SEARCH_FUNCTIONS_FEW_SHOT_OPENAI_FUNC\n        else:\n            system_prompt += SEARCH_FUNCTIONS_FEW_SHOT\n\n        if not self.support_test_files:\n            system_prompt += IGNORE_TEST_PROMPT\n        return system_prompt", "kind": "Chunk", "id": "find/search.py#176.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py_SearchCode.messages_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\find\\search.py", "file_name": "search.py", "file_type": "text/x-python", "category": "test", "tokens": 482, "span_ids": ["SearchCode.messages", "is_test_pattern"], "start_line": 412, "end_line": 486, "community": null}, "content": "class SearchCode(AgenticState):\n\n    def messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        content = f\"<issue>\\n{self.initial_message}\\n</issue>\"\n\n        if self.provide_initial_context:\n            logger.info(\"Search for initial context to provide in the prompt\")\n            result = self.workspace.code_index.semantic_search(\r\n                query=self.initial_message,\r\n                exact_match_if_possible=False,\r\n                max_spans_per_file=5,\r\n                max_results=100,\r\n            )\n\n            file_context = self.create_file_context(max_tokens=4000)\n\n            for hit in result.hits:\n                for span in hit.spans:\n                    file_context.add_span_to_context(\r\n                        hit.file_path, span.span_id, tokens=1\r\n                    )\n\n            content += \"\\n\\nHere's some files that might be relevant when formulating the search.\\n\"\n            content += file_context.create_prompt(\r\n                show_span_ids=False,\r\n                show_line_numbers=False,\r\n                exclude_comments=True,\r\n                show_outcommented_code=False,\r\n            )\n\n        previous_states = self.get_previous_states(self)\n        for previous_state in previous_states:\n            if previous_state.message:\n                content += previous_state.message\n            messages.append(UserMessage(content=content))\n            messages.append(\r\n                AssistantMessage(\r\n                    action=previous_state.last_action.request,\r\n                )\r\n            )\n            content = \"\"\n\n        if self.message:\n            content += f\"\\n\\n{self.message}\\n\"\n\n        if self.file_context.files:\n            file_context_str = self.file_context.create_prompt(\r\n                exclude_comments=True,\r\n                show_outcommented_code=True,\r\n                outcomment_code_comment=\"... rest of the code\",\r\n            )\n        else:\n            file_context_str = \"No files found yet.\"\n\n        content += f\"\\n\\n<file_context>\\n{file_context_str}\\n</file_context>\"\n\n        messages.append(UserMessage(content=content))\n        messages.extend(self.retry_messages())\n\n        return messages\n\n\ndef is_test_pattern(file_pattern: str):\n    test_patterns = [\"test_*.py\", \"/tests/\"]\n    for pattern in test_patterns:\n        if pattern in file_pattern:\n            return True\n\n    if file_pattern.startswith(\"test\"):\n        return True\n\n    test_patterns = [\"test_*.py\"]\n\n    return any(fnmatch.filter([file_pattern], pattern) for pattern in test_patterns)", "kind": "Chunk", "id": "find/search.py#177.74"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 35, "span_ids": ["imports"], "start_line": 1, "end_line": 4, "community": null}, "content": "from moatless.index.code_index import CodeIndex\nfrom moatless.index.settings import IndexSettings\nfrom moatless.index.simple_faiss import SimpleFaissVectorStore", "kind": "Chunk", "id": "index/__init__.py#178.3"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_fnmatch_default_vector_store.return.SimpleFaissVectorStore_fa", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 354, "span_ids": ["imports", "default_vector_store"], "start_line": 1, "end_line": 51, "community": null}, "content": "import fnmatch\nimport json\nimport logging\nimport mimetypes\nimport os\nimport shutil\nimport tempfile\nfrom typing import Optional\n\nimport requests\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\nfrom llama_index.core.ingestion import DocstoreStrategy, IngestionPipeline\nfrom llama_index.core.storage import docstore\nfrom llama_index.core.storage.docstore import DocumentStore, SimpleDocumentStore\nfrom llama_index.core.vector_stores.types import (\r\n    BasePydanticVectorStore,\r\n    FilterCondition,\r\n    MetadataFilter,\r\n    MetadataFilters,\r\n    VectorStoreQuery,\r\n)\nfrom rapidfuzz import fuzz\n\nfrom moatless.codeblocks import CodeBlock, CodeBlockType\nfrom moatless.index.embed_model import get_embed_model\nfrom moatless.index.epic_split import EpicSplitter\nfrom moatless.index.settings import IndexSettings\nfrom moatless.index.simple_faiss import SimpleFaissVectorStore\nfrom moatless.index.types import (\r\n    CodeSnippet,\r\n    SearchCodeHit,\r\n    SearchCodeResponse,\r\n)\nfrom moatless.repository import FileRepository\nfrom moatless.types import FileWithSpans\nfrom moatless.utils.tokenizer import count_tokens\n\nlogger = logging.getLogger(__name__)\n\n\ndef default_vector_store(settings: IndexSettings):\n    try:\n        import faiss\n    except ImportError as e:\n        raise ImportError(\r\n            \"faiss needs to be installed to set up a default index for CodeIndex. Run 'pip install faiss-cpu'\"\r\n        ) from e\n\n    faiss_index = faiss.IndexIDMap(faiss.IndexFlatL2(settings.dimensions))\n    return SimpleFaissVectorStore(faiss_index)", "kind": "Chunk", "id": "index/code_index.py#179.50"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex_CodeIndex.__init__.logger_info_f_Initiated_C", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 338, "span_ids": ["CodeIndex.__init__", "CodeIndex"], "start_line": 54, "end_line": 88, "community": null}, "content": "class CodeIndex:\n    def __init__(\r\n        self,\r\n        file_repo: FileRepository,\r\n        index_name: Optional[str] = None,\r\n        vector_store: BasePydanticVectorStore | None = None,\r\n        docstore: DocumentStore | None = None,\r\n        embed_model: BaseEmbedding | None = None,\r\n        blocks_by_class_name: Optional[dict] = None,\r\n        blocks_by_function_name: Optional[dict] = None,\r\n        settings: IndexSettings | None = None,\r\n        max_results: int = 25,\r\n        max_hits_without_exact_match: int = 100,\r\n        max_exact_results: int = 5,\r\n    ):\n        self._index_name = index_name\n        self._settings = settings or IndexSettings()\n\n        self.max_results = max_results\n        self.max_hits_without_exact_match = max_hits_without_exact_match\n        self.max_exact_results = max_exact_results\n\n        self._file_repo = file_repo\n\n        self._blocks_by_class_name = blocks_by_class_name or {}\n        self._blocks_by_function_name = blocks_by_function_name or {}\n\n        self._embed_model = embed_model or get_embed_model(self._settings.embed_model)\n        self._vector_store = vector_store or default_vector_store(self._settings)\n        self._docstore = docstore or SimpleDocumentStore()\n\n        logger.info(f\"Initiated CodeIndex {self._index_name} with:\\n\"\r\n                    f\" * {len(self._blocks_by_class_name)} classes\\n\"\r\n                    f\" * {len(self._blocks_by_function_name)} functions\\n\"\r\n                    f\" * {len(self._docstore.docs)} vectors\\n\")", "kind": "Chunk", "id": "index/code_index.py#180.34"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.from_persist_dir_CodeIndex.from_persist_dir.return.cls_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 251, "span_ids": ["CodeIndex.from_persist_dir"], "start_line": 90, "end_line": 117, "community": null}, "content": "class CodeIndex:\n\n    @classmethod\r\n    def from_persist_dir(cls, persist_dir: str, file_repo: FileRepository, **kwargs):\n        vector_store = SimpleFaissVectorStore.from_persist_dir(persist_dir)\n        docstore = SimpleDocumentStore.from_persist_dir(persist_dir)\n\n        settings = IndexSettings.from_persist_dir(persist_dir)\n\n        if os.path.exists(os.path.join(persist_dir, \"blocks_by_class_name.json\")):\n            with open(os.path.join(persist_dir, \"blocks_by_class_name.json\")) as f:\n                blocks_by_class_name = json.load(f)\n        else:\n            blocks_by_class_name = {}\n\n        if os.path.exists(os.path.join(persist_dir, \"blocks_by_function_name.json\")):\n            with open(os.path.join(persist_dir, \"blocks_by_function_name.json\")) as f:\n                blocks_by_function_name = json.load(f)\n        else:\n            blocks_by_function_name = {}\n\n        return cls(\r\n            file_repo=file_repo,\r\n            vector_store=vector_store,\r\n            docstore=docstore,\r\n            settings=settings,\r\n            blocks_by_class_name=blocks_by_class_name,\r\n            blocks_by_function_name=blocks_by_function_name,\r\n            **kwargs,\r\n        )", "kind": "Chunk", "id": "index/code_index.py#181.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.from_url_CodeIndex.from_url.return.cls_from_persist_dir_pers", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 192, "span_ids": ["CodeIndex.from_url"], "start_line": 119, "end_line": 142, "community": null}, "content": "class CodeIndex:\n\n    @classmethod\r\n    def from_url(cls, url: str, persist_dir: str, file_repo: FileRepository):\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()\n\n            with tempfile.TemporaryDirectory() as temp_dir:\n                temp_zip_file = os.path.join(temp_dir, url.split(\"/\")[-1])\n\n                with open(temp_zip_file, \"wb\") as data:\n                    for chunk in response.iter_content(chunk_size=8192):\n                        data.write(chunk)\n\n                shutil.unpack_archive(temp_zip_file, persist_dir)\n\n        except requests.exceptions.HTTPError as e:\n            logger.exception(f\"HTTP Error while fetching {url}\")\n            raise e\n        except Exception as e:\n            logger.exception(f\"Failed to download {url}\")\n            raise e\n\n        logger.info(f\"Downloaded existing index from {url}.\")\n        return cls.from_persist_dir(persist_dir, file_repo)", "kind": "Chunk", "id": "index/code_index.py#182.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.from_index_name_CodeIndex.dict.return._index_name_self__inde", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 238, "span_ids": ["CodeIndex.dict", "CodeIndex.from_index_name"], "start_line": 144, "end_line": 169, "community": null}, "content": "class CodeIndex:\n\n    @classmethod\r\n    def from_index_name(\r\n        cls,\r\n        index_name: str,\r\n        file_repo: FileRepository,\r\n        index_store_dir: Optional[str] = None,\r\n    ):\n        if not index_store_dir:\n            index_store_dir = os.getenv(\"INDEX_STORE_DIR\")\n\n        persist_dir = os.path.join(index_store_dir, index_name)\n        if os.path.exists(persist_dir):\n            logger.info(f\"Loading existing index {index_name} from {persist_dir}.\")\n            return cls.from_persist_dir(persist_dir, file_repo=file_repo)\n\n        if os.getenv(\"INDEX_STORE_URL\"):\n            index_store_url = os.getenv(\"INDEX_STORE_URL\")\n        else:\n            index_store_url = \"https://stmoatless.blob.core.windows.net/indexstore/20240522-voyage-code-2\"\n\n        store_url = os.path.join(index_store_url, f\"{index_name}.zip\")\n        logger.info(f\"Downloading existing index {index_name} from {store_url}.\")\n        return cls.from_url(store_url, persist_dir, file_repo)\n\n    def dict(self):\n        return {\"index_name\": self._index_name}", "kind": "Chunk", "id": "index/code_index.py#183.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.search_CodeIndex.search.return.result", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 294, "span_ids": ["CodeIndex.search"], "start_line": 171, "end_line": 218, "community": null}, "content": "class CodeIndex:\n\n    def search(\r\n        self,\r\n        query: Optional[str] = None,\r\n        code_snippet: Optional[str] = None,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        max_results: int = 25,\r\n    ) -> SearchCodeResponse:\n        if class_names or function_names:\n            result = self.find_by_name(\r\n                class_names=class_names,\r\n                function_names=function_names,\r\n                file_pattern=file_pattern,\r\n            )\n\n            if len(result.hits) == 0 and class_names and function_names:\n                results = []\n                results.extend(\r\n                    self.find_by_name(\r\n                        class_names=class_names,\r\n                        file_pattern=file_pattern,\r\n                        include_functions_in_class=False,\r\n                    ).hits\r\n                )\n                results.extend(\r\n                    self.find_by_name(\r\n                        function_names=function_names, file_pattern=file_pattern\r\n                    ).hits\r\n                )\n\n                if len(results) > 0 and len(results) <= max_results:\n                    return SearchCodeResponse(\r\n                        message=f\"Found {len(results)} hits.\",\r\n                        hits=results,\r\n                    )\n\n        if query or code_snippet:\n            return self.semantic_search(\r\n                query=query,\r\n                code_snippet=code_snippet,\r\n                class_names=class_names,\r\n                function_names=function_names,\r\n                file_pattern=file_pattern,\r\n                max_results=max_results,\r\n            )\n\n        return result", "kind": "Chunk", "id": "index/code_index.py#184.47"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.semantic_search_CodeIndex.semantic_search.require_exact_query_match.False", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 387, "span_ids": ["CodeIndex.semantic_search"], "start_line": 220, "end_line": 272, "community": null}, "content": "class CodeIndex:\n\n    def semantic_search(\r\n        self,\r\n        query: Optional[str] = None,\r\n        code_snippet: Optional[str] = None,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        category: str = \"implementation\",\r\n        max_results: int = 25,\r\n        max_hits_without_exact_match: int = 100,\r\n        max_exact_results: int = 5,\r\n        max_spans_per_file: Optional[int] = None,\r\n        exact_match_if_possible: bool = False,\r\n    ) -> SearchCodeResponse:\n        if query is None:\n            query = \"\"\n\n        if class_names:\n            query += f\", class {class_names}\"\n\n        if function_names:\n            query += f\", function {function_names}\"\n\n        message = \"\"\n        if file_pattern:\n            if category != \"test\":\n                exclude_files = self._file_repo.matching_files(\"**/test*/**\")\n            else:\n                exclude_files = []\n\n            matching_files = self._file_repo.matching_files(file_pattern)\n            matching_files = [\r\n                file for file in matching_files if file not in exclude_files\r\n            ]\n\n            if not matching_files:\n                logger.info(\r\n                    f\"semantic_search() No files found for file pattern {file_pattern}. Will search all files...\"\r\n                )\n                message += f\"No files found for file pattern {file_pattern}. Will search all files.\\n\"\n                file_pattern = None\n\n        search_results = self._vector_search(\r\n            query, file_pattern=file_pattern, exact_content_match=code_snippet\r\n        )\n\n        files_with_spans: dict[str, SearchCodeHit] = {}\n\n        span_count = 0\n        spans_with_exact_query_match = 0\n        filtered_out = 0\n\n        require_exact_query_match = False\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#185.52"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.semantic_search.for_rank_search_hit_in_e_CodeIndex.semantic_search.if_class_names_or_functio.logger_info_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 746, "span_ids": ["CodeIndex.semantic_search"], "start_line": 274, "end_line": 366, "community": null}, "content": "class CodeIndex:\n\n    def semantic_search(\r\n        self,\r\n        query: Optional[str] = None,\r\n        code_snippet: Optional[str] = None,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        category: str = \"implementation\",\r\n        max_results: int = 25,\r\n        max_hits_without_exact_match: int = 100,\r\n        max_exact_results: int = 5,\r\n        max_spans_per_file: Optional[int] = None,\r\n        exact_match_if_possible: bool = False,\r\n    ) -> SearchCodeResponse:\n        # ... other code\n\n        for rank, search_hit in enumerate(search_results):\n            file = self._file_repo.get_file(search_hit.file_path)\n            if not file:\n                logger.warning(\r\n                    f\"semantic_search() Could not find file {search_hit.file_path}.\"\r\n                )\n                continue\n\n            spans = []\n            for span_id in search_hit.span_ids:\n                span = file.module.find_span_by_id(span_id)\n\n                if span:\n                    spans.append(span)\n                else:\n                    logger.debug(\r\n                        f\"semantic_search() Could not find span with id {span_id} in file {file.file_path}\"\r\n                    )\n\n                    spans_by_line_number = file.module.find_spans_by_line_numbers(\r\n                        search_hit.start_line, search_hit.end_line\r\n                    )\n\n                    for span_by_line_number in spans_by_line_number:\n                        spans.append(span_by_line_number)\n\n            names = []\n            if class_names:\n                names.extend(class_names)\n\n            if function_names:\n                names.extend(function_names)\n\n            for span in spans:\n                has_exact_query_match = (\r\n                    exact_match_if_possible\r\n                    and query\r\n                    and span.initiating_block.has_content(query, span.span_id)\r\n                )\n\n                if has_exact_query_match:\n                    spans_with_exact_query_match += 1\n\n                if has_exact_query_match and not require_exact_query_match:\n                    require_exact_query_match = True\n                    files_with_spans = {}\n\n                if (\r\n                    not require_exact_query_match and span_count <= max_results\r\n                ) or has_exact_query_match:\n                    if search_hit.file_path not in files_with_spans:\n                        files_with_spans[search_hit.file_path] = SearchCodeHit(\r\n                            file_path=search_hit.file_path\r\n                        )\n\n                    if files_with_spans[search_hit.file_path].contains_span(\r\n                        span.span_id\r\n                    ):\n                        continue\n\n                    if names and not any(\r\n                        name in span.initiating_block.full_path() for name in names\r\n                    ):\n                        filtered_out += 1\n                        continue\n\n                    span_count += 1\n                    files_with_spans[search_hit.file_path].add_span(\r\n                        span_id=span.span_id, rank=rank, tokens=span.tokens\r\n                    )\n\n                    if (\r\n                        max_spans_per_file\r\n                        and len(files_with_spans[search_hit.file_path].spans)\r\n                        >= max_spans_per_file\r\n                    ):\n                        break\n\n            if exact_match_if_possible:\n                if spans_with_exact_query_match > max_exact_results or (\r\n                    spans_with_exact_query_match == 0\r\n                    and span_count > max_hits_without_exact_match\r\n                ):\n                    break\n            elif span_count > max_results:\n                break\n\n        span_count = sum([len(file.spans) for file in files_with_spans.values()])\n\n        if class_names or function_names:\n            logger.info(\r\n                f\"semantic_search() Filtered out {filtered_out} spans by class names {class_names} and function names {function_names}.\"\r\n            )\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#186.92"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.semantic_search.if_require_exact_query_ma_CodeIndex.semantic_search.return.SearchCodeResponse_messag", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 268, "span_ids": ["CodeIndex.semantic_search"], "start_line": 368, "end_line": 379, "community": null}, "content": "class CodeIndex:\n\n    def semantic_search(\r\n        self,\r\n        query: Optional[str] = None,\r\n        code_snippet: Optional[str] = None,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        category: str = \"implementation\",\r\n        max_results: int = 25,\r\n        max_hits_without_exact_match: int = 100,\r\n        max_exact_results: int = 5,\r\n        max_spans_per_file: Optional[int] = None,\r\n        exact_match_if_possible: bool = False,\r\n    ) -> SearchCodeResponse:\n        # ... other code\n\n        if require_exact_query_match:\n            logger.info(\r\n                f\"semantic_search() Found {spans_with_exact_query_match} code spans with exact match out of {span_count} spans.\"\r\n            )\n            message = f\"Found {spans_with_exact_query_match} code spans with code that matches the exact query `{query}`.\"\n        else:\n            logger.info(\r\n                f\"semantic_search() Found {span_count} code spans in {len(files_with_spans.values())} files.\"\r\n            )\n            message = f\"Found {span_count} code spans.\"\n\n        return SearchCodeResponse(message=message, hits=list(files_with_spans.values()))", "kind": "Chunk", "id": "index/code_index.py#187.11"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.find_by_name_CodeIndex.find_by_name.for_file_path_block_path.if_include_functions_in_c.for_child_in_block_childr.if_.files_with_spans_file_pat", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 787, "span_ids": ["CodeIndex.find_by_name"], "start_line": 381, "end_line": 494, "community": null}, "content": "class CodeIndex:\n\n    def find_by_name(\r\n        self,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        include_functions_in_class: bool = True,\r\n        category: str = \"implementation\",\r\n    ) -> SearchCodeResponse:\n        if not class_names and not function_names:\n            raise ValueError(\r\n                \"At least one of class_name or function_name must be provided.\"\r\n            )\n\n        paths = []\n\n        if function_names:\n            for function_name in function_names:\n                paths.extend(self._blocks_by_function_name.get(function_name, []))\n\n        if class_names:\n            for class_name in class_names:\n                paths.extend(self._blocks_by_class_name.get(class_name, []))\n\n        logger.info(\r\n            f\"find_by_name(class_name={class_names}, function_name={function_names}, file_pattern={file_pattern}) {len(paths)} hits.\"\r\n        )\n\n        if not paths:\n            if function_names:\n                return SearchCodeResponse(\r\n                    message=f\"No functions found with the name {function_names}.\"\r\n                )\n            else:\n                return SearchCodeResponse(\r\n                    message=f\"No classes found with the name {class_names}.\"\r\n                )\n\n        if category != \"test\":\n            exclude_files = self._file_repo.matching_files(\"**/test*/**\")\n\n            filtered_paths = []\n            for file_path, block_path in paths:\n                if file_path not in exclude_files:\n                    filtered_paths.append((file_path, block_path))\n\n            filtered_out_test_files = len(paths) - len(filtered_paths)\n            if filtered_out_test_files > 0:\n                logger.info(\r\n                    f\"find_by_name() Filtered out {filtered_out_test_files} test files.\"\r\n                )\n\n            paths = filtered_paths\n\n        check_all_files = False\n        if file_pattern:\n            include_files = self._file_repo.matching_files(file_pattern)\n\n            if include_files:\n                filtered_paths = []\n                for file_path, block_path in paths:\n                    if file_path in include_files:\n                        filtered_paths.append((file_path, block_path))\n\n                filtered_out_by_file_pattern = len(paths) - len(filtered_paths)\n                if filtered_paths:\n                    logger.info(\r\n                        f\"find_by_name() Filtered out {filtered_out_by_file_pattern} files by file pattern.\"\r\n                    )\n                    paths = filtered_paths\n                else:\n                    logger.info(\r\n                        f\"find_by_name() No files found for file pattern {file_pattern}. Will search all files...\"\r\n                    )\n                    check_all_files = True\n\n        filtered_out_by_class_name = 0\n        invalid_blocks = 0\n\n        files_with_spans = {}\n        for file_path, block_path in paths:\n            file = self._file_repo.get_file(file_path)\n            block = file.module.find_by_path(block_path)\n\n            if not block:\n                invalid_blocks += 1\n                continue\n\n            if (\r\n                class_names\r\n                and function_names\r\n                and not self._found_class(block, class_names)\r\n            ):\n                filtered_out_by_class_name += 1\n                continue\n\n            if file_path not in files_with_spans:\n                files_with_spans[file_path] = SearchCodeHit(file_path=file_path)\n\n            files_with_spans[file_path].add_span(\r\n                block.belongs_to_span.span_id,\r\n                rank=0,\r\n                tokens=block.belongs_to_span.tokens,\r\n            )\n            if include_functions_in_class and not function_names:\n                for child in block.children:\n                    if (\r\n                        child.belongs_to_span.span_id\r\n                        not in files_with_spans[file_path].span_ids\r\n                    ):\n                        files_with_spans[file_path].add_span(\r\n                            child.belongs_to_span.span_id,\r\n                            rank=0,\r\n                            tokens=child.belongs_to_span.tokens,\r\n                        )\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#188.113"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.find_by_name.if_filtered_out_by_class__CodeIndex.find_by_name.return.SearchCodeResponse_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 399, "span_ids": ["CodeIndex.find_by_name"], "start_line": 496, "end_line": 533, "community": null}, "content": "class CodeIndex:\n\n    def find_by_name(\r\n        self,\r\n        class_names: list[str] = None,\r\n        function_names: list[str] = None,\r\n        file_pattern: Optional[str] = None,\r\n        include_functions_in_class: bool = True,\r\n        category: str = \"implementation\",\r\n    ) -> SearchCodeResponse:\n        # ... other code\n\n        if filtered_out_by_class_name > 0:\n            logger.info(\r\n                f\"find_by_function_name() Filtered out {filtered_out_by_class_name} functions by class name {class_name}.\"\r\n            )\n\n        if invalid_blocks > 0:\n            logger.info(\r\n                f\"find_by_function_name() Ignored {invalid_blocks} invalid blocks.\"\r\n            )\n\n        if check_all_files and len(files_with_spans) > 0:\n            message = f\"The file pattern {file_pattern} didn't match any files. But I found {len(files_with_spans)} matches in other files.\"\n        elif len(files_with_spans):\n            message = f\"Found {len(files_with_spans)} hits.\"\n        elif class_names and function_names:\n            message = f\"No functions found with the names {function_names} in class {class_names}.\"\n        elif class_names:\n            message = f\"No classes found with the name {class_names}.\"\n        elif function_names:\n            message = f\"No functions found with the names {function_names}.\"\n        else:\n            message = \"No results found.\"\n\n        file_paths = [file.file_path for file in files_with_spans.values()]\n        if file_pattern:\n            file_paths = _rerank_files(file_paths, file_pattern)\n\n        search_hits = []\n        for rank, file_path in enumerate(file_paths):\n            file = files_with_spans[file_path]\n            for span in file.spans:\n                span.rank = rank\n            search_hits.append(file)\n\n        return SearchCodeResponse(\r\n            message=message,\r\n            hits=search_hits,\r\n        )", "kind": "Chunk", "id": "index/code_index.py#189.37"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex._found_class_CodeIndex._create_search_hit.return.file_hit", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 125, "span_ids": ["CodeIndex._found_class", "CodeIndex._create_search_hit"], "start_line": 535, "end_line": 547, "community": null}, "content": "class CodeIndex:\n\n    def _found_class(self, block: CodeBlock, class_names: list[str]):\n        for class_name in class_names:\n            parent_class = block.find_type_in_parents(CodeBlockType.CLASS)\n            if parent_class and parent_class.identifier == class_name:\n                return True\n        else:\n            return False\n\n    def _create_search_hit(self, file: FileWithSpans, rank: int = 0):\n        file_hit = SearchCodeHit(file_path=file.file_path)\n        for span_id in file.span_ids:\n            file_hit.add_span(span_id, rank)\n        return file_hit", "kind": "Chunk", "id": "index/code_index.py#190.12"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex._vector_search_CodeIndex._vector_search.return.search_results", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 818, "span_ids": ["CodeIndex._vector_search"], "start_line": 549, "end_line": 666, "community": null}, "content": "class CodeIndex:\n\n    def _vector_search(\r\n        self,\r\n        query: str = \"\",\r\n        exact_query_match: bool = False,\r\n        category: str = \"implementation\",\r\n        file_pattern: Optional[str] = None,\r\n        exact_content_match: Optional[str] = None,\r\n    ):\n        if file_pattern:\n            query += f\" file:{file_pattern}\"\n\n        if exact_content_match:\n            query += \"\\n\" + exact_content_match\n\n        if not query:\n            raise ValueError(\r\n                \"At least one of query, span_keywords or content_keywords must be provided.\"\r\n            )\n\n        logger.info(\r\n            f\"vector_search() Searching for query [{query[:50]}...] and file pattern [{file_pattern}].\"\r\n        )\n\n        query_embedding = self._embed_model.get_query_embedding(query)\n\n        filters = MetadataFilters(filters=[], condition=FilterCondition.AND)\n        if category:\n            filters.filters.append(MetadataFilter(key=\"category\", value=category))\n\n        query_bundle = VectorStoreQuery(\r\n            query_str=query,\r\n            query_embedding=query_embedding,\r\n            similarity_top_k=500,  # TODO: Fix paging?\r\n            filters=filters,\r\n        )\n\n        result = self._vector_store.query(query_bundle)\n\n        filtered_out_snippets = 0\n        ignored_removed_snippets = 0\n        sum_tokens = 0\n\n        sum_tokens_per_file = {}\n\n        if file_pattern:\n            include_files = self._file_repo.matching_files(file_pattern)\n            if len(include_files) == 0:\n                logger.info(\r\n                    f\"vector_search() No files found for file pattern {file_pattern}, return empty result...\"\r\n                )\n                return []\n        else:\n            include_files = []\n\n        if category != \"test\":\n            exclude_files = self._file_repo.find_files(\r\n                [\"**/tests/**\", \"tests*\", \"*_test.py\", \"test_*.py\"]\r\n            )\n        else:\n            exclude_files = set()\n\n        search_results = []\n\n        for node_id, distance in zip(result.ids, result.similarities, strict=False):\n            node_doc = self._docstore.get_document(node_id, raise_error=False)\n            if not node_doc:\n                ignored_removed_snippets += 1\n                # TODO: Retry to get top_k results\r\n                continue\n\n            if exclude_files and node_doc.metadata[\"file_path\"] in exclude_files:\n                filtered_out_snippets += 1\n                continue\n\n            if include_files and node_doc.metadata[\"file_path\"] not in include_files:\n                filtered_out_snippets += 1\n                continue\n\n            if exact_query_match and query not in node_doc.get_content():\n                filtered_out_snippets += 1\n                continue\n\n            if exact_content_match and not is_string_in(\r\n                exact_content_match, node_doc.get_content()\r\n            ):\n                filtered_out_snippets += 1\n                continue\n\n            if node_doc.metadata[\"file_path\"] not in sum_tokens_per_file:\n                sum_tokens_per_file[node_doc.metadata[\"file_path\"]] = 0\n\n            sum_tokens += node_doc.metadata[\"tokens\"]\n            sum_tokens_per_file[node_doc.metadata[\"file_path\"]] += node_doc.metadata[\r\n                \"tokens\"\r\n            ]\n\n            code_snippet = CodeSnippet(\r\n                id=node_doc.id_,\r\n                file_path=node_doc.metadata[\"file_path\"],\r\n                distance=distance,\r\n                content=node_doc.get_content(),\r\n                tokens=node_doc.metadata[\"tokens\"],\r\n                span_ids=node_doc.metadata.get(\"span_ids\", []),\r\n                start_line=node_doc.metadata.get(\"start_line\", None),\r\n                end_line=node_doc.metadata.get(\"end_line\", None),\r\n            )\n\n            search_results.append(code_snippet)\n\n        # TODO: Rerank by file pattern if no exact matches on file pattern\r\n\n        logger.info(\r\n            f\"vector_search() Returning {len(search_results)} search results. \"\r\n            f\"(Ignored {ignored_removed_snippets} removed search results. \"\r\n            f\"Filtered out {filtered_out_snippets} search results.)\"\r\n        )\n\n        return search_results", "kind": "Chunk", "id": "index/code_index.py#191.117"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.run_ingestion_CodeIndex.run_ingestion.file_metadata_func.return._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 232, "span_ids": ["CodeIndex.run_ingestion"], "start_line": 668, "end_line": 699, "community": null}, "content": "class CodeIndex:\n\n    def run_ingestion(\r\n        self,\r\n        repo_path: Optional[str] = None,\r\n        input_files: list[str] | None = None,\r\n        num_workers: Optional[int] = None,\r\n    ):\n        repo_path = repo_path or self._file_repo.path\n\n        # Only extract file name and type to not trigger unnecessary embedding jobs\r\n        def file_metadata_func(file_path: str) -> dict:\n            file_path = file_path.replace(repo_path, \"\")\n            if file_path.startswith(\"/\"):\n                file_path = file_path[1:]\n\n            test_patterns = [\r\n                \"**/test/**\",\r\n                \"**/tests/**\",\r\n                \"**/test_*.py\",\r\n                \"**/*_test.py\",\r\n            ]\n            category = (\r\n                \"test\"\r\n                if any(fnmatch.fnmatch(file_path, pattern) for pattern in test_patterns)\r\n                else \"implementation\"\r\n            )\n\n            return {\r\n                \"file_path\": file_path,\r\n                \"file_name\": os.path.basename(file_path),\r\n                \"file_type\": mimetypes.guess_type(file_path)[0],\r\n                \"category\": category,\r\n            }\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#192.31"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.run_ingestion.if_self__settings_and_sel_CodeIndex.run_ingestion.blocks_by_function_name._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 269, "span_ids": ["CodeIndex.run_ingestion"], "start_line": 701, "end_line": 730, "community": null}, "content": "class CodeIndex:\n\n    def run_ingestion(\r\n        self,\r\n        repo_path: Optional[str] = None,\r\n        input_files: list[str] | None = None,\r\n        num_workers: Optional[int] = None,\r\n    ):\n        # ... other code\n\n        if self._settings and self._settings.language == \"java\":\n            required_exts = [\".java\"]\n        else:\n            required_exts = [\".py\"]\n\n        try:\n            reader = SimpleDirectoryReader(\r\n                input_dir=repo_path,\r\n                file_metadata=file_metadata_func,\r\n                input_files=input_files,\r\n                filename_as_id=True,\r\n                required_exts=required_exts,\r\n                recursive=True,\r\n            )\n        except Exception as e:\n            logger.exception(f\"Failed to create reader with input_dir {repo_path}, input_files {input_files} and required_exts {required_exts}.\")\n            raise e\n\n        embed_pipeline = IngestionPipeline(\r\n            transformations=[self._embed_model],\r\n            docstore_strategy=DocstoreStrategy.UPSERTS_AND_DELETE,\r\n            docstore=self._docstore,\r\n            vector_store=self._vector_store,\r\n        )\n\n        docs = reader.load_data()\n        logger.info(f\"Read {len(docs)} documents\")\n\n        blocks_by_class_name = {}\n        blocks_by_function_name = {}\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#193.29"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.run_ingestion.index_callback_CodeIndex.run_ingestion.index_callback.None_1.blocks_by_function_name_c", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 189, "span_ids": ["CodeIndex.run_ingestion"], "start_line": 732, "end_line": 745, "community": null}, "content": "class CodeIndex:\n\n    def run_ingestion(\r\n        self,\r\n        repo_path: Optional[str] = None,\r\n        input_files: list[str] | None = None,\r\n        num_workers: Optional[int] = None,\r\n    ):\n        # ... other code\n\n        def index_callback(codeblock: CodeBlock):\n            if codeblock.type == CodeBlockType.CLASS:\n                if codeblock.identifier not in blocks_by_class_name:\n                    blocks_by_class_name[codeblock.identifier] = []\n                blocks_by_class_name[codeblock.identifier].append(\r\n                    (codeblock.module.file_path, codeblock.full_path())\r\n                )\n\n            if codeblock.type == CodeBlockType.FUNCTION:\n                if codeblock.identifier not in blocks_by_function_name:\n                    blocks_by_function_name[codeblock.identifier] = []\n                blocks_by_function_name[codeblock.identifier].append(\r\n                    (codeblock.module.file_path, codeblock.full_path())\r\n                )\n        # ... other code", "kind": "Chunk", "id": "index/code_index.py#194.13"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.run_ingestion.splitter_CodeIndex.run_ingestion.return.len_embedded_nodes_embe", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 321, "span_ids": ["CodeIndex.run_ingestion"], "start_line": 747, "end_line": 785, "community": null}, "content": "class CodeIndex:\n\n    def run_ingestion(\r\n        self,\r\n        repo_path: Optional[str] = None,\r\n        input_files: list[str] | None = None,\r\n        num_workers: Optional[int] = None,\r\n    ):\n        # ... other code\n\n        splitter = EpicSplitter(\r\n            language=self._settings.language,\r\n            min_chunk_size=self._settings.min_chunk_size,\r\n            chunk_size=self._settings.chunk_size,\r\n            hard_token_limit=self._settings.hard_token_limit,\r\n            max_chunks=self._settings.max_chunks,\r\n            comment_strategy=self._settings.comment_strategy,\r\n            index_callback=index_callback,\r\n            repo_path=repo_path,\r\n        )\n\n        prepared_nodes = splitter.get_nodes_from_documents(docs, show_progress=True)\n        prepared_tokens = sum(\r\n            [\r\n                count_tokens(node.get_content(), self._settings.embed_model)\r\n                for node in prepared_nodes\r\n            ]\r\n        )\n        logger.info(\r\n            f\"Prepared {len(prepared_nodes)} nodes and {prepared_tokens} tokens\"\r\n        )\n\n        embedded_nodes = embed_pipeline.run(\r\n            nodes=list(prepared_nodes), show_progress=True, num_workers=num_workers\r\n        )\n        embedded_tokens = sum(\r\n            [\r\n                count_tokens(node.get_content(), self._settings.embed_model)\r\n                for node in embedded_nodes\r\n            ]\r\n        )\n        logger.info(\r\n            f\"Embedded {len(embedded_nodes)} vectors with {embedded_tokens} tokens\"\r\n        )\n\n        self._blocks_by_class_name = blocks_by_class_name\n        self._blocks_by_function_name = blocks_by_function_name\n\n        return len(embedded_nodes), embedded_tokens", "kind": "Chunk", "id": "index/code_index.py#195.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py_CodeIndex.persist_CodeIndex.persist.None_1.f_write_json_dumps_self__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 137, "span_ids": ["CodeIndex.persist"], "start_line": 787, "end_line": 798, "community": null}, "content": "class CodeIndex:\n\n    def persist(self, persist_dir: str):\n        self._vector_store.persist(persist_dir)\n        self._docstore.persist(\r\n            os.path.join(persist_dir, docstore.types.DEFAULT_PERSIST_FNAME)\r\n        )\n        self._settings.persist(persist_dir)\n\n        with open(os.path.join(persist_dir, \"blocks_by_class_name.json\"), \"w\") as f:\n            f.write(json.dumps(self._blocks_by_class_name, indent=2))\n\n        with open(os.path.join(persist_dir, \"blocks_by_function_name.json\"), \"w\") as f:\n            f.write(json.dumps(self._blocks_by_function_name, indent=2))", "kind": "Chunk", "id": "index/code_index.py#196.11"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py__rerank_files_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_index.py", "file_name": "code_index.py", "file_type": "text/x-python", "category": "test", "tokens": 267, "span_ids": ["_rerank_files", "is_string_in"], "start_line": 801, "end_line": 831, "community": null}, "content": "def _rerank_files(file_paths: list[str], file_pattern: str):\n    if len(file_paths) < 2:\n        return file_paths\n\n    tokenized_query = file_pattern.replace(\".py\", \"\").replace(\"*\", \"\").split(\"/\")\n    tokenized_query = [part for part in tokenized_query if part.strip()]\n    query = \"/\".join(tokenized_query)\n\n    scored_files = []\n    for file_path in file_paths:\n        cleaned_file_path = file_path.replace(\".py\", \"\")\n        score = fuzz.partial_ratio(cleaned_file_path, query)\n        scored_files.append((file_path, score))\n\n    scored_files.sort(key=lambda x: x[1], reverse=True)\n\n    sorted_file_paths = [file for file, score in scored_files]\n\n    logger.info(\r\n        f\"rerank_files() Reranked {len(file_paths)} files with query {tokenized_query}. First hit {sorted_file_paths[0]}\"\r\n    )\n\n    return sorted_file_paths\n\n\ndef is_string_in(s1, s2):\n    s1_clean = s1.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n    s2_clean = s2.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n    found_in = s1_clean in s2_clean\n    return found_in", "kind": "Chunk", "id": "index/code_index.py#197.30"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_node.py_from_hashlib_import_sha25_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\code_node.py", "file_name": "code_node.py", "file_type": "text/x-python", "category": "test", "tokens": 111, "span_ids": ["CodeNode.hash", "imports", "CodeNode"], "start_line": 1, "end_line": 15, "community": null}, "content": "from hashlib import sha256\n\nfrom llama_index.core.schema import TextNode\n\n\nclass CodeNode(TextNode):\n    # Skip start and end line in metadata to try to lower the number of changes and triggers of new embeddings.\r\n    @property\r\n    def hash(self):\n        metadata = self.metadata.copy()\n        metadata.pop(\"start_line\", None)\n        metadata.pop(\"end_line\", None)\n        doc_identity = str(self.text) + str(metadata)\n        return str(sha256(doc_identity.encode(\"utf-8\", \"surrogatepass\")).hexdigest())", "kind": "Chunk", "id": "index/code_node.py#198.14"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\embed_model.py_os_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\embed_model.py", "file_name": "embed_model.py", "file_type": "text/x-python", "category": "test", "tokens": 271, "span_ids": ["imports", "get_embed_model"], "start_line": 1, "end_line": 36, "community": null}, "content": "import os\n\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\n\n\ndef get_embed_model(model_name: str) -> BaseEmbedding:\n    if model_name.startswith(\"voyage\"):\n        try:\n            from llama_index.embeddings.voyageai import VoyageEmbedding\n        except ImportError as e:\n            raise ImportError(\r\n                \"llama-index-embeddings-voyageai is not installed. Please install it using `pip install llama-index-embeddings-voyageai`\"\r\n            ) from e\n\n        if \"VOYAGE_API_KEY\" not in os.environ:\n            raise ValueError(\r\n                \"VOYAGE_API_KEY environment variable is not set. Please set it to your Voyage API key.\"\r\n            )\n\n        return VoyageEmbedding(\r\n            model_name=model_name,\r\n            voyage_api_key=os.environ.get(\"VOYAGE_API_KEY\"),\r\n            truncation=True,\r\n            embed_batch_size=50,\r\n        )\n    else:\r\n        # Assumes OpenAI otherwise\r\n        try:\n            from llama_index.embeddings.openai import OpenAIEmbedding\n        except ImportError as e:\n            raise ImportError(\r\n                \"llama-index-embeddings-openai is not installed. Please install it using `pip install llama-index-embeddings-openai`\"\r\n            ) from e\n\n        return OpenAIEmbedding(model_name=model_name)", "kind": "Chunk", "id": "index/embed_model.py#199.35"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_re_SPLIT_BLOCK_TYPES._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 275, "span_ids": ["impl:3", "imports", "count_chunk_tokens", "count_parent_tokens"], "start_line": 1, "end_line": 39, "community": null}, "content": "import re\nimport time\nfrom collections.abc import Callable, Sequence\nfrom typing import Any, Optional\n\nfrom llama_index.core.bridge.pydantic import Field\nfrom llama_index.core.callbacks import CallbackManager\nfrom llama_index.core.node_parser import NodeParser, TextSplitter, TokenTextSplitter\nfrom llama_index.core.node_parser.node_utils import logger\nfrom llama_index.core.schema import BaseNode, TextNode\nfrom llama_index.core.utils import get_tokenizer, get_tqdm_iterable\n\nfrom moatless.codeblocks import create_parser\nfrom moatless.codeblocks.codeblocks import CodeBlock, CodeBlockType, PathTree\nfrom moatless.codeblocks.parser.python import PythonParser\nfrom moatless.index.code_node import CodeNode\nfrom moatless.index.settings import CommentStrategy\n\nCodeBlockChunk = list[CodeBlock]\n\n\ndef count_chunk_tokens(chunk: CodeBlockChunk) -> int:\n    return sum([block.tokens for block in chunk])\n\n\ndef count_parent_tokens(codeblock: CodeBlock) -> int:\n    tokens = codeblock.tokens\n    if codeblock.parent:\n        tokens += codeblock.parent.tokens\n    return tokens\n\n\nSPLIT_BLOCK_TYPES = [\r\n    CodeBlockType.FUNCTION,\r\n    CodeBlockType.CLASS,\r\n    CodeBlockType.TEST_SUITE,\r\n    CodeBlockType.TEST_CASE,\r\n    CodeBlockType.MODULE,\r\n]", "kind": "Chunk", "id": "index/epic_split.py#200.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter_EpicSplitter.class_name.return._GhostcoderNodeParser_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 745, "span_ids": ["EpicSplitter", "EpicSplitter.__init__", "EpicSplitter.class_name"], "start_line": 42, "end_line": 135, "community": null}, "content": "class EpicSplitter(NodeParser):\n    language: str = Field(\r\n        default=\"python\", description=\"Language of the code blocks to parse.\"\r\n    )\n\n    text_splitter: TextSplitter = Field(\r\n        description=\"Text splitter to use for splitting non code documents into nodes.\"\r\n    )\n\n    include_non_code_files: bool = Field(\r\n        default=True, description=\"Whether or not to include non code files.\"\r\n    )\n\n    non_code_file_extensions: list[str] = Field(\r\n        default=[\"md\", \"txt\"],\r\n        description=\"File extensions to consider as non code files.\",\r\n    )\n\n    comment_strategy: CommentStrategy = Field(\r\n        default=CommentStrategy.INCLUDE, description=\"Comment strategy to use.\"\r\n    )\n\n    chunk_size: int = Field(\r\n        default=1500, description=\"Chunk size to use for splitting code documents.\"\r\n    )\n\n    max_chunks: int = Field(\r\n        default=100, description=\"Max number of chunks to split a document into.\"\r\n    )\n\n    min_chunk_size: int = Field(default=256, description=\"Min tokens to split code.\")\n\n    max_chunk_size: int = Field(default=2000, description=\"Max tokens in one chunk.\")\n\n    hard_token_limit: int = Field(\r\n        default=6000, description=\"Hard token limit for a chunk.\"\r\n    )\n\n    repo_path: str = Field(default=None, description=\"Path to the repository.\")\n\n    index_callback: Optional[Callable] = Field(\r\n        default=None, description=\"Callback to call when indexing a code block.\"\r\n    )\n\n    # _fallback_code_splitter: Optional[TextSplitter] = PrivateAttr() TODO: Implement fallback when tree sitter fails\r\n\n    def __init__(\r\n        self,\r\n        language: str = \"python\",\r\n        chunk_size: int = 750,\r\n        min_chunk_size: int = 100,\r\n        max_chunk_size: int = 1500,\r\n        hard_token_limit: int = 6000,\r\n        max_chunks: int = 100,\r\n        include_metadata: bool = True,\r\n        include_prev_next_rel: bool = True,\r\n        text_splitter: TextSplitter | None = None,\r\n        index_callback: Optional[Callable[[CodeBlock], None]] = None,\r\n        repo_path: Optional[str] = None,\r\n        comment_strategy: CommentStrategy = CommentStrategy.ASSOCIATE,\r\n        # fallback_code_splitter: Optional[TextSplitter] = None,\r\n        include_non_code_files: bool = True,\r\n        tokenizer: Optional[Callable] = None,\r\n        non_code_file_extensions: list[str] | None = None,\r\n        callback_manager: CallbackManager | None = None,\r\n    ) -> None:\n        if non_code_file_extensions is None:\n            non_code_file_extensions = [\"md\", \"txt\"]\n        callback_manager = callback_manager or CallbackManager([])\n\n        # self._fallback_code_splitter = fallback_code_splitter\r\n\n        super().__init__(\r\n            language=language,\r\n            chunk_size=chunk_size,\r\n            chunk_overlap=0,\r\n            text_splitter=text_splitter or TokenTextSplitter(),\r\n            min_chunk_size=min_chunk_size,\r\n            max_chunk_size=max_chunk_size,\r\n            hard_token_limit=hard_token_limit,\r\n            max_chunks=max_chunks,\r\n            index_callback=index_callback,\r\n            repo_path=repo_path,\r\n            comment_strategy=comment_strategy,\r\n            include_non_code_files=include_non_code_files,\r\n            non_code_file_extensions=non_code_file_extensions,\r\n            include_metadata=include_metadata,\r\n            include_prev_next_rel=include_prev_next_rel,\r\n            callback_manager=callback_manager,\r\n        )\n\n    @classmethod\r\n    def class_name(cls):\n        return \"GhostcoderNodeParser\"", "kind": "Chunk", "id": "index/epic_split.py#201.93"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._parse_nodes_EpicSplitter._parse_nodes.return.all_nodes", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 488, "span_ids": ["EpicSplitter._parse_nodes"], "start_line": 137, "end_line": 193, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _parse_nodes(\r\n        self,\r\n        nodes: Sequence[BaseNode],\r\n        show_progress: bool = False,\r\n        **kwargs: Any,\r\n    ) -> list[BaseNode]:\n        nodes_with_progress = get_tqdm_iterable(nodes, show_progress, \"Parsing nodes\")\n\n        all_nodes: list[BaseNode] = []\n\n        for node in nodes_with_progress:\n            file_path = node.metadata.get(\"file_path\")\n            content = node.get_content()\n\n            try:\n                starttime = time.time_ns()\n\n                # TODO: Derive language from file extension\r\n                parser = create_parser(language=self.language, index_callback=self.index_callback)\n                codeblock = parser.parse(content, file_path=file_path)\n\n                parse_time = time.time_ns() - starttime\n                if parse_time > 1e9:\n                    logger.warning(\r\n                        f\"Parsing file {file_path} took {parse_time / 1e9:.2f} seconds.\"\r\n                    )\n\n            except Exception as e:\n                logger.warning(\r\n                    f\"Failed to use epic splitter to split {file_path}. Fallback to treesitter_split(). Error: {e}\"\r\n                )\n                # TODO: Fall back to treesitter or text split\r\n                continue\n\n            starttime = time.time_ns()\n            chunks = self._chunk_contents(codeblock=codeblock, file_path=file_path)\n            parse_time = time.time_ns() - starttime\n            if parse_time > 1e8:\n                logger.warning(\r\n                    f\"Splitting file {file_path} took {parse_time / 1e9:.2f} seconds.\"\r\n                )\n            if len(chunks) > 100:\n                logger.info(f\"Splitting file {file_path} in {len(chunks)} chunks\")\n\n            starttime = time.time_ns()\n            for chunk in chunks:\n                path_tree = self._create_path_tree(chunk)\n                content = self._to_context_string(codeblock, path_tree)\n                chunk_node = self._create_node(content, node, chunk=chunk)\n                if chunk_node:\n                    all_nodes.append(chunk_node)\n            parse_time = time.time_ns() - starttime\n            if parse_time > 1e9:\n                logger.warning(\r\n                    f\"Create nodes for file {file_path} took {parse_time / 1e9:.2f} seconds.\"\r\n                )\n        return all_nodes", "kind": "Chunk", "id": "index/epic_split.py#202.56"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._chunk_contents_EpicSplitter._chunk_contents.return.self__chunk_block_codeblo", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 304, "span_ids": ["EpicSplitter._chunk_contents"], "start_line": 195, "end_line": 228, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _chunk_contents(\r\n        self, codeblock: CodeBlock | None = None, file_path: Optional[str] = None\r\n    ) -> list[CodeBlockChunk]:\n        tokens = codeblock.sum_tokens()\n        if tokens == 0:\n            logger.debug(f\"Skipping file {file_path} because it has no tokens.\")\n            return []\n\n        if codeblock.find_errors():\n            logger.warning(\r\n                f\"Failed to use spic splitter to split {file_path}. {len(codeblock.find_errors())} codeblocks with type ERROR. Fallback to treesitter_split()\"\r\n            )\n            # TODO: Fall back to treesitter or text split\r\n            return []\n\n        if tokens > self.hard_token_limit:\n            for child in codeblock.children:\n                if (\r\n                    child.type == CodeBlockType.COMMENT\r\n                    and \"generated\" in child.content.lower()\r\n                ):  # TODO: Make a generic solution to detect files that shouldn't be indexed. Maybe ask an LLM?\r\n                    logger.info(\r\n                        f\"File {file_path} has {tokens} tokens and the word 'generated' in the first comments,\"\r\n                        f\" will assume it's a generated file.\"\r\n                    )\n                    return []\n                else:\n                    break\n\n        if tokens < self.min_chunk_size:\n            child_blocks = codeblock.get_all_child_blocks()\n            return [[codeblock] + child_blocks]\n\n        return self._chunk_block(codeblock, file_path)", "kind": "Chunk", "id": "index/epic_split.py#203.33"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._chunk_block_EpicSplitter._chunk_block.return.self__merge_chunks_chunks", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 598, "span_ids": ["EpicSplitter._chunk_block"], "start_line": 230, "end_line": 324, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _chunk_block(\r\n        self, codeblock: CodeBlock, file_path: Optional[str] = None\r\n    ) -> list[CodeBlockChunk]:\n        chunks: list[CodeBlockChunk] = []\n        current_chunk = []\n        comment_chunk = []\n\n        parent_tokens = count_parent_tokens(codeblock)\n\n        ignoring_comment = False\n\n        for child in codeblock.children:\n            if child.type == CodeBlockType.COMMENT:\n                if self.comment_strategy == CommentStrategy.EXCLUDE:\n                    continue\n                elif self._ignore_comment(child) or ignoring_comment:\n                    ignoring_comment = True\n                    continue\n                elif (\r\n                    self.comment_strategy == CommentStrategy.ASSOCIATE\r\n                    and not codeblock.parent\r\n                ):\n                    comment_chunk.append(child)\n                    continue\n            else:\n                if child.tokens > self.max_chunk_size:\n                    start_content = child.content[:100]\n                    logger.warning(\r\n                        f\"Skipping code block {child.path_string()} in {file_path} as it has {child.tokens} tokens which is\"\r\n                        f\" more than chunk size {self.chunk_size}. Content: {start_content}...\"\r\n                    )\n                    continue\n\n                ignoring_comment = False\n\n            if (\r\n                child.type in SPLIT_BLOCK_TYPES\r\n                and child.sum_tokens() > self.min_chunk_size\r\n            ) or parent_tokens + child.sum_tokens() > self.max_chunk_size:\n                if current_chunk:\n                    chunks.append(current_chunk)\n                    current_chunk = []\n\n                current_chunk.extend(comment_chunk)\n                comment_chunk = []\n                current_chunk.append(child)\n\n                child_chunks = self._chunk_block(child, file_path=file_path)\n\n                if child_chunks:\n                    first_child_chunk = child_chunks[0]\n\n                    if (\r\n                        parent_tokens\r\n                        + child.tokens\r\n                        + count_chunk_tokens(first_child_chunk)\r\n                        < self.max_chunk_size\r\n                    ):\n                        current_chunk.extend(first_child_chunk)\n                        chunks.append(current_chunk)\n                        chunks.extend(child_chunks[1:])\n                        current_chunk = []\n                    else:\n                        chunks.append(current_chunk)\n                        chunks.extend(child_chunks)\n                        current_chunk = []\n\n                continue\n\n            new_token_count = (\r\n                parent_tokens + count_chunk_tokens(current_chunk) + child.sum_tokens()\r\n            )\n            if (\r\n                codeblock.type not in SPLIT_BLOCK_TYPES\r\n                and new_token_count < self.max_chunk_size\r\n                or new_token_count < self.chunk_size\r\n            ):\n                current_chunk.extend(comment_chunk)\n                current_chunk.append(child)\n            else:\n                if current_chunk:\n                    current_chunk.extend(comment_chunk)\n                    chunks.append(current_chunk)\n                current_chunk = [child]\n\n            comment_chunk = []\n            child_blocks = child.get_all_child_blocks()\n            current_chunk.extend(child_blocks)\n\n        if chunks and count_chunk_tokens(current_chunk) < self.min_chunk_size:\n            chunks[-1].extend(current_chunk)\n        else:\n            chunks.append(current_chunk)\n\n        return self._merge_chunks(chunks)", "kind": "Chunk", "id": "index/epic_split.py#204.94"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._merge_chunks_EpicSplitter._ignore_comment.return._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 525, "span_ids": ["EpicSplitter._merge_chunks", "EpicSplitter._ignore_comment", "EpicSplitter._create_path_tree"], "start_line": 326, "end_line": 402, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _merge_chunks(self, chunks: list[CodeBlockChunk]) -> list[CodeBlockChunk]:\n        while True:\n            merged_chunks = []\n            should_continue = False\n\n            for i, chunk in enumerate(chunks):\n                if (\r\n                    count_chunk_tokens(chunk) < self.min_chunk_size\r\n                    or len(chunks) > self.max_chunks\r\n                ):\n                    if i == 0 and len(chunks) > 1:\n                        if (\r\n                            count_chunk_tokens(chunks[1]) + count_chunk_tokens(chunk)\r\n                            <= self.hard_token_limit\r\n                        ):\n                            chunks[1] = chunk + chunks[1]\n                            should_continue = True\n                        else:\n                            merged_chunks.append(chunk)\n\n                    elif i == len(chunks) - 1:\n                        if (\r\n                            merged_chunks\r\n                            and count_chunk_tokens(merged_chunks[-1])\r\n                            + count_chunk_tokens(chunk)\r\n                            <= self.hard_token_limit\r\n                        ):\n                            merged_chunks[-1] = merged_chunks[-1] + chunk\n                            should_continue = True\n                        else:\n                            merged_chunks.append(chunk)\n\n                    else:\n                        if count_chunk_tokens(chunks[i - 1]) < count_chunk_tokens(\r\n                            chunks[i + 1]\r\n                        ):\n                            if (\r\n                                merged_chunks\r\n                                and count_chunk_tokens(merged_chunks[-1])\r\n                                + count_chunk_tokens(chunk)\r\n                                <= self.hard_token_limit\r\n                            ):\n                                merged_chunks[-1] = merged_chunks[-1] + chunk\n                                should_continue = True\n                            else:\n                                merged_chunks.append(chunk)\n                        else:\n                            if (\r\n                                count_chunk_tokens(chunks[i + 1])\r\n                                + count_chunk_tokens(chunk)\r\n                                <= self.hard_token_limit\r\n                            ):\n                                chunks[i + 1] = chunk + chunks[i + 1]\n                                should_continue = True\n                            else:\n                                merged_chunks.append(chunk)\n                else:\n                    merged_chunks.append(chunk)\n\n            chunks = merged_chunks + chunks[i + 1 :]\n\n            if len(chunks) < self.max_chunks or not should_continue:\n                break\n\n        return chunks\n\n    def _create_path_tree(self, blocks: list[CodeBlock]) -> PathTree:\n        path_tree = PathTree()\n        for block in blocks:\n            path_tree.add_to_tree(block.full_path())\n        return path_tree\n\n    def _ignore_comment(self, codeblock: CodeBlock) -> bool:\n        return (\r\n            re.search(r\"(?i)copyright|license|author\", codeblock.content)\r\n            or not codeblock.content\r\n        )", "kind": "Chunk", "id": "index/epic_split.py#205.76"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._to_context_string_EpicSplitter._to_context_string.return.contents", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 424, "span_ids": ["EpicSplitter._to_context_string"], "start_line": 404, "end_line": 462, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _to_context_string(self, codeblock: CodeBlock, path_tree: PathTree) -> str:\n        contents = \"\"\n\n        if codeblock.pre_lines:\n            contents += \"\\n\" * (codeblock.pre_lines - 1)\n            for i, line in enumerate(codeblock.content_lines):\n                if i == 0 and line:\n                    contents += \"\\n\" + codeblock.indentation + line\n                elif line:\n                    contents += \"\\n\" + line\n                else:\n                    contents += \"\\n\"\n        else:\n            contents += codeblock.pre_code + codeblock.content\n\n        has_outcommented_code = False\n        for _i, child in enumerate(codeblock.children):\n            child_tree = path_tree.child_tree(child.identifier)\n            if child_tree and child_tree.show:\n                if (\r\n                    has_outcommented_code\r\n                    and child.type\r\n                    not in [\r\n                        CodeBlockType.COMMENT,\r\n                        CodeBlockType.COMMENTED_OUT_CODE,\r\n                    ]\r\n                    and codeblock.type\r\n                    not in [\r\n                        CodeBlockType.CLASS,\r\n                        CodeBlockType.MODULE,\r\n                        CodeBlockType.TEST_SUITE,\r\n                    ]\r\n                ):\n                    contents += child.create_commented_out_block(\r\n                        \"... other code\"\r\n                    ).to_string()\n                contents += self._to_context_string(\r\n                    codeblock=child, path_tree=child_tree\r\n                )\n                has_outcommented_code = False\n            elif child_tree:\n                contents += self._to_context_string(\r\n                    codeblock=child, path_tree=child_tree\r\n                )\n                has_outcommented_code = False\n            elif child.type not in [\r\n                CodeBlockType.COMMENT,\r\n                CodeBlockType.COMMENTED_OUT_CODE,\r\n            ]:\n                has_outcommented_code = True\n\n        if has_outcommented_code and codeblock.type not in [\r\n            CodeBlockType.CLASS,\r\n            CodeBlockType.MODULE,\r\n            CodeBlockType.TEST_SUITE,\r\n        ]:\n            contents += child.create_commented_out_block(\"... other code\").to_string()\n\n        return contents", "kind": "Chunk", "id": "index/epic_split.py#206.58"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py_EpicSplitter._contains_block_paths_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\epic_split.py", "file_name": "epic_split.py", "file_type": "text/x-python", "category": "test", "tokens": 408, "span_ids": ["EpicSplitter._count_tokens", "EpicSplitter._contains_block_paths", "EpicSplitter._create_node"], "start_line": 464, "end_line": 518, "community": null}, "content": "class EpicSplitter(NodeParser):\n\n    def _contains_block_paths(self, codeblock: CodeBlock, block_paths: list[list[str]]):\n        return [\r\n            block_path\r\n            for block_path in block_paths\r\n            if block_path[: len(codeblock.full_path())] == codeblock.full_path()\r\n        ]\n\n    def _create_node(\r\n        self, content: str, node: BaseNode, chunk: CodeBlockChunk | None = None\r\n    ) -> TextNode | None:\n        metadata = {}\n        metadata.update(node.metadata)\n\n        node_id = node.id_\n\n        if chunk:\n            metadata[\"start_line\"] = chunk[0].start_line\n            metadata[\"end_line\"] = chunk[-1].end_line\n\n            # TODO: Change this when EpicSplitter is adjusted to use the span concept natively\r\n            span_ids = set(\r\n                [\r\n                    block.belongs_to_span.span_id\r\n                    for block in chunk\r\n                    if block.belongs_to_span\r\n                ]\r\n            )\n            metadata[\"span_ids\"] = list(span_ids)\n\n            node_id += f\"_{chunk[0].path_string()}_{chunk[-1].path_string()}\"\n\n        content = content.strip(\"\\n\")\n\n        tokens = get_tokenizer()(content)\n        metadata[\"tokens\"] = len(tokens)\n\n        excluded_embed_metadata_keys = node.excluded_embed_metadata_keys.copy()\n        excluded_embed_metadata_keys.extend([\"start_line\", \"end_line\", \"tokens\"])\n\n        return CodeNode(\r\n            id_=node_id,\r\n            text=content,\r\n            metadata=metadata,\r\n            excluded_embed_metadata_keys=excluded_embed_metadata_keys,\r\n            excluded_llm_metadata_keys=node.excluded_llm_metadata_keys,\r\n            metadata_seperator=node.metadata_seperator,\r\n            metadata_template=node.metadata_template,\r\n            text_template=node.text_template,\r\n            # relationships={NodeRelationship.SOURCE: node.as_related_node_info()},\r\n        )\n\n    def _count_tokens(self, text: str):\n        tokenizer = get_tokenizer()\n        return len(tokenizer(text))", "kind": "Chunk", "id": "index/epic_split.py#207.54"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\settings.py_json_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\settings.py", "file_name": "settings.py", "file_type": "text/x-python", "category": "test", "tokens": 390, "span_ids": ["IndexSettings.from_persist_dir", "IndexSettings", "CommentStrategy", "IndexSettings.persist", "IndexSettings.to_serializable_dict", "imports"], "start_line": 1, "end_line": 53, "community": null}, "content": "import json\nimport os\nfrom enum import Enum\n\nfrom pydantic import BaseModel, Field\n\n\nclass CommentStrategy(Enum):\n    # Keep comments\r\n    INCLUDE = \"include\"\n\n    # Always associate comments before a code block with the code block\r\n    ASSOCIATE = \"associate\"\n\n    # Exclude comments in parsed chunks\r\n    EXCLUDE = \"exclude\"\n\n\nclass IndexSettings(BaseModel):\n    embed_model: str = Field(\r\n        default=\"text-embedding-3-small\", description=\"The embedding model to use.\"\r\n    )\n    dimensions: int = Field(\r\n        default=1536, description=\"The number of dimensions of the vectors.\"\r\n    )\n\n    language: str = Field(default=\"python\", description=\"The language of the code.\")\n    min_chunk_size: int = Field(default=100, description=\"The minimum chunk size.\")\n    chunk_size: int = Field(default=750, description=\"The soft max chunk size.\")\n    hard_token_limit: int = Field(default=2000, description=\"The hard token limit.\")\n    max_chunks: int = Field(\r\n        default=200, description=\"The maximum number of chunks for one file.\"\r\n    )\n    comment_strategy: CommentStrategy = Field(\r\n        default=CommentStrategy.ASSOCIATE,\r\n        description=\"Strategy on how comments will be indexed.\",\r\n    )\n\n    def to_serializable_dict(self):\n        data = self.dict()\n        data[\"comment_strategy\"] = data[\"comment_strategy\"].value\n        return data\n\n    def persist(self, persist_dir: str):\n        with open(os.path.join(persist_dir, \"settings.json\"), \"w\") as f:\n            json.dump(self.to_serializable_dict(), f, indent=4)\n\n    @classmethod\r\n    def from_persist_dir(cls, persist_dir: str):\n        with open(os.path.join(persist_dir, \"settings.json\")) as f:\n            data = json.load(f)\n        return cls(**data)", "kind": "Chunk", "id": "index/settings.py#208.52"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py__Simple_vector_store_in_SimpleVectorStoreData.metadata_dict.field_default_factory_dic", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 291, "span_ids": ["docstring", "SimpleVectorStoreData"], "start_line": 1, "end_line": 44, "community": null}, "content": "\"\"\"Simple vector store index.\"\"\"\n\nimport json\nimport logging\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Any, cast\n\nimport faiss\nimport fsspec\nimport numpy as np\nfrom dataclasses_json import DataClassJsonMixin\nfrom fsspec.implementations.local import LocalFileSystem\nfrom llama_index.core.bridge.pydantic import PrivateAttr\nfrom llama_index.core.schema import BaseNode\nfrom llama_index.core.vector_stores.simple import _build_metadata_filter_fn\nfrom llama_index.core.vector_stores.types import (\r\n    DEFAULT_PERSIST_DIR,\r\n    BasePydanticVectorStore,\r\n    VectorStoreQuery,\r\n    VectorStoreQueryMode,\r\n    VectorStoreQueryResult,\r\n)\nfrom llama_index.core.vector_stores.utils import node_to_metadata_dict\n\nlogger = logging.getLogger(__name__)\n\nLEARNER_MODES = {\r\n    VectorStoreQueryMode.SVM,\r\n    VectorStoreQueryMode.LINEAR_REGRESSION,\r\n    VectorStoreQueryMode.LOGISTIC_REGRESSION,\r\n}\n\nMMR_MODE = VectorStoreQueryMode.MMR\n\nNAMESPACE_SEP = \"__\"\nDEFAULT_VECTOR_STORE = \"default\"\n\n\n@dataclass\r\nclass SimpleVectorStoreData(DataClassJsonMixin):\n    text_id_to_ref_doc_id: dict[str, str] = field(default_factory=dict)\n    vector_id_to_text_id: dict[int, str] = field(default_factory=dict)\n    metadata_dict: dict[str, Any] = field(default_factory=dict)", "kind": "Chunk", "id": "index/simple_faiss.py#209.43"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore_SimpleFaissVectorStore.client.return.self__faiss_index", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 439, "span_ids": ["SimpleFaissVectorStore.__init__", "SimpleFaissVectorStore.client", "SimpleFaissVectorStore", "SimpleFaissVectorStore.from_defaults"], "start_line": 47, "end_line": 102, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n    \"\"\"Simple Vector Store using Faiss as .\r\n\r\n    In this vector store, embeddings are stored within a simple, in-memory dictionary.\r\n\r\n    Args:\r\n        simple_vector_store_data_dict (Optional[dict]): data dict\r\n            containing the embeddings and doc_ids. See SimpleVectorStoreData\r\n            for more details.\r\n    \"\"\"\n\n    _data: SimpleVectorStoreData = PrivateAttr()\n    _fs: fsspec.AbstractFileSystem = PrivateAttr()\n    _faiss_index: Any = PrivateAttr()\n    _d: int = PrivateAttr()\n\n    _vector_ids_to_delete: list[int] = PrivateAttr(default_factory=list)\n    _text_ids_to_delete: set[str] = PrivateAttr(default_factory=set)\n\n    stores_text: bool = False\n\n    def __init__(\r\n        self,\r\n        faiss_index: Any,\r\n        d: int = 1536,\r\n        data: SimpleVectorStoreData | None = None,\r\n        fs: fsspec.AbstractFileSystem | None = None,\r\n        **kwargs: Any,\r\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n\n        import_err_msg = \"\"\"\r\n            `faiss` package not found. For instructions on\r\n            how to install `faiss` please visit\r\n            https://github.com/facebookresearch/faiss/wiki/Installing-Faiss\r\n        \"\"\"\n        try:\n            import faiss\n        except ImportError as e:\n            raise ImportError(import_err_msg) from e\n\n        self._d = d\n        self._faiss_index = cast(faiss.Index, faiss_index)\n        self._data = data or SimpleVectorStoreData()\n        self._fs = fs or fsspec.filesystem(\"file\")\n        super().__init__(**kwargs)\n\n    @classmethod\r\n    def from_defaults(cls, d: int = 1536):\n        faiss_index = faiss.IndexIDMap(faiss.IndexFlatL2(1536))\n        return cls(faiss_index, d)\n\n    @property\r\n    def client(self) -> Any:\n        \"\"\"Return the faiss index.\"\"\"\n        return self._faiss_index", "kind": "Chunk", "id": "index/simple_faiss.py#210.55"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore.add_SimpleFaissVectorStore.add.return._node_node_id_for_node_in", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 284, "span_ids": ["SimpleFaissVectorStore.add"], "start_line": 104, "end_line": 142, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def add(\r\n        self,\r\n        nodes: list[BaseNode],\r\n        **add_kwargs: Any,\r\n    ) -> list[str]:\n        \"\"\"Add nodes to index.\"\"\"\n\n        if not nodes:\n            return []\n\n        vector_id = (\r\n            max([int(k) for k in self._data.vector_id_to_text_id])\r\n            if self._data.vector_id_to_text_id\r\n            else 0\r\n        )\n\n        logger.info(f\"Adding {len(nodes)} nodes to index, start at id {vector_id}.\")\n\n        embeddings = []\n        ids = []\n        for node in nodes:\n            embeddings.append(node.get_embedding())\n            ids.append(int(vector_id))\n            self._data.vector_id_to_text_id[vector_id] = node.id_\n            self._data.text_id_to_ref_doc_id[node.id_] = node.ref_doc_id or node.id_\n            vector_id += 1\n\n            metadata = node_to_metadata_dict(\r\n                node, remove_text=True, flat_metadata=False\r\n            )\n            metadata.pop(\"_node_content\", None)\n            self._data.metadata_dict[node.node_id] = metadata\n\n        vectors_ndarray = np.array(embeddings)\n        ids_ndarray = np.array(ids)\n\n        self._faiss_index.add_with_ids(vectors_ndarray, ids_ndarray)\n\n        return [node.node_id for node in nodes]", "kind": "Chunk", "id": "index/simple_faiss.py#211.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore.delete_SimpleFaissVectorStore.delete.for_vector_id_text_id_in.if_text_id_in_self__text_.self__vector_ids_to_delet", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 159, "span_ids": ["SimpleFaissVectorStore.delete"], "start_line": 144, "end_line": 160, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def delete(self, ref_doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"\r\n        Delete nodes using with ref_doc_id.\r\n\r\n        Args:\r\n            ref_doc_id (str): The doc_id of the document to delete.\r\n\r\n        \"\"\"\n\n        self._text_ids_to_delete = set()\n        for text_id, ref_doc_id_ in self._data.text_id_to_ref_doc_id.items():\n            if ref_doc_id == ref_doc_id_:\n                self._text_ids_to_delete.add(text_id)\n\n        for vector_id, text_id in self._data.vector_id_to_text_id.items():\n            if text_id in self._text_ids_to_delete:\n                self._vector_ids_to_delete.append(vector_id)", "kind": "Chunk", "id": "index/simple_faiss.py#212.16"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore.query_SimpleFaissVectorStore.query.return.VectorStoreQueryResult_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 415, "span_ids": ["SimpleFaissVectorStore.query"], "start_line": 162, "end_line": 217, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def query(\r\n        self,\r\n        query: VectorStoreQuery,\r\n        **kwargs: Any,\r\n    ) -> VectorStoreQueryResult:\n        \"\"\"Query index for top k most similar nodes.\r\n\r\n        Args:\r\n            query_embedding (List[float]): query embedding\r\n            similarity_top_k (int): top k most similar nodes\r\n\r\n        \"\"\"\n        query_filter_fn = _build_metadata_filter_fn(\r\n            lambda node_id: self._data.metadata_dict[node_id], query.filters\r\n        )\n\n        query_embedding = cast(list[float], query.query_embedding)\n        query_embedding_np = np.array(query_embedding, dtype=\"float32\")[np.newaxis, :]\n        dists, indices = self._faiss_index.search(\r\n            query_embedding_np, query.similarity_top_k\r\n        )\n        dists = list(dists[0])\n        if len(indices) == 0:\n            return VectorStoreQueryResult(similarities=[], ids=[])\n\n        node_idxs = indices[0]\n\n        duplicates = 0\n        not_found = 0\n        filtered_out = 0\n\n        filtered_dists = []\n        filtered_node_ids = []\n        for dist, idx in zip(dists, node_idxs, strict=False):\n            if idx < 0:\n                break\n\n            node_id = self._data.vector_id_to_text_id.get(idx)\n            if not query_filter_fn(node_id):\n                filtered_out += 1\n            elif node_id and node_id not in filtered_node_ids:\n                filtered_node_ids.append(node_id)\n                filtered_dists.append(dist.item())\n            elif node_id in filtered_node_ids:\n                duplicates += 1\n            else:\n                not_found += 1\n\n        if not_found or duplicates:\n            logger.debug(\r\n                f\"Return {len(filtered_node_ids)} nodes ({not_found} not found, {duplicates} duplicates and {filtered_out} nodes).\"\r\n            )\n\n        return VectorStoreQueryResult(\r\n            similarities=filtered_dists, ids=filtered_node_ids\r\n        )", "kind": "Chunk", "id": "index/simple_faiss.py#213.55"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore.persist_SimpleFaissVectorStore.persist.with_fs_open_f_persist_d.json_dump_self__data_to_d", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 386, "span_ids": ["SimpleFaissVectorStore.persist"], "start_line": 219, "end_line": 258, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    def persist(\r\n        self,\r\n        persist_dir: str = DEFAULT_PERSIST_DIR,\r\n        fs: fsspec.AbstractFileSystem | None = None,\r\n    ) -> None:\n        \"\"\"Persist the SimpleVectorStore to a directory.\"\"\"\n        fs = fs or self._fs\n\n        # I don't think FAISS supports fsspec, it requires a path in the SWIG interface\r\n        # TODO: write to a temporary file and then copy to the final destination\r\n        if fs and not isinstance(fs, LocalFileSystem):\n            raise NotImplementedError(\"FAISS only supports local storage for now.\")\n        import faiss\n\n        if not os.path.exists(persist_dir):\n            os.makedirs(persist_dir)\n\n        logger.info(f\"Deleting {len(self._vector_ids_to_delete)} vectors from index.\")\n\n        if self._vector_ids_to_delete:\n            ids_to_remove_array = np.array(self._vector_ids_to_delete, dtype=np.int64)\n            removed = self._faiss_index.remove_ids(ids_to_remove_array)\n            logger.info(f\"Removed {removed} vectors from index.\")\n\n        if self._text_ids_to_delete:\n            for text_id in self._text_ids_to_delete:\n                if self._data.metadata_dict is not None:\n                    self._data.metadata_dict.pop(text_id, None)\n\n        faiss.write_index(self._faiss_index, f\"{persist_dir}/vector_index.faiss\")\n\n        for vector_id in self._vector_ids_to_delete:\n            text_id = self._data.vector_id_to_text_id.pop(vector_id, None)\n            if text_id:\n                self._data.text_id_to_ref_doc_id.pop(text_id, None)\n\n        self._vector_ids_to_delete = []\n\n        with fs.open(f\"{persist_dir}/vector_index.json\", \"w\") as f:\n            json.dump(self._data.to_dict(), f)", "kind": "Chunk", "id": "index/simple_faiss.py#214.39"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py_SimpleFaissVectorStore.from_persist_dir_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\simple_faiss.py", "file_name": "simple_faiss.py", "file_type": "text/x-python", "category": "test", "tokens": 314, "span_ids": ["SimpleFaissVectorStore.from_persist_dir", "SimpleFaissVectorStore.from_index", "SimpleFaissVectorStore.to_dict"], "start_line": 260, "end_line": 292, "community": null}, "content": "class SimpleFaissVectorStore(BasePydanticVectorStore):\n\n    @classmethod\r\n    def from_persist_dir(\r\n        cls, persist_dir: str, fs: fsspec.AbstractFileSystem | None = None\r\n    ) -> \"SimpleFaissVectorStore\":\n        \"\"\"Create a SimpleKVStore from a persist directory.\"\"\"\n\n        fs = fs or fsspec.filesystem(\"file\")\n        if not fs.exists(persist_dir):\n            raise ValueError(f\"No existing index store found at {persist_dir}.\")\n\n        # I don't think FAISS supports fsspec, it requires a path in the SWIG interface\r\n        # TODO: copy to a temp file and load into memory from there\r\n        if fs and not isinstance(fs, LocalFileSystem):\n            raise NotImplementedError(\"FAISS only supports local storage for now.\")\n\n        faiss_index = faiss.read_index(f\"{persist_dir}/vector_index.faiss\")\n\n        logger.debug(f\"Loading {__name__} from {persist_dir}.\")\n        with fs.open(f\"{persist_dir}/vector_index.json\", \"rb\") as f:\n            data_dict = json.load(f)\n            data = SimpleVectorStoreData.from_dict(data_dict)\n\n        logger.info(f\"Loading {__name__} from {persist_dir}.\")\n\n        return cls(faiss_index=faiss_index, data=data)\n\n    @classmethod\r\n    def from_index(cls, faiss_index: Any):\n        return cls(faiss_index)\n\n    def to_dict(self) -> dict:\n        return self._data.to_dict()", "kind": "Chunk", "id": "index/simple_faiss.py#215.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\types.py_from_dataclasses_import_d_SpanHit.tokens.Field_default_0_descript", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\types.py", "file_name": "types.py", "file_type": "text/x-python", "category": "test", "tokens": 201, "span_ids": ["imports", "CodeSnippet", "SpanHit"], "start_line": 1, "end_line": 28, "community": null}, "content": "from dataclasses import dataclass\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\n@dataclass\r\nclass CodeSnippet:\n    id: str\n    file_path: str\n    content: str = None\n    distance: float = 0.0\n    tokens: int = None\n    language: str = \"python\"\n    span_ids: list[str] = None\n    start_line: Optional[int] = None\n    end_line: Optional[int] = None\n    start_block: Optional[str] = None\n    end_block: Optional[str] = None\n\n\nclass SpanHit(BaseModel):\n    span_id: str = Field(description=\"The span id of the relevant code in the file\")\n    rank: int = Field(\r\n        default=0,\r\n        description=\"The rank of relevance of the span in the file. 0 is highest.\",\r\n    )\n    tokens: int = Field(default=0, description=\"The number of tokens in the span.\")", "kind": "Chunk", "id": "index/types.py#216.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\types.py_SearchCodeHit_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\index\\types.py", "file_name": "types.py", "file_type": "text/x-python", "category": "test", "tokens": 272, "span_ids": ["SearchCodeHit.span_ids", "SearchCodeHit.add_spans", "SearchCodeResponse", "SearchCodeHit.add_span", "SearchCodeHit", "SearchCodeHit.contains_span"], "start_line": 31, "end_line": 65, "community": null}, "content": "class SearchCodeHit(BaseModel):\n    file_path: str = Field(\r\n        description=\"The file path where the relevant code is found.\"\r\n    )\n    spans: list[SpanHit] = Field(\r\n        default_factory=list,\r\n        description=\"The spans of the relevant code in the file\",\r\n    )\n\n    @property\r\n    def span_ids(self):\n        return [span.span_id for span in self.spans]\n\n    def add_span(self, span_id: str, rank: int = 0, tokens: int = 0):\n        if span_id not in [span.span_id for span in self.spans]:\n            self.spans.append(SpanHit(span_id=span_id, rank=rank, tokens=tokens))\n\n    def contains_span(self, span_id: str) -> bool:\n        return span_id in [span.span_id for span in self.spans]\n\n    def add_spans(self, span_ids: list[str], rank: int = 0):\n        for span_id in span_ids:\n            self.add_span(span_id, rank)\n\n\nclass SearchCodeResponse(BaseModel):\n    message: Optional[str] = Field(\r\n        default=None, description=\"A message to return to the user.\"\r\n    )\n\n    hits: list[SearchCodeHit] = Field(\r\n        default_factory=list,\r\n        description=\"Search results.\",\r\n    )", "kind": "Chunk", "id": "index/types.py#217.34"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_json_logger.logging_getLogger_Loop_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 218, "span_ids": ["imports"], "start_line": 1, "end_line": 42, "community": null}, "content": "import json\nimport logging\nimport os\nimport random\nimport string\nimport sys\nimport traceback\nfrom collections.abc import Callable\nfrom datetime import datetime\nfrom typing import Any, Optional, Type, Tuple\nimport subprocess\n\nimport instructor\nimport litellm\nfrom anthropic import Anthropic\nfrom litellm import completion_cost, cost_per_token, token_counter\nfrom pydantic import BaseModel, Field, PrivateAttr, ConfigDict\n\nfrom moatless.repository import GitRepository\nfrom moatless.state import (\r\n    AgenticState,\r\n    Finished,\r\n    NoopState,\r\n    Pending,\r\n    Rejected,\r\n    get_state_class,\r\n)\nfrom moatless.trajectory import Trajectory\nfrom moatless.transition_rules import TransitionRule, TransitionRules\nfrom moatless.types import (\r\n    ActionRequest,\r\n    AssistantMessage,\r\n    Content,\r\n    Message,\r\n    Response,\r\n    Usage,\r\n    UserMessage,\r\n)\nfrom moatless.utils.llm_utils import instructor_mode_by_model\nfrom moatless.workspace import Workspace\n\nlogger = logging.getLogger(\"Loop\")", "kind": "Chunk", "id": "moatless/loop.py#218.41"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop_AgenticLoop.persist.self_trajectory_persist_t", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 817, "span_ids": ["AgenticLoop.__init__", "AgenticLoop", "AgenticLoop.persist", "AgenticLoop.from_trajectory_file"], "start_line": 45, "end_line": 157, "community": null}, "content": "class AgenticLoop:\n    def __init__(\r\n        self,\r\n        transition_rules: TransitionRules,\r\n        workspace: Workspace,\r\n        input_data: dict[str, Any] | None = None,\r\n        initial_message: str | None = None,\r\n        trajectory: Trajectory | None = None,\r\n        mocked_actions: list[dict] | None = None,\r\n        expected_states: list[Type[AgenticState]] | None = None,\r\n        reset_mocks_at_state: Optional[str] = None,\r\n        verify_state_func: Optional[Callable] = None,\r\n        max_cost: float = 0.25,\r\n        max_actions: int = 2,\r\n        max_transitions: int = 25,\r\n        max_message_tokens: Optional[int] = None,\r\n        max_retries: int = 2,\r\n        max_rejections: int = 2,\r\n        instructor_mode: instructor.Mode | None = None,\r\n        metadata: dict[str, Any] | None = None,\r\n        trajectory_path: Optional[str] = None,\r\n        prompt_log_dir: Optional[str] = None,\r\n        **kwargs,\r\n    ):\n        \"\"\"\r\n        Initialize the Loop instance.\r\n\r\n        Args:\r\n\r\n        \"\"\"\n\n        self._workspace = workspace\n\n        self._input_data = input_data\n\n        if trajectory_path:\n            parent_dir = os.path.dirname(trajectory_path)\n            if not os.path.exists(parent_dir):\n                os.makedirs(parent_dir)\n        self._trajectory_path = trajectory_path\n\n        if not trajectory:\n            self._trajectory = Trajectory(\r\n                \"MoatlessTools\",\r\n                initial_message=initial_message,\r\n                persist_path=self._trajectory_path,\r\n                workspace=self._workspace,\r\n                transition_rules=transition_rules,\r\n            )\n            pending_state = Pending()\n            self._trajectory.save_state(pending_state)\n            self._set_current_state(pending_state)\n        else:\n            self._trajectory = trajectory\n            self._current_state = trajectory.get_current_state()\n\n        self._initial_message = initial_message\n\n        if prompt_log_dir and not os.path.exists(prompt_log_dir):\n            os.makedirs(prompt_log_dir)\n        self._prompt_log_dir = prompt_log_dir\n\n        if expected_states and not verify_state_func:\n\n            def verify_state_func(state: AgenticState):\n                nonlocal expected_states\n                if not expected_states:\n                    raise ValueError(\r\n                        f\"No more expected states, but got {state.__class__}\"\r\n                    )\n                expected_state = expected_states.pop(0)\n                if isinstance(expected_state, str):\n                    if state.name != expected_state:\n                        raise ValueError(\r\n                            f\"Expected state {expected_state} but got {state.__class__.__name__}\"\r\n                        )\n                elif isinstance(expected_state, AgenticState) and not isinstance(state, expected_state):\n                    raise ValueError(\r\n                        f\"Expected state {expected_state} but got {state.__class__.__name__}\"\r\n                    )\n\n                self.log_info(f\"Verified expected next state {expected_state}\")\n\n        self._verify_state_func = verify_state_func\n        self._mocked_actions = mocked_actions\n        self._reset_mocks_at_state = reset_mocks_at_state\n\n        self._max_cost = max_cost\n        self._max_message_tokens = max_message_tokens\n        self._max_transitions = max_transitions\n        self._max_actions = max_actions\n        self._max_retries = max_retries\n        self._max_rejections = max_rejections\n        self._instructor_mode = instructor_mode\n\n        self._transition_count = 0\n        self._rejections = 0\n\n        self._transition_rules = transition_rules\n        self._metadata = metadata\n\n    @classmethod\r\n    def from_trajectory_file(cls, trajectory_path: str, **kwargs):\n        trajectory = Trajectory.load(trajectory_path)\n        return cls(\r\n            transition_rules=trajectory.transitions,\r\n            trajectory=trajectory,\r\n            workspace=trajectory.workspace,\r\n            **kwargs,\r\n        )\n\n    def persist(self, trajectory_path: str):\n        self.trajectory.persist(trajectory_path)", "kind": "Chunk", "id": "moatless/loop.py#219.112"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop.run_AgenticLoop.run.raise_RuntimeError_f_Loop", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 383, "span_ids": ["AgenticLoop.run"], "start_line": 159, "end_line": 204, "community": null}, "content": "class AgenticLoop:\n\n    def run(self, message: Optional[str] = None) -> Response:\n        \"\"\"\r\n        Executes the entire loop until completion or termination.\r\n\r\n        This method initializes the loop if it hasn't started, and then repeatedly\r\n        calls run_until_transition() until the loop is finished. It handles the\r\n        overall flow of the loop, including initialization and final state processing.\r\n\r\n        Args:\r\n            message (Optional[str]): An optional initial message to start the loop with.\r\n\r\n        Returns:\r\n            Response: An object containing the final status and message of the loop.\r\n                The status will be either \"finished\" or \"rejected\".\r\n\r\n        Raises:\r\n            RuntimeError: If an unexpected state or condition occurs during execution.\r\n                This includes cases where the loop is already running, exits with an \r\n                unknown state, or encounters other unexpected runtime conditions.\r\n\r\n        Note:\r\n            This method will continue running until a Finished or Rejected state is reached,\r\n            or until an exception occurs. It's designed to be the main entry point for\r\n            executing the entire loop process.\r\n        \"\"\"\n        if self.is_running():\n            raise RuntimeError(\"Loop is already running.\")\n\n        # TODO: Move to always set this when the Loop is created instead\r\n        if message:\n            logger.warning(\"Setting initial message in run is deprecated. Set in contructor.\")\n            self._initial_message = message\n            self._trajectory._initial_message = message\n\n        if not isinstance(self._current_state, Pending):\n            self._trajectory.update_workspace_to_current_state()\n\n        while not self.is_finished():\n            self._execute_state_until_transition()\n\n        if isinstance(self.state, Finished):\n            return Response(status=\"finished\", message=self.state.message or \"\")\n        elif isinstance(self.state, Rejected):\n            return Response(status=\"rejected\", message=self.state.message or \"\")\n\n        raise RuntimeError(f\"Loop exited with unknown state {self.state.name}.\")", "kind": "Chunk", "id": "moatless/loop.py#220.45"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop._execute_state_until_transition_AgenticLoop._execute_state_until_transition.raise_RuntimeError_Loop_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 353, "span_ids": ["AgenticLoop._execute_state_until_transition"], "start_line": 206, "end_line": 244, "community": null}, "content": "class AgenticLoop:\n\n    def _execute_state_until_transition(self) -> AgenticState | None:\n        \"\"\"\r\n        Executes the state until a transition to a new state occurs.\r\n\r\n        This method executes the state, processing actions and handling\r\n        state changes until one of the following conditions is met:\r\n        1. A transition to a new state occurs\r\n        2. Maximum cost, retries, or transitions are exceeded\r\n\r\n        Returns:\r\n            AgenticState: The new state after a transition occurs\r\n\r\n        Raises:\r\n            RuntimeError: If the loop exits without a transition or if the maximum cost is exceeded\r\n            ValueError: If the maximum number of retries is reached\r\n        \"\"\"\n        while not self.state.executed:\n            total_cost = self.total_cost()\n            if total_cost > self._max_cost:\n                self.log_info(f\"Max cost reached ({total_cost} > {self._max_cost}). Exiting.\")\n                self.trajectory.save_info({\"error\": \"Max cost reached.\"})\n                raise RuntimeError(\"The loop was aborted because the cost exceeded the limit.\")\n\n            self.log_info(f\"Running transition {len(self._trajectory.states)}. Current total cost: {total_cost}\")\n\n            try:\n                state = self._execute_state()\n                if state:\n                    return state\n            except Exception as e:\n                self.log_info(f\"Failed to run loop. Error: {e}\")\n                raise\n\n            if self.state.retries() > self._max_retries:\n                self.log_info(f\"Max retries reached ({self._max_retries}). Exiting.\")\n                self.trajectory.save_info({\"error\": \"Max retries reached.\"})\n                return self.transition_to(Rejected(message=\"Max retries reached.\"))\n\n        raise RuntimeError(\"Loop exited without a transition.\")", "kind": "Chunk", "id": "moatless/loop.py#221.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop._execute_state_AgenticLoop._execute_state.return.self_transition_to_next_s", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 351, "span_ids": ["AgenticLoop._execute_state"], "start_line": 246, "end_line": 299, "community": null}, "content": "class AgenticLoop:\n\n    def _execute_state(self) -> AgenticState | None:\n        \"\"\"\r\n        Execute one iteration of the current state and handle potential transitions.\r\n\r\n        Processes the next action, updates the trajectory, and determines if a state\r\n        transition should occur based on the action's response.\r\n\r\n        Returns:\r\n            AgenticState | None: The next state if transitioning, or None if remaining in the current state.\r\n\r\n        Raises:\r\n            ValueError: \r\n        \"\"\"\n        if self.state.executed:\n            raise ValueError(\"Tried to execute already executed state.\")\n\n        if isinstance(self.state, Pending):\n            logger.info(\"Initializing first state.\")\n            trigger = \"init\"\n            output = {}\n\n        else:\n            action, usage = self._next_action()\n\n            self.log_info(f\"Received new action {action.action_name}.\")\n            response = self.state.handle_action(action, usage)\n\n            if not response.trigger:\n                self.log_info(\r\n                    f\"{self.state.name}: No trigger in action response. Staying in the same state.\"\r\n                )\n                return None\n\n            self.log_info(f\"Received response with trigger {response.trigger}\")\n\n            if response.trigger == \"retry\":\n                self.log_info(f\"Retry requested. {response.retry_message}\")\n                return None\n\n            trigger = response.trigger\n            output = response.output\n\n        transition_rule = self._transition_rules.get_next_rule(\r\n            self.state,\r\n            trigger,\r\n            output,\r\n        )\n        if not transition_rule:\n            raise RuntimeError(\r\n                f\"No transition rule found for {self.state.name} with trigger {response.trigger} and output {response.output}\"\r\n            )\n\n        next_state = self._create_state(transition_rule, output)\n        return self.transition_to(next_state)", "kind": "Chunk", "id": "moatless/loop.py#222.53"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop._create_state_AgenticLoop._create_state.return.next_state", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 364, "span_ids": ["AgenticLoop._create_state"], "start_line": 301, "end_line": 341, "community": null}, "content": "class AgenticLoop:\n\n    def _create_state(self, transition_rule: TransitionRule, output: dict) -> AgenticState:\n        params = {}\n        params.update(self._transition_rules.params(transition_rule))\n\n        for k, v in output.items():\n            if transition_rule.excluded_fields and k in transition_rule.excluded_fields:\n                continue\n\n            params[k] = v\n\n        params[\"id\"] = self.state_count()\n\n        next_state_type = transition_rule.dest\n        if next_state_type not in [Finished, Rejected]:\n\n            if self.state_count() >= self._max_transitions:\n                self.log_info(f\"Max transitions exceeded ({self._max_transitions}). Transitioning to Rejected.\")\n                next_state_type = Rejected\n                params[\"message\"] = \"Max transitions exceeded.\"\n            if (\r\n                params.get(\"max_iterations\")\r\n                and self.state_count(next_state_type) >= params[\"max_iterations\"]\r\n            ):\n                self.log_info(f\"Max iterations exceeded ({params['max_iterations']}). Transitioning to Rejected.\")\n                next_state_type = Rejected\n                params[\"message\"] = f\"Max iterations exceeded ({params['max_iterations']}).\"\n\n        self.log_info(f\"Creating state {next_state_type.__name__} with params {params}\")\n\n        try:\n            next_state = next_state_type.model_validate(params)\n            next_state.previous_state = self._current_state\n            next_state._workspace = self._workspace\n            next_state._initial_message = self._initial_message\n        except Exception as e:\n            logger.error(f\"Failed to create state {next_state_type.__name__} with params {params}\")\n            raise e\n\n        self._trajectory.save_state(next_state)\n        self._current_state.next_states.append(next_state)\n        return next_state", "kind": "Chunk", "id": "moatless/loop.py#223.40"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop.total_cost_AgenticLoop.transition_to.return.new_state", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 173, "span_ids": ["AgenticLoop.total_cost", "AgenticLoop.transition_to", "AgenticLoop.is_running", "AgenticLoop._set_current_state", "AgenticLoop.is_finished"], "start_line": 343, "end_line": 365, "community": null}, "content": "class AgenticLoop:\n\n    def total_cost(self):\n        total_cost = 0\n        for state in self._trajectory.transitions:\n            total_cost += state.state.total_cost()\n        return total_cost\n\n    def is_running(self) -> bool:\n        return not isinstance(self.state, NoopState)\n\n    def is_finished(self) -> bool:\n        return isinstance(self.state, (Finished, Rejected))\n\n    def _set_current_state(self, state: AgenticState):\n        self._current_state = state\n        self._trajectory.set_current_state(state)\n\n    def transition_to(self, new_state: AgenticState) -> AgenticState:\n        self.log_info(f\"Transitioning from {self.state.name} to {new_state.name}\")\n\n        self._trajectory.save_state(new_state)\n        self._set_current_state(new_state)\n\n        return new_state", "kind": "Chunk", "id": "moatless/loop.py#224.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop._next_action_AgenticLoop._next_action.return.action_request_usage", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 819, "span_ids": ["AgenticLoop._next_action"], "start_line": 367, "end_line": 492, "community": null}, "content": "class AgenticLoop:\n\n    def _next_action(\r\n        self,\r\n    ) -> Tuple[ActionRequest, Usage | None]:\n        messages = self._to_completion_messages()\n        self.log_info(f\"Create completion with {len(messages)} messages\")\n\n        if self._verify_state_func:\n            self._verify_state_func(self.state)\n\n        mocked_action = self._next_mock_action()\n        if mocked_action:\n            return mocked_action, None\n\n        metadata = {}\n        if self._metadata:\n            metadata.update(self._metadata)\n        metadata[\"generation_name\"] = self.state.name\n\n        tokens = token_counter(messages=messages[-1:])\n        if self._max_message_tokens and tokens > self._max_message_tokens:\n            raise ValueError(f\"Too many tokens in the new message: {tokens}\")\n\n        self.log_info(f\"Do completion request to {self.state.model}\")\n\n        if self.state.model.startswith(\"claude\") and self.state.action_type():\n            try:\n                anthropic_client = instructor.from_anthropic(\r\n                    Anthropic(),\r\n                    mode=self.instructor_mode,\r\n                )\n\n                action_request, completion_response = (\r\n                    anthropic_client.chat.completions.create_with_completion(\r\n                        model=self.state.model,\r\n                        max_tokens=self.state.max_tokens,\r\n                        temperature=self.state.temperature,\r\n                        # stop=self.state.stop_words(),\r\n                        response_model=self.state.action_type(),\r\n                        messages=messages,\r\n                    )\r\n                )\n\n                self.log_info(\r\n                    f\"Input tokens: {completion_response.usage.input_tokens}, Output tokens: {completion_response.usage.output_tokens}\"\r\n                )\n                (\r\n                    prompt_tokens_cost_usd_dollar,\r\n                    completion_tokens_cost_usd_dollar,\r\n                ) = cost_per_token(\r\n                    model=self.state.model,\r\n                    prompt_tokens=completion_response.usage.input_tokens,\r\n                    completion_tokens=completion_response.usage.output_tokens,\r\n                )\n                _final_cost = (\r\n                    prompt_tokens_cost_usd_dollar + completion_tokens_cost_usd_dollar\r\n                )\n            except Exception as e:\n                self._log_prompt(messages, error=traceback.format_exc())\n                raise e\n\n\n            self._log_prompt(messages, completion_response.content)\n\n            usage = Usage(\r\n                completion_cost=_final_cost,\r\n                completion_tokens=completion_response.usage.output_tokens,\r\n                prompt_tokens=completion_response.usage.input_tokens,\r\n            )\n\n            return action_request, usage\n\n        if self.state.action_type() is None:\n            completion_response = litellm.completion(\r\n                model=self.state.model,\r\n                max_tokens=self.state.max_tokens,\r\n                temperature=self.state.temperature,\r\n                stop=self.state.stop_words(),\r\n                metadata=metadata,\r\n                messages=messages,\r\n            )\n            action_request = Content(\r\n                content=completion_response.choices[0].message.content\r\n            )\n        else:\n            client = instructor.from_litellm(\r\n                litellm.completion, mode=self.instructor_mode\r\n            )\n\n            try:\n                action_request, completion_response = (\r\n                    client.chat.completions.create_with_completion(\r\n                        model=self.state.model,\r\n                        max_tokens=self.state.max_tokens,\r\n                        temperature=self.state.temperature,\r\n                        stop=self.state.stop_words(),\r\n                        response_model=self.state.action_type(),\r\n                        metadata=metadata,\r\n                        messages=messages,\r\n                    )\r\n                )\n            except Exception as e:\n                self._log_prompt(messages, error=traceback.format_exc())\n                raise e\n\n        try:\n            cost = completion_cost(\r\n                completion_response=completion_response,\r\n                model=self.state.model,\r\n            )\n        except Exception as e:\n            self.log_info(f\"Error calculating completion cost: {e}\")\n            cost = 0\n\n        self._log_prompt(\r\n            messages, [completion_response.choices[0].message.model_dump()], error=None\r\n        )\n        prompt_tokens = completion_response.get(\"usage\", {}).get(\"prompt_tokens\", 0)\n        completion_tokens = completion_response.get(\"usage\", {}).get(\r\n            \"completion_tokens\", 0\r\n        )\n        usage = Usage(\r\n            completion_cost=cost,\r\n            completion_tokens=completion_tokens,\r\n            prompt_tokens=prompt_tokens,\r\n        )\n        return action_request, usage", "kind": "Chunk", "id": "moatless/loop.py#225.125"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop.state_count_AgenticLoop._to_completion_messages.return.messages", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 603, "span_ids": ["AgenticLoop.state", "AgenticLoop._to_completion_messages", "AgenticLoop.workspace", "AgenticLoop.trajectory", "AgenticLoop.state_count"], "start_line": 494, "end_line": 599, "community": null}, "content": "class AgenticLoop:\n\n    def state_count(self, state: AgenticState | None = None) -> int:\n        if not state:\n            return len(self._trajectory.transitions)\n\n        return len(\r\n            [s for s in self._trajectory.transitions if s.state.name == state.name]\r\n        )\n\n    @property\r\n    def state(self):\n        return self._current_state\n\n    @property\r\n    def workspace(self) -> Workspace:\n        return self._workspace\n\n    @property\r\n    def trajectory(self):\n        return self._trajectory\n\n    def _to_completion_messages(self) -> list[dict]:\n        messages = [{\"role\": \"system\", \"content\": self.state.system_prompt()}]\n\n        tool_call_id = None\n        state_messages = self.state.messages()\n        for message in state_messages:\n            if message.role == \"user\":\n                if tool_call_id and self.instructor_mode == instructor.Mode.TOOLS:\n                    messages.append(\r\n                        {\r\n                            \"role\": \"tool\",\r\n                            \"tool_call_id\": tool_call_id,\r\n                            \"content\": message.content,\r\n                        }\r\n                    )\n                elif (\r\n                    tool_call_id\r\n                    and self.instructor_mode == instructor.Mode.ANTHROPIC_TOOLS\r\n                ):\n                    messages.append(\r\n                        {\r\n                            \"role\": \"user\",\r\n                            \"content\": [\r\n                                {\r\n                                    \"tool_use_id\": tool_call_id,\r\n                                    \"content\": message.content,\r\n                                    \"type\": \"tool_result\",\r\n                                }\r\n                            ],\r\n                        }\r\n                    )\n                else:\n                    messages.append({\"role\": \"user\", \"content\": message.content})\n            elif message.role == \"assistant\":\n                if message.action:\n                    tool_call_id = generate_call_id()\n                    if self.instructor_mode == instructor.Mode.ANTHROPIC_TOOLS:\n                        messages.append(\r\n                            {\r\n                                \"role\": \"assistant\",\r\n                                \"content\": [\r\n                                    {\r\n                                        \"id\": tool_call_id,\r\n                                        \"input\": message.action.model_dump(),\r\n                                        \"type\": \"tool_use\",\r\n                                        \"name\": message.action.action_name,\r\n                                    }\r\n                                ],\r\n                            }\r\n                        )\n                    elif self.instructor_mode == instructor.Mode.TOOLS:\n                        messages.append(\r\n                            {\r\n                                \"role\": \"assistant\",\r\n                                \"tool_calls\": [\r\n                                    {\r\n                                        \"id\": tool_call_id,\r\n                                        \"type\": \"function\",\r\n                                        \"function\": {\r\n                                            \"name\": message.action.action_name,\r\n                                            \"arguments\": message.action.model_dump_json(\r\n                                                exclude_none=True\r\n                                            ),\r\n                                        },\r\n                                    }\r\n                                ],\r\n                            }\r\n                        )\n                    else:\n                        json_content = message.action.model_dump_json(indent=2)\n\n                        if self.state.model.startswith(\"deepseek\"):\n                            json_content = f\"```json\\n{json_content}\\n```\"\n\n                        messages.append(\r\n                            {\r\n                                \"role\": \"assistant\",\r\n                                \"content\": json_content,\r\n                            }\r\n                        )\n\n                else:\n                    tool_call_id = None\n                    messages.append({\"role\": \"assistant\", \"content\": message.content})\n\n        return messages", "kind": "Chunk", "id": "moatless/loop.py#226.105"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop.instructor_mode_AgenticLoop._next_mock_action.if_self_state_action_type.else_.raise_ValueError_f_Mocked", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 294, "span_ids": ["AgenticLoop.instructor_mode", "AgenticLoop._next_mock_action"], "start_line": 601, "end_line": 638, "community": null}, "content": "class AgenticLoop:\n\n    @property\r\n    def instructor_mode(self):\n        if self._instructor_mode:\n            return self._instructor_mode\n\n        return instructor_mode_by_model(self.state.model)\n\n    def _next_mock_action(\r\n        self,\r\n    ) -> ActionRequest | None:\n        if not self._mocked_actions:\n            return None\n\n        if self._reset_mocks_at_state and self.state.name == self._reset_mocks_at_state:\n            self.log_info(f\"Resetting mocked actions at state {self.state.name}\")\n            self._mocked_actions = []\n            return None\n\n        action = self._mocked_actions.pop(0)\n\n        if self.state.action_type():\n            try:\n                self.log_info(\r\n                    f\"Return mocked response with type {self.state.action_type().__name__} ({len(self._mocked_actions)} left).\"\r\n                )\n                return self.state.action_type().model_validate(action)\n\n            except Exception:\n                logger.error(\r\n                    f\"{self.transition_name}: Failed to parse {action} to {self.state.action_type().__name__} in state {self.state.name}\"\r\n                )\n                raise\n        elif \"content\" in action:\n            self.log_info(f\"Return mocked response ({len(self._mocked_actions)} left).\")\n            return Content(content=action[\"content\"])\n\n        else:\n            raise ValueError(f\"Mocked action {action} does not have 'content' field.\")", "kind": "Chunk", "id": "moatless/loop.py#227.37"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py_AgenticLoop._log_prompt_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\loop.py", "file_name": "loop.py", "file_type": "text/x-python", "category": "test", "tokens": 658, "span_ids": ["generate_call_id", "AgenticLoop.transition_name", "AgenticLoop.log_info", "AgenticLoop._log_prompt"], "start_line": 641, "end_line": 730, "community": null}, "content": "class AgenticLoop:\n\n\n    def _log_prompt(\r\n        self,\r\n        messages: list[dict],\r\n        completion: Any | None = None,\r\n        error: Optional[str] = None,\r\n    ):\n        if not self._prompt_log_dir:\n            return\n\n        time_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n        prompt_path = (\r\n            f\"{self._prompt_log_dir}/{self._current_state.id}_{self._current_state.name}\"\r\n        )\n        if self.state.retries() > 0:\n            prompt_path += f\"_retry_{self.state.retries()}\"\n\n        prompt_path += f\"_{time_str}.md\"\n\n        with open(prompt_path, \"w\") as f:\n            f.write(\"\\n\\n# Completion\\n\")\n\n            f.write(\"\\n\\n## Input\\n\")\n            for message in messages:\n                f.write(f\"\\n\\n### {message['role']}\\n\\n\")\n\n                if \"content\" in message:\n                    if isinstance(message[\"content\"], str):\n                        f.write(message[\"content\"])\n                    elif isinstance(message[\"content\"], list):\n                        for content in message[\"content\"]:\n                            if isinstance(content, str):\n                                f.write(content)\n                            if isinstance(content, dict) and \"content\" in content:\n                                f.write(content[\"content\"])\n                            else:\n                                f.write(\r\n                                    f\"\\n\\n```json\\n{json.dumps(content, indent=2)}\\n```\"\r\n                                )\n                elif isinstance(message.get(\"content\"), list):\n                    for block in message[\"content\"]:\n                        f.write(f\"\\n\\n### {block['tool_use_id']}\\n\")\n                        f.write(block[\"content\"])\n                else:\n                    f.write(f\"\\n\\n```json\\n{json.dumps(message, indent=2)}\\n```\")\n\n            if completion:\n                f.write(\"\\n\\n## Output\\n\")\n\n                if isinstance(completion, list):\n                    for block in completion:\n                        if isinstance(block, BaseModel):\n                            block = block.model_dump()\n\n                        if isinstance(block, dict):\n                            if block.get(\"content\"):\n                                f.write(f\"{block.get('content')}\\n\")\n                            else:\n                                f.write(f\"```json\\n{json.dumps(block, indent=2)}\\n```\")\n                        else:\n                            f.write(f\"```json\\n{json.dumps(block, indent=2)}\\n```\")\n                else:\n                    f.write(f\"```json\\n{json.dumps(completion, indent=2)}\\n```\")\n\n            if error:\n                f.write(\"\\n\\n# Error\\n\")\n                f.write(f\"\\n```\\n{error}\\n```\\n\")\n\n    def log_info(self, message: str):\n        logger.info(f\"{self.transition_name}: {message}\")\n\n    @property\r\n    def transition_name(self):\n        if self._current_state:\n            return f\"{self._current_state.name}:{self._current_state.id}\"\n        else:\n            return \"No state\"\n\n\ndef generate_call_id():\n    prefix = \"call_\"\n    chars = string.ascii_letters + string.digits\n    length = 24\n\n    random_chars = \"\".join(random.choices(chars, k=length))\n\n    random_string = prefix + random_chars\n\n    return random_string", "kind": "Chunk", "id": "moatless/loop.py#228.89"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\__init__.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "category": "test", "tokens": 25, "span_ids": ["imports"], "start_line": 1, "end_line": 3, "community": null}, "content": "from moatless.repository.file import CodeFile, FileRepository, UpdateResult\nfrom moatless.repository.git import GitRepository", "kind": "Chunk", "id": "repository/__init__.py#229.2"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_difflib_UpdateResult.new_span_ids.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 144, "span_ids": ["imports", "UpdateResult"], "start_line": 1, "end_line": 24, "community": null}, "content": "import difflib\nimport glob\nimport logging\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ConfigDict\n\nfrom moatless.codeblocks import get_parser_by_path\nfrom moatless.codeblocks.codeblocks import CodeBlockType, CodeBlockTypeGroup\nfrom moatless.codeblocks.module import Module\nfrom moatless.codeblocks.parser.python import PythonParser\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\r\nclass UpdateResult:\n    file_path: str\n    updated: bool\n    diff: Optional[str] = None\n    error: Optional[str] = None\n    new_span_ids: set[str] | None = None", "kind": "Chunk", "id": "repository/file.py#230.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_CodeFile_CodeFile.supports_codeblocks.return.self_module_is_not_None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 200, "span_ids": ["CodeFile", "CodeFile.from_file", "CodeFile.supports_codeblocks", "CodeFile.from_content"], "start_line": 27, "end_line": 54, "community": null}, "content": "class CodeFile(BaseModel):\n    file_path: str\n    content: str\n    module: Module | None = None\n    dirty: bool = False\n\n    model_config = ConfigDict(exclude={\"module\", \"dirty\"})\n\n    @classmethod\r\n    def from_file(cls, repo_path: str, file_path: str):\n        with open(os.path.join(repo_path, file_path)) as f:\n            parser = get_parser_by_path(file_path)\n            if parser:\n                content = f.read()\n                module = parser.parse(content)\n            else:\n                module = None\n            return cls(file_path=file_path, content=content, module=module)\n\n    @classmethod\r\n    def from_content(cls, file_path: str, content: str):\n        parser = PythonParser()\n        module = parser.parse(content)\n        return cls(file_path=file_path, content=content, module=module)\n\n    @property\r\n    def supports_codeblocks(self):\n        return self.module is not None", "kind": "Chunk", "id": "repository/file.py#231.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_CodeFile.update_content_by_line_numbers_CodeFile.update_content_by_line_numbers.return.self_update_content_updat", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 230, "span_ids": ["CodeFile.update_content_by_line_numbers"], "start_line": 56, "end_line": 84, "community": null}, "content": "class CodeFile(BaseModel):\n\n    def update_content_by_line_numbers(\r\n        self, start_line_index: int, end_line_index: int, replacement_content: str\r\n    ) -> UpdateResult:\n        replacement_lines = replacement_content.split(\"\\n\")\n\n        # Strip empty lines from the start and end\r\n        while replacement_lines and replacement_lines[0].strip() == \"\":\n            replacement_lines.pop(0)\n\n        while replacement_lines and replacement_lines[-1].strip() == \"\":\n            replacement_lines.pop()\n\n        original_lines = self.content.split(\"\\n\")\n\n        replacement_lines = remove_duplicate_lines(\r\n            replacement_lines, original_lines[end_line_index:]\r\n        )\n\n        updated_lines = (\r\n            original_lines[:start_line_index]\r\n            + replacement_lines\r\n            + original_lines[end_line_index:]\r\n        )\n        updated_content = \"\\n\".join(updated_lines)\n        logger.info(\r\n            f\"Updating content for {self.file_path} from line {start_line_index} to {end_line_index} with {len(replacement_lines)} lines. The updated file has {len(updated_lines)} lines.\"\r\n        )\n\n        return self.update_content(updated_content)", "kind": "Chunk", "id": "repository/file.py#232.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_CodeFile.update_content_CodeFile.update_content.return.UpdateResult_file_path_se", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 656, "span_ids": ["CodeFile.update_content"], "start_line": 86, "end_line": 171, "community": null}, "content": "class CodeFile(BaseModel):\n\n    def update_content(self, updated_content: str) -> UpdateResult:\n        diff = do_diff(self.file_path, self.content, updated_content)\n        if diff:\n            parser = get_parser_by_path(self.file_path)\n            if parser:\n                module = parser.parse(updated_content)\n                if not module.children:\n                    return UpdateResult(\r\n                        file_path=self.file_path,\r\n                        updated=False,\r\n                        diff=diff,\r\n                        error=\"The updated code is invalid.\",\r\n                    )\n\n                # TODO: Move the prompt instructions to the loop\r\n                error_blocks = module.find_errors()\n                validation_errors = module.find_validation_errors()\n                existing_placeholders = self.module.find_blocks_with_type(\r\n                    CodeBlockType.COMMENTED_OUT_CODE\r\n                )\n                new_placeholders = (\r\n                    module.find_blocks_with_type(CodeBlockType.COMMENTED_OUT_CODE)\r\n                    if not existing_placeholders\r\n                    else []\r\n                )\n                if error_blocks or validation_errors or new_placeholders:\n                    error_response = \"\"\n                    if error_blocks:\n                        for error_block in error_blocks:\n                            parent_block = error_block.find_type_group_in_parents(\r\n                                CodeBlockTypeGroup.STRUCTURE\r\n                            )\n                            if (\r\n                                parent_block\r\n                                and parent_block.type != CodeBlockType.MODULE\r\n                            ):\n                                error_response += f\"{parent_block.type.name} has invalid code:\\n\\n```{parent_block.to_string()}\\n```.\\n\"\n                            else:\n                                error_response += f\"This code is invalid: \\n```{error_block.to_string()}\\n```.\\n\"\n\n                    if new_placeholders:\n                        for new_placeholder in new_placeholders:\n                            parent_block = new_placeholder.find_type_group_in_parents(\r\n                                CodeBlockTypeGroup.STRUCTURE\r\n                            )\n                            if parent_block:\n                                error_response += f\"{parent_block.identifier} has a placeholder `{new_placeholder.content}` indicating that it's not fully implemented. Implement the full {parent_block.type.name} or reject the request.: \\n\\n```{parent_block.to_string()}```\\n\\n\"\n                            else:\n                                error_response += f\"There is a placeholder indicating out commented code : \\n```{new_placeholder.to_string()}\\n```. Do the full implementation or reject the request.\\n\"\n\n                    for validation_error in validation_errors:\n                        error_response += f\"{validation_error}\\n\"\n\n                    logger.warning(\r\n                        f\"Errors in updated file {self.file_path}:\\n{error_response}\"\r\n                    )\n\n                    return UpdateResult(\r\n                        file_path=self.file_path,\r\n                        updated=False,\r\n                        diff=diff,\r\n                        error=error_response,\r\n                    )\n\n                new_span_ids = module.get_all_span_ids() - set(\r\n                    self.module.get_all_span_ids()\r\n                )\n\n                logger.info(\r\n                    f\"Updated content for {self.file_path} with {len(new_span_ids)} new span ids.\"\r\n                )\n                self.module = module\n            else:\n                new_span_ids = []\n\n            self.dirty = True\n            self.content = updated_content\n\n            return UpdateResult(\r\n                file_path=self.file_path,\r\n                updated=True,\r\n                diff=diff,\r\n                new_span_ids=new_span_ids,\r\n            )\n\n        return UpdateResult(file_path=self.file_path, updated=False)", "kind": "Chunk", "id": "repository/file.py#233.85"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_FileRepository_FileRepository.path.return.self__repo_path", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 143, "span_ids": ["FileRepository.restore_from_disk", "FileRepository", "FileRepository.restore_from_snapshot", "FileRepository.snapshot", "FileRepository.__init__", "FileRepository.repo_dir", "FileRepository.dict", "FileRepository.path"], "start_line": 174, "end_line": 198, "community": null}, "content": "class FileRepository:\n    def __init__(self, repo_path: str):\n        self._repo_path = repo_path\n        self._files: dict[str, CodeFile] = {}\n\n    @property\r\n    def repo_dir(self):\n        return self._repo_path\n\n    def dict(self):\n        return {\"type\": \"file\", \"path\": self._repo_path}\n\n    def snapshot(self) -> dict:\n        return {}\n\n    def restore_from_snapshot(self, snapshot: dict):\n        pass\n\n    def restore_from_disk(self):\n        for file_path in self._files.keys():\n            self.get_file(file_path, refresh=True)\n\n    @property\r\n    def path(self):\n        return self._repo_path", "kind": "Chunk", "id": "repository/file.py#234.24"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_FileRepository.get_file_FileRepository.get_file.return.existing_file", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 276, "span_ids": ["FileRepository.get_file"], "start_line": 200, "end_line": 236, "community": null}, "content": "class FileRepository:\n\n    def get_file(\r\n        self, file_path: str, refresh: bool = False, from_origin: bool = False\r\n    ):\n        \"\"\"\r\n        Get a file from the repository.\r\n\r\n        Args:\r\n\r\n        \"\"\"\n        existing_file = self._files.get(file_path)\n        if not existing_file or refresh or from_origin:\n            full_file_path = os.path.join(self._repo_path, file_path)\n            if not os.path.exists(full_file_path):\n                logger.warning(f\"File not found: {full_file_path}\")\n                return None\n            if not os.path.isfile(full_file_path):\n                logger.warning(f\"{full_file_path} is not a file\")\n                return None\n\n            with open(full_file_path) as f:\n                parser = get_parser_by_path(file_path)\n                if parser:\n                    content = f.read()\n                    module = parser.parse(content)\n                    found_file = CodeFile(file_path=file_path, content=content, module=module)\n                else:\n                    found_file = CodeFile(file_path=file_path, content=f.read())\n\n            if not existing_file:\n                existing_file = found_file\n                self._files[file_path] = existing_file\n            elif refresh or not from_origin:\n                existing_file.content = found_file.content\n                existing_file.module = found_file.module\n                existing_file.dirty = False\n\n        return existing_file", "kind": "Chunk", "id": "repository/file.py#235.36"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_FileRepository.save_file_FileRepository.file_match.return.match", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 364, "span_ids": ["FileRepository.file_match", "FileRepository.find_files", "FileRepository.save_file", "FileRepository.matching_files", "FileRepository.save", "FileRepository.has_matching_files"], "start_line": 238, "end_line": 287, "community": null}, "content": "class FileRepository:\n\n    def save_file(self, file_path: str, updated_content: Optional[str] = None):\n        file = self._files.get(file_path)\n        full_file_path = os.path.join(self._repo_path, file_path)\n        with open(full_file_path, \"w\") as f:\n            updated_content = updated_content or file.module.to_string()\n            f.write(updated_content)\n\n        file.dirty = False\n\n    def save(self):\n        for file in self._files.values():\n            if file.dirty:\n                self.save_file(file.file_path, file.content)\n\n    def matching_files(self, file_pattern: str):\n        matched_files = []\n        for matched_file in glob.iglob(\r\n            file_pattern, root_dir=self._repo_path, recursive=True\r\n        ):\n            matched_files.append(matched_file)\n\n        if not matched_files and not file_pattern.startswith(\"*\"):\n            return self.matching_files(f\"**/{file_pattern}\")\n\n        return matched_files\n\n    def find_files(self, file_patterns: list[str]) -> set[str]:\n        found_files = set()\n        for file_pattern in file_patterns:\n            matched_files = self.matching_files(file_pattern)\n            found_files.update(matched_files)\n\n        return found_files\n\n    def has_matching_files(self, file_pattern: str):\n        for _matched_file in glob.iglob(\r\n            file_pattern, root_dir=self._repo_path, recursive=True\r\n        ):\n            return True\n        return False\n\n    def file_match(self, file_pattern: str, file_path: str):\n        match = False\n        for matched_file in glob.iglob(\r\n            file_pattern, root_dir=self._repo_path, recursive=True\r\n        ):\n            if matched_file == file_path:\n                match = True\n                break\n        return match", "kind": "Chunk", "id": "repository/file.py#236.49"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py_remove_duplicate_lines_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\file.py", "file_name": "file.py", "file_type": "text/x-python", "category": "test", "tokens": 180, "span_ids": ["remove_duplicate_lines", "do_diff"], "start_line": 290, "end_line": 318, "community": null}, "content": "def remove_duplicate_lines(replacement_lines, original_lines):\n    \"\"\"\r\n    Removes overlapping lines at the end of replacement_lines that match the beginning of original_lines.\r\n    \"\"\"\n    if not replacement_lines or not original_lines:\n        return replacement_lines\n\n    max_overlap = min(len(replacement_lines), len(original_lines))\n\n    for overlap in range(max_overlap, 0, -1):\n        if replacement_lines[-overlap:] == original_lines[:overlap]:\n            return replacement_lines[:-overlap]\n\n    return replacement_lines\n\n\ndef do_diff(\r\n    file_path: str, original_content: str, updated_content: str\r\n) -> Optional[str]:\n    return \"\".join(\r\n        difflib.unified_diff(\r\n            original_content.strip().splitlines(True),\r\n            updated_content.strip().splitlines(True),\r\n            fromfile=file_path,\r\n            tofile=file_path,\r\n            lineterm=\"\\n\",\r\n        )\r\n    )", "kind": "Chunk", "id": "repository/file.py#237.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\git.py_logging_GitRepository.commit.logger_info_f_Committed_c", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\git.py", "file_name": "git.py", "file_type": "text/x-python", "category": "test", "tokens": 649, "span_ids": ["GitRepository", "GitRepository.from_dict", "GitRepository.commit", "GitRepository.from_repo", "GitRepository.save_file", "GitRepository.dict", "GitRepository.restore_from_snapshot", "GitRepository.snapshot", "imports", "GitRepository.save", "GitRepository.__init__"], "start_line": 1, "end_line": 99, "community": null}, "content": "import logging\nfrom typing import Optional\n\nimport litellm\nfrom git import Repo\n\nfrom moatless.repository.file import FileRepository\nfrom moatless.settings import Settings\nfrom moatless.utils.repo import maybe_clone, checkout_commit\n\nlogger = logging.getLogger(__name__)\n\n\nclass GitRepository(FileRepository):\n    def __init__(\r\n        self, repo_path: str, git_repo_url: Optional[str], commit: Optional[str] = None\r\n    ):\n        super().__init__(repo_path)\n        self._repo_path = repo_path\n        self._repo_url = git_repo_url\n        self._repo = Repo(path=repo_path)\n        if not self._repo.heads:\n            raise Exception(\r\n                \"Git repository has no heads, you need to do an initial commit.\"\r\n            )\n\n        # TODO: Add support for branches\r\n        # self._current_branch = self._repo.active_branch.name\r\n\n        # TODO: Check if current branch is mainline\r\n\n        # TODO: Check if repo is dirty\r\n\n        if commit:\n            checkout_commit(repo_path, commit)\n\n        self._current_commit = self._repo.head.commit.hexsha\n        self._initial_commit = self._current_commit\n\n    @classmethod\r\n    def from_repo(cls, git_repo_url: str, repo_path: str, commit: Optional[str] = None):\n        logger.info(\r\n            f\"Create GitRepository for {git_repo_url} with commit {commit} on path {repo_path} \"\r\n        )\n\n        maybe_clone(git_repo_url, repo_path)\n\n        return cls(repo_path=repo_path, git_repo_url=git_repo_url, commit=commit)\n\n    @classmethod\r\n    def from_dict(cls, data: dict):\n        return cls.from_repo(\r\n            git_repo_url=data[\"repo_url\"],\r\n            repo_path=data[\"path\"],\r\n            commit=data[\"commit\"],\r\n        )\n\n    def restore_from_snapshot(self, snapshot: dict):\n        self._current_commit = snapshot[\"commit\"]\n\n\n        self._repo.git.checkout(self._current_commit)\n\n        # TODO: Check diff and only reset changed files\r\n\n        self.restore_from_disk()\n\n    def dict(self):\n        return {\r\n            \"type\": \"git\",\r\n            \"repo_path\": self._repo_path,\r\n            \"git_repo_url\": self._repo_url,\r\n            \"commit\": self._initial_commit,\r\n        }\n\n    def snapshot(self) -> dict:\n        return {\r\n            \"commit\": self._current_commit,\r\n        }\n\n    def save_file(self, file_path: str, updated_content: Optional[str] = None):\n        super().save_file(file_path, updated_content)\n        self.commit(file_path)\n\n    def save(self):\n        super().save()\n        self.commit()\n\n    def commit(self, file_path: str | None = None):\n        commit_message = self.commit_message(file_path)\n\n        if file_path:\n            self._repo.index.add(file_path)\n        else:\n            self._repo.index.add(\"*\")\n        self._repo.index.commit(commit_message)\n        self._current_commit = self._repo.head.commit.hexsha\n\n        logger.info(f\"Committed changes to git with message '{commit_message}' and commit hash '{self._current_commit}'\")", "kind": "Chunk", "id": "repository/git.py#238.98"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\git.py_GitRepository.commit_message_GitRepository.diff.return.self__repo_git_diff_self_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\repository\\git.py", "file_name": "git.py", "file_type": "text/x-python", "category": "test", "tokens": 231, "span_ids": ["GitRepository.diff", "GitRepository.commit_message"], "start_line": 101, "end_line": 129, "community": null}, "content": "class GitRepository(FileRepository):\n\n    def commit_message(self, file_path: str | None = None) -> str:\n        if file_path:\n            diff = self._repo.git.diff(\"HEAD\", file_path)\n        else:\n            diff = self._repo.git.diff(\"HEAD\")\n\n        if not diff:\n            return \"No changes.\"\n\n        if Settings.cheap_model:\n            prompt = f\"Generate a concise commit message for the following git diff\"\n            if file_path:\n                prompt += f\" of file {file_path}\"\n            prompt += f\":\\n\\n{diff}\\n\\nCommit message:\"\n\n            try:\n                response = litellm.completion(\r\n                    model=Settings.cheap_model,\r\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\r\n                    max_tokens=50,\r\n                )\n                return response.choices[0].message.content.strip()\n            except Exception as e:\n                logging.error(f\"Error generating commit message: {e}\")\n\n        return \"Automated commit by Moatless Tools\"\n\n    def diff(self):\n        return self._repo.git.diff(self._initial_commit, self._current_commit)", "kind": "Chunk", "id": "repository/git.py#239.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\settings.py_os_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\settings.py", "file_name": "settings.py", "file_type": "text/x-python", "category": "test", "tokens": 385, "span_ids": ["_Settings.embed_model", "_Settings.cheap_model", "_Settings.default_model", "_Settings", "_Settings.cheap_model_3", "_Settings.max_message_tokens_9", "_Settings.max_context_tokens_7", "_Settings.max_context_tokens", "_Settings.default_model_1", "_Settings.max_message_tokens", "_Settings.embed_model_5", "imports", "impl"], "start_line": 1, "end_line": 56, "community": null}, "content": "import os\nfrom dataclasses import dataclass\n\n\n@dataclass\r\nclass _Settings:\n    _default_model: str = os.environ.get(\"DEFAULT_MODEL\", \"gpt-4o-2024-05-13\")\n    _cheap_model: str | None = os.environ.get(\"CHEAP_MODEL\", \"gpt-4o-mini-2024-07-18\")\n    _embed_model: str = \"text-embedding-3-small\"\n\n    _max_context_tokens: int = 8000\n    _max_message_tokens: int = 16000\n\n    @property\r\n    def default_model(self) -> str:\n        return self._default_model\n\n    @default_model.setter\r\n    def default_model(self, default_model: str) -> None:\n        self._default_model = default_model\n\n    @property\r\n    def cheap_model(self) -> str | None:\n        return self._cheap_model\n\n    @cheap_model.setter\r\n    def cheap_model(self, cheap_model: str | None) -> None:\n        self._cheap_model = cheap_model\n\n    @property\r\n    def embed_model(self) -> str:\n        return self._embed_model\n\n    @embed_model.setter\r\n    def embed_model(self, embed_model: str) -> None:\n        self._embed_model = embed_model\n\n    @property\r\n    def max_context_tokens(self) -> int:\n        return self._max_context_tokens\n\n    @max_context_tokens.setter\r\n    def max_context_tokens(self, max_context_tokens: int) -> None:\n        self._max_context_tokens = max_context_tokens\n\n    @property\r\n    def max_message_tokens(self) -> int:\n        return self._max_message_tokens\n\n    @max_message_tokens.setter\r\n    def max_message_tokens(self, max_message_tokens: int) -> None:\n        self._max_message_tokens = max_message_tokens\n\n\nSettings = _Settings()", "kind": "Chunk", "id": "moatless/settings.py#240.55"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_logging_logger.logging_getLogger___name_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 124, "span_ids": ["imports"], "start_line": 1, "end_line": 22, "community": null}, "content": "import logging\nimport sys\nimport importlib\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Optional, List\nfrom copy import deepcopy\n\nfrom pydantic import BaseModel, Field, PrivateAttr, ConfigDict, model_validator\n\nfrom moatless.file_context import FileContext\nfrom moatless.repository import FileRepository\nfrom moatless.types import (\r\n    ActionRequest,\r\n    ActionResponse,\r\n    ActionTransaction,\r\n    FileWithSpans,\r\n    Message, Content, AssistantMessage,\r\n    Usage, UserMessage,\r\n)\nfrom moatless.workspace import Workspace\n\nlogger = logging.getLogger(__name__)", "kind": "Chunk", "id": "moatless/state.py#241.21"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_AgenticState_AgenticState.required_fields.return.set_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 740, "span_ids": ["AgenticState.workspace", "AgenticState.initial_message", "AgenticState.init", "AgenticState.required_fields", "AgenticState.response", "AgenticState.file_repo", "AgenticState.__init__", "AgenticState.create_file_context", "AgenticState.messages", "AgenticState.file_context", "AgenticState.last_action", "AgenticState.executed", "AgenticState.finish", "AgenticState", "AgenticState.handle_action", "AgenticState._execute_action", "AgenticState.name"], "start_line": 25, "end_line": 132, "community": null}, "content": "class AgenticState(ABC, BaseModel):\n    id: int = Field(..., description=\"The unique identifier of the state\")\n    previous_state: Optional[\"AgenticState\"] = Field(\r\n        default=None, description=\"The state that led to this state\"\r\n    )\n    next_states: List[\"AgenticState\"] = Field(\r\n        default_factory=list, description=\"The states this state transitioned to\"\r\n    )\n    model: Optional[str] = Field(\r\n        default=None, description=\"The model to use for completion\"\r\n    )\n    temperature: float = Field(0.0, description=\"The temperature to use for completion\")\n    max_tokens: int = Field(\r\n        1000, description=\"The maximum number of tokens to generate\"\r\n    )\n    include_message_history: bool = Field(\r\n        default=False,\r\n        description=\"The message history from previous initations should be included in the completion request\",\r\n    )\n    max_iterations: Optional[int] = Field(\r\n        None, description=\"The maximum number of transitions to this state.\"\r\n    )\n\n    _workspace: Optional[Workspace] = PrivateAttr(None)\n    _initial_message: Optional[str] = PrivateAttr(None)\n\n    _executed: bool = PrivateAttr(False)\n    _actions: List[ActionTransaction] = PrivateAttr(default_factory=list)\n\n    model_config = ConfigDict(\r\n        arbitrary_types_allowed=True,\r\n        exclude={\"previous_state\", \"next_states\"}\r\n    )\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._workspace = data.get('_workspace')\n        self._initial_message = data.get('_initial_message')\n\n    def handle_action(self, action: ActionRequest, usage: Usage | None) -> ActionResponse:\n        if self._executed:\n            raise ValueError(f\"State has already been executed\")\n\n        response = self._execute_action(action)\n        self._actions.append(ActionTransaction(request=action, response=response, usage=usage))\n\n        if response.trigger and response.trigger != \"retry\":\n            self._executed = True\n\n        return response\n\n    @abstractmethod\r\n    def _execute_action(self, action: ActionRequest) -> ActionResponse:\n        raise NotImplementedError\n\n    @property\r\n    def name(self):\n        return self.__class__.__name__\n\n    @property\r\n    def executed(self):\n        return self._executed\n\n    @property\r\n    def last_action(self) -> Optional[ActionTransaction]:\n        return self._actions[-1] if self._actions else None\n\n    @property\r\n    def response(self) -> Optional[ActionResponse]:\n        return self._actions[-1].response if self._actions else None\n\n    @property\r\n    def workspace(self) -> Workspace:\n        return self._workspace\n\n    @property\r\n    def file_repo(self) -> FileRepository:\n        return self._workspace.file_repo\n\n    @property\r\n    def file_context(self) -> FileContext:\n        return self._workspace.file_context\n\n    @property\r\n    def initial_message(self) -> str:\n        return self._initial_message\n\n    def create_file_context(\r\n        self, files: list[FileWithSpans] = None, **kwargs\r\n    ) -> FileContext:\n        if files is None:\n            files = []\n        return self.workspace.create_file_context(files, **kwargs)\n\n    def init(self):\n        \"\"\"Initialization logic for the state.\"\"\"\n        pass\n\n    def finish(self, message: str):\n        # TODO!!\r\n        logger.info(message)\n\n    def messages(self) -> list[Message]:\n        return []\n\n    @classmethod\r\n    def required_fields(cls) -> set[str]:\n        return set()", "kind": "Chunk", "id": "moatless/state.py#242.107"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_AgenticState.get_previous_states_AgenticState.get_previous_states.return.previous_states", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 202, "span_ids": ["AgenticState.get_previous_states"], "start_line": 134, "end_line": 157, "community": null}, "content": "class AgenticState(ABC, BaseModel):\n\n    def get_previous_states(self, state: Optional[\"AgenticState\"] = None) -> list[\"AgenticState\"]:\n        \"\"\"\r\n        Retrieves previous states of the same type as the given state.\r\n        If no state is provided, it returns all previous states.\r\n\r\n        Args:\r\n            state (AgenticState | None): The state to filter by. If None, all previous states are returned.\r\n\r\n        Returns:\r\n            list: A list of previous states, filtered by type if a state is provided.\r\n        \"\"\"\n        previous_states = []\n        current_state = self\n\n        while current_state and current_state.previous_state:\n            current_state = current_state.previous_state\n            if not state or isinstance(current_state, type(state)):\n                previous_states.insert(0, current_state)\n\n        logger.debug(\r\n            f\"Found {len(previous_states)} previous states of type {state.__class__.__name__ if state else 'all types'}\"\r\n        )\n\n        return previous_states", "kind": "Chunk", "id": "moatless/state.py#243.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_AgenticState.retries_AgenticState.__eq__.return.True", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 469, "span_ids": ["AgenticState.retries", "AgenticState.validate_previous_state", "AgenticState.model_dump", "AgenticState.stop_words", "AgenticState.system_prompt", "AgenticState.total_cost", "AgenticState.__eq__", "AgenticState.action_type", "AgenticState.retry_messages", "AgenticState.clone"], "start_line": 159, "end_line": 238, "community": null}, "content": "class AgenticState(ABC, BaseModel):\n\n    def retries(self) -> int:\n        retries = 0\n        for action in reversed(self._actions):\n            if action.response.trigger == \"retry\":\n                retries += 1\n            else:\n                return retries\n\n        return retries\n\n    def retry_messages(self) -> list[Message]:\n        messages: list[Message] = []\n\n        for action in self._actions:\n            if isinstance(action.request, Content):\n                messages.append(\r\n                    AssistantMessage(\r\n                        content=action.request.content,\r\n                    )\r\n                )\n            else:\n                messages.append(AssistantMessage(action=action.request))\n\n            if action.response.retry_message:\n                messages.append(\r\n                    UserMessage(\r\n                        content=action.response.retry_message,\r\n                    )\r\n                )\n\n        return messages\n\n    def system_prompt(self) -> str:\n        return \"\"\n\n    def action_type(self) -> type[ActionRequest] | None:\n        \"\"\"\r\n        The type of the action to expect in the completion response.\r\n        If not set a content string is expected.\r\n        \"\"\"\n        raise NotImplementedError\n\n    def stop_words(self) -> list[str] | None:\n        return None\n\n    def model_dump(self, **kwargs):\n        if 'exclude' not in kwargs:\n            kwargs['exclude'] = {\"previous_state\", \"next_states\"}\n\n        data = super().model_dump(**kwargs)\n        return data\n\n    @classmethod\r\n    @model_validator(mode=\"before\")\r\n    def validate_previous_state(cls, values):\n        if isinstance(obj, dict) and \"previous_state_id\" in obj:\n            obj = obj.copy()\n            obj[\"previous_state\"] = None\n        return super().model_validate(obj)\n\n    def clone(self) -> \"AgenticState\":\n        new_state = self.__class__(**self.model_dump())\n        if hasattr(self, '_workspace'):\n            new_state._workspace = self._workspace\n        return new_state\n\n    def total_cost(self):\n        total_cost = 0\n        for action in self._actions:\n            if action.usage:\n                total_cost += action.usage.completion_cost\n\n        return total_cost\n\n    def __eq__(self, other):\n        if not isinstance(other, AgenticState):\n            return NotImplemented\n        if self.model_dump() != other.model_dump():\n            return False\n        return True", "kind": "Chunk", "id": "moatless/state.py#244.79"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_NoopState_Pending.__init__.super___init___data_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 121, "span_ids": ["Finished", "Pending", "NoopState._execute_action", "Rejected", "Pending.__init__", "NoopState"], "start_line": 241, "end_line": 260, "community": null}, "content": "class NoopState(AgenticState):\n\n    def _execute_action(self, action: ActionRequest):\n        raise ValueError(\"NoopState cannot handle actions\")\n\n\nclass Finished(NoopState):\n    message: Optional[str] = None\n    output: dict[str, Any] | None = None\n\n\nclass Rejected(NoopState):\n    message: Optional[str] = None\n\n\nclass Pending(NoopState):\n    def __init__(self, **data):\n        if 'id' not in data:\n            data['id'] = 0\n        super().__init__(**data)", "kind": "Chunk", "id": "moatless/state.py#245.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py_get_state_class_get_state_class.raise_ValueError_f_State_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\state.py", "file_name": "state.py", "file_type": "text/x-python", "category": "test", "tokens": 241, "span_ids": ["get_state_class"], "start_line": 263, "end_line": 297, "community": null}, "content": "def get_state_class(name: str) -> type[AgenticState]:\n    builtin_states = {\r\n        \"NoopState\": NoopState,\r\n        \"Finished\": Finished,\r\n        \"Rejected\": Rejected,\r\n        \"Pending\": Pending,\r\n    }\n    if name in builtin_states:\n        return builtin_states[name]\n\n    # If not a built-in state, try to import dynamically\r\n    possible_modules = [\r\n        \"moatless.edit\",\r\n        \"moatless.find\",\r\n    ]\n\n    for module_name in possible_modules:\n\n        try:\n            module = importlib.import_module(module_name)\n            if hasattr(module, name):\n                cls = getattr(module, name)\n                if isinstance(cls, type) and issubclass(cls, AgenticState):\n                    return cls\n        except ImportError:\n            logger.debug(f\"Could not import module {module_name}\")\n\n    # If still not found, try sys.modules as a fallback\r\n    for module in sys.modules.values():\n        if hasattr(module, name):\n            cls = getattr(module, name)\n            if isinstance(cls, type) and issubclass(cls, AgenticState):\n                return cls\n\n    raise ValueError(f\"State {name} not found\")", "kind": "Chunk", "id": "moatless/state.py#246.34"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_json_TrajectoryState.model_dump.return.data", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 303, "span_ids": ["imports", "TrajectoryState", "TrajectoryState.name", "TrajectoryState.model_dump"], "start_line": 1, "end_line": 48, "community": null}, "content": "import json\nimport logging\nfrom datetime import datetime\nfrom typing import Any, Optional, List\n\nfrom pydantic import BaseModel, Field\nfrom pydantic_core import to_jsonable_python\n\nfrom moatless.workspace import Workspace\nfrom moatless.transition_rules import TransitionRules\nfrom moatless.state import AgenticState, get_state_class\nfrom moatless.types import ActionRequest, ActionTransaction, ActionResponse, Usage, Content\n\nlogger = logging.getLogger(__name__)\n\n\n\nclass TrajectoryState(BaseModel):\n    id: int\n    timestamp: datetime = Field(default_factory=datetime.now)\n    snapshot: Optional[dict] = None\n    state: AgenticState\n\n    @property\r\n    def name(self):\n        return self.state.name if self.state else None\n\n    def model_dump(self, **kwargs):\n        data = {\r\n            \"id\": self.id,\r\n            \"name\": self.state.name,\r\n            \"timestamp\": self.timestamp,\r\n        }\n\n        if self.snapshot:\n            data[\"snapshot\"] = self.snapshot\n\n        if self.state.previous_state:\n            data[\"previous_state_id\"] = self.state.previous_state.id\n\n        properties = self.state.model_dump(exclude={\"previous_state\", \"next_states\", \"id\"}, **kwargs) if self.state else None\n        if properties:\n            data[\"properties\"] = properties\n\n        if self.state._actions:\n            data[\"actions\"] = [a.model_dump(**kwargs) for a in self.state._actions]\n\n        return data", "kind": "Chunk", "id": "moatless/trajectory.py#247.47"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory_Trajectory.__init__.self._info._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 182, "span_ids": ["Trajectory.__init__", "Trajectory"], "start_line": 51, "end_line": 74, "community": null}, "content": "class Trajectory:\n    def __init__(\r\n        self,\r\n        name: str,\r\n        workspace: Workspace,\r\n        initial_message: Optional[str] = None,\r\n        persist_path: Optional[str] = None,\r\n        transition_rules: Optional[TransitionRules] = None,\r\n    ):\n        self._name = name\n        self._persist_path = persist_path\n        self._initial_message = initial_message\n        self._workspace = workspace\n\n        # Workaround to set to keep the current initial workspace state when loading an existing trajectory.\r\n        # TODO: Remove this when we have a better way to handle this.\r\n        self._initial_workspace_state = self._workspace.dict()\n\n        self._transition_rules = transition_rules\n\n        self._current_transition_id = 0\n        self._transitions: dict[int, TrajectoryState] = {}\n\n        self._info: dict[str, Any] = {}", "kind": "Chunk", "id": "moatless/trajectory.py#248.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory.load_Trajectory.load.return.trajectory", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 546, "span_ids": ["Trajectory.load"], "start_line": 76, "end_line": 148, "community": null}, "content": "class Trajectory:\n\n    @classmethod\r\n    def load(cls, file_path: str):\n        with open(file_path, \"r\") as f:\n            data = json.load(f)\n\n        if \"transition_rules\" in data:\n            transition_rules = TransitionRules.model_validate(data[\"transition_rules\"])\n        else:\n            transition_rules = None\n\n        workspace = Workspace.from_dict(data[\"workspace\"])\n        trajectory = cls(\r\n            name=data[\"name\"],\r\n            initial_message=data[\"initial_message\"],\r\n            transition_rules=transition_rules,\r\n            workspace=workspace\r\n        )\n\n        trajectory._info = data.get(\"info\", {})\n\n        trajectory._transitions = {}\n        trajectory._current_transition_id = data.get(\"current_transition_id\", 0)\n\n        for t in data[\"transitions\"]:\n            state_class = get_state_class(t[\"name\"])\n            state_data = t[\"properties\"]\n            state_data[\"id\"] = t[\"id\"]\n            state = state_class.model_validate(state_data)\n\n            state._workspace = trajectory._workspace\n            state._initial_message = trajectory._initial_message\n            state._actions = []\n            if \"actions\" in t:\n                for a in t[\"actions\"]:\n                    try:\n                        if state.action_type() is None:\n                            request = Content.model_validate(a[\"request\"])\n                        else:\n                            request = state.action_type().model_validate(a[\"request\"])\n                        response = ActionResponse.model_validate(a.get(\"response\"))\n                        if a.get(\"usage\"):\n                            usage = Usage.model_validate(a.get(\"usage\"))\n                        else:\n                            usage = None\n                        state._actions.append(ActionTransaction(request=request, response=response, usage=usage))\n                    except Exception as e:\n                        logger.exception(f\"Error loading action for state {state.name}: {a}\")\n                        raise e\n\n            trajectory_state = TrajectoryState(\r\n                id=t[\"id\"],\r\n                timestamp=datetime.fromisoformat(t[\"timestamp\"]),\r\n                snapshot=t.get(\"snapshot\"),\r\n                state=state\r\n            )\n\n            trajectory._transitions[t[\"id\"]] = trajectory_state\n\n        # Set previous_state and next_states\r\n        for t in data[\"transitions\"]:\n            try:\n                current_state = trajectory._transitions[t[\"id\"]].state\n                if t.get(\"previous_state_id\") is not None:\n                    current_state.previous_state = trajectory._transitions.get(t[\"previous_state_id\"]).state\n            except KeyError as e:\n                logger.exception(f\"Missing key {e}, existing keys: {trajectory._transitions.keys()}\")\n                raise\n\n        trajectory._info = data.get(\"info\", {})\n\n        logger.info(f\"Loaded trajectory {trajectory._name} with {len(trajectory._transitions)} transitions\")\n\n        return trajectory", "kind": "Chunk", "id": "moatless/trajectory.py#249.72"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory.initial_message_Trajectory.update_workspace_to_current_state.self_restore_from_snapsho", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 216, "span_ids": ["Trajectory.info", "Trajectory.transitions", "Trajectory.states", "Trajectory.update_workspace_to_current_state", "Trajectory.set_current_state", "Trajectory.get_current_state", "Trajectory.workspace", "Trajectory.initial_message", "Trajectory.transition_rules"], "start_line": 150, "end_line": 182, "community": null}, "content": "class Trajectory:\n\n    @property\r\n    def initial_message(self):\n        return self._initial_message\n\n    @property\r\n    def info(self):\n        return self._info\n\n    @property\r\n    def states(self) -> List[dict]:\n        return [t.state.model_dump() for t in self.transitions]\n\n    @property\r\n    def transition_rules(self) -> TransitionRules:\n        return self._transition_rules\n\n    @property\r\n    def workspace(self) -> Workspace:\n        return self._workspace\n\n    @property\r\n    def transitions(self) -> List[TrajectoryState]:\n        return sorted(self._transitions.values(), key=lambda x: x.id)\n\n    def set_current_state(self, state: AgenticState):\n        self._current_transition_id = state.id\n        self._maybe_persist()\n\n    def get_current_state(self) -> AgenticState:\n        return self._transitions.get(self._current_transition_id).state\n\n    def update_workspace_to_current_state(self):\n        self.restore_from_snapshot(self._transitions[self._current_transition_id])", "kind": "Chunk", "id": "moatless/trajectory.py#250.32"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory.restore_from_snapshot_Trajectory.restore_from_snapshot.if_state_snapshot_get_fi.self__workspace_file_cont", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 116, "span_ids": ["Trajectory.restore_from_snapshot"], "start_line": 184, "end_line": 195, "community": null}, "content": "class Trajectory:\n\n    def restore_from_snapshot(self, state: TrajectoryState):\n        if not state.snapshot:\n            logger.info(f\"restore_from_snapshot(state: {state.id}:{state.name}) No snapshot found\")\n            return\n\n        logger.info(f\"restore_from_snapshot(starte: {state.id}:{state.name}) Restoring from snapshot\")\n\n        if state.snapshot.get(\"repository\"):\n            self._workspace.file_repo.restore_from_snapshot(state.snapshot[\"repository\"])\n\n        if state.snapshot.get(\"file_context\"):\n            self._workspace.file_context.restore_from_snapshot(state.snapshot[\"file_context\"])", "kind": "Chunk", "id": "moatless/trajectory.py#251.11"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory.save_state_Trajectory.get_expected_states.return._transition_state_name_fo", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 258, "span_ids": ["Trajectory.save_info", "Trajectory.get_state", "Trajectory.save_state", "Trajectory.get_mocked_actions", "Trajectory.get_expected_states"], "start_line": 197, "end_line": 232, "community": null}, "content": "class Trajectory:\n\n    def save_state(self, state: AgenticState):\n        if state.id in self._transitions:\n            self._transitions[state.id].state = state\n        else:\n            transition = TrajectoryState(\r\n                id=state.id,\r\n                state=state,\r\n                snapshot=state.workspace.snapshot() if state.workspace else None,\r\n            )\n            self._transitions[state.id] = transition\n\n        self._maybe_persist()\n\n    def get_state(self, state_id: int) -> TrajectoryState | None:\n        return self._transitions.get(state_id)\n\n    def save_info(self, info: dict):\n        self._info = info\n        self._maybe_persist()\n\n    def get_mocked_actions(self) -> List[dict]:\n        \"\"\"\r\n        Return a list of actions that can be used to mock the trajectory.\r\n        \"\"\"\n        actions = []\n\n        for transition in self.transitions:\n            for action in transition.state._actions:\n                actions.append(action.request.model_dump())\n        return actions\n\n    def get_expected_states(self) -> List[str]:\n        \"\"\"\r\n        Return a list of expected states in the trajectory to use for verification when rerunning the trajectory.\r\n        \"\"\"\n        return [transition.state.name for transition in self.transitions[1:]]", "kind": "Chunk", "id": "moatless/trajectory.py#252.35"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py_Trajectory.to_dict_Trajectory.persist.with_open_f_file_path_.f_write_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\trajectory.py", "file_name": "trajectory.py", "file_type": "text/x-python", "category": "test", "tokens": 190, "span_ids": ["Trajectory.to_dict", "Trajectory.persist", "Trajectory._maybe_persist"], "start_line": 234, "end_line": 261, "community": null}, "content": "class Trajectory:\n\n    def to_dict(self):\n        return {\r\n            \"name\": self._name,\r\n            \"transition_rules\": self._transition_rules.model_dump(\r\n                exclude_none=True\r\n            )\r\n            if self._transition_rules\r\n            else None,\r\n            \"workspace\": self._initial_workspace_state,\r\n            \"initial_message\": self._initial_message,\r\n            \"current_transition_id\": self._current_transition_id,\r\n            \"transitions\": [t.model_dump(exclude_none=True) for t in self.transitions],\r\n            \"info\": self._info,\r\n        }\n\n    def _maybe_persist(self):\n        if self._persist_path:\n            self.persist(self._persist_path)\n\n    def persist(self, file_path: str):\n        with open(f\"{file_path}\", \"w\") as f:\n            f.write(\r\n                json.dumps(\r\n                    self.to_dict(),\r\n                    indent=2,\r\n                    default=to_jsonable_python,\r\n                )\r\n            )", "kind": "Chunk", "id": "moatless/trajectory.py#253.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py_logging_TransitionRule.validate_state_classes.return.data", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py", "file_name": "transition_rules.py", "file_type": "text/x-python", "category": "test", "tokens": 444, "span_ids": ["TransitionRule.validate_state_classes", "TransitionRule", "TransitionRule.get", "TransitionRule.model_dump", "imports"], "start_line": 1, "end_line": 62, "community": null}, "content": "import logging\n\nfrom pydantic import BaseModel, Field, PrivateAttr, model_validator\nfrom typing import Any, Type, Optional\n\nfrom moatless.settings import Settings\nfrom moatless.state import AgenticState, get_state_class\nfrom moatless.workspace import Workspace\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass TransitionRule(BaseModel):\n    trigger: str = Field(\r\n        ...,\r\n        description=\"The trigger from the current state that causes the transition to fire.\",\r\n    )\n    source: type[AgenticState] = Field(\r\n        ..., description=\"The source state that the transition rule is defined for.\"\r\n    )\n    dest: type[AgenticState] = Field(\r\n        ...,\r\n        description=\"The destination state that the transition rule is defined for.\",\r\n    )\n    required_fields: Optional[set[str]] = Field(\r\n        default=None,\r\n        description=\"The fields that are required for the transition to fire.\",\r\n    )\n    excluded_fields: Optional[set[str]] = Field(\r\n        default=None, description=\"The fields that are excluded from the transition.\"\r\n    )\n\n    def get(self, key: str, default: Any = None) -> Any:\n        return getattr(self, key, default)\n\n    def model_dump(self, **kwargs):\n        data = super().model_dump(**kwargs)\n        data[\"source\"] = self.source.__name__\n        data[\"dest\"] = self.dest.__name__\n\n        if data.get(\"required_fields\"):\n            data[\"required_fields\"] = list(data.get(\"required_fields\"))\n\n        if data.get(\"excluded_fields\"):\n            data[\"excluded_fields\"] = list(data.get(\"excluded_fields\"))\n\n        return data\n\n    @model_validator(mode=\"before\")\r\n    @classmethod\r\n    def validate_state_classes(cls, data: Any) -> Any:\n        if isinstance(data, dict):\n            if isinstance(data.get(\"source\"), str):\n                data[\"source\"] = get_state_class(data[\"source\"])\n            if isinstance(data.get(\"dest\"), str):\n                data[\"dest\"] = get_state_class(data[\"dest\"])\n\n        if data[\"source\"] == data[\"dest\"]:\n            raise ValueError(\"Source and destination states cannot be the same.\")\n\n        return data", "kind": "Chunk", "id": "moatless/transition_rules.py#254.61"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py_TransitionRules_TransitionRules.model_dump.return.data", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py", "file_name": "transition_rules.py", "file_type": "text/x-python", "category": "test", "tokens": 285, "span_ids": ["TransitionRules.model_dump", "TransitionRules.__init__", "TransitionRules"], "start_line": 65, "end_line": 101, "community": null}, "content": "class TransitionRules(BaseModel):\n    initial_state: type[AgenticState] | None = Field(\r\n        default=None, \r\n        description=\"The initial state for the loop.\",\r\n        deprecated=\"Initial state should be set in transition_rules instead.\"\r\n    )\n    transition_rules: list[TransitionRule] = Field(\r\n        ..., description=\"The transition rules for the loop.\"\r\n    )\n    global_params: dict[str, Any] = Field(\r\n        default_factory=dict, description=\"Global parameters used by all transitions.\"\r\n    )\n    state_params: dict[type[AgenticState], dict[str, Any]] = Field(\r\n        default_factory=dict, description=\"State-specific parameters.\"\r\n    )\n\n    _source_trigger_index: dict[\r\n        tuple[type[AgenticState], str], list[TransitionRule]\r\n    ] = PrivateAttr(default_factory=dict)\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._build_source_trigger_index()\n\n    def model_dump(self, **kwargs):\n        data = {\r\n            \"global_params\": self.global_params,\r\n            \"state_params\": {k.__name__: v for k, v in self.state_params.items()},\r\n            \"transition_rules\": [\r\n                rule.model_dump(**kwargs) for rule in self.transition_rules\r\n            ],\r\n        }\n\n        if self.initial_state:\n            data[\"initial_state\"] = self.initial_state.__name__\n\n        return data", "kind": "Chunk", "id": "moatless/transition_rules.py#255.36"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py_TransitionRules.validate_before_init_TransitionRules.validate_before_init.return.data", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py", "file_name": "transition_rules.py", "file_type": "text/x-python", "category": "test", "tokens": 180, "span_ids": ["TransitionRules.validate_before_init"], "start_line": 103, "end_line": 123, "community": null}, "content": "class TransitionRules(BaseModel):\n\n    @model_validator(mode=\"before\")\r\n    @classmethod\r\n    def validate_before_init(cls, data: Any) -> Any:\n        if isinstance(data, dict):\n            if isinstance(data.get(\"initial_state\"), str):\n                data[\"initial_state\"] = get_state_class(data[\"initial_state\"])\n\n            if \"state_params\" in data:\n                data[\"state_params\"] = {\r\n                    get_state_class(k) if isinstance(k, str) else k: v\r\n                    for k, v in data[\"state_params\"].items()\r\n                }\n\n        if \"global_params\" not in data:\n            data[\"global_params\"] = {}\n\n        if \"model\" not in data[\"global_params\"]:\n            logger.info(f\"No model specified in global_params. Using default model: {Settings.default_model}\")\n            data[\"global_params\"][\"model\"] = Settings.default_model\n\n        return data", "kind": "Chunk", "id": "moatless/transition_rules.py#256.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py_TransitionRules._build_source_trigger_index_TransitionRules.params.return.params", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py", "file_name": "transition_rules.py", "file_type": "text/x-python", "category": "test", "tokens": 154, "span_ids": ["TransitionRules.find_transition_rule_by_source_and_trigger", "TransitionRules.params", "TransitionRules._build_source_trigger_index"], "start_line": 125, "end_line": 141, "community": null}, "content": "class TransitionRules(BaseModel):\n\n    def _build_source_trigger_index(self):\n        for rule in self.transition_rules:\n            key = (rule.source, rule.trigger)\n            if key not in self._source_trigger_index:\n                self._source_trigger_index[key] = []\n            self._source_trigger_index[key].append(rule)\n\n    def find_transition_rule_by_source_and_trigger(\r\n        self, source: type[AgenticState], trigger: str\r\n    ) -> list[TransitionRule]:\n        return self._source_trigger_index.get((source, trigger), [])\n\n    def params(self, rule: TransitionRule) -> dict[str, Any]:\n        params = {}\n        params.update(self.global_params)\n        params.update(self.state_params.get(rule.dest, {}))\n        return params", "kind": "Chunk", "id": "moatless/transition_rules.py#257.16"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py_TransitionRules.get_next_rule_TransitionRules.get_next_rule.return.None", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transition_rules.py", "file_name": "transition_rules.py", "file_type": "text/x-python", "category": "test", "tokens": 176, "span_ids": ["TransitionRules.get_next_rule"], "start_line": 143, "end_line": 168, "community": null}, "content": "class TransitionRules(BaseModel):\n\n    def get_next_rule(\r\n        self, source: AgenticState, trigger: str, data: dict[str, Any]\r\n    ) -> TransitionRule | None:\n\n        if trigger == \"init\" and self.initial_state:\n            logger.warning(\"Using deprecated 'initial_state'. Set initial state in transition_rules instead.\")\n            return TransitionRule(\r\n                trigger=\"init\",\r\n                source=source.__class__,\r\n                dest=self.initial_state,\r\n            )\n\n        transition_rules = self.find_transition_rule_by_source_and_trigger(\r\n            source.__class__, trigger\r\n        )\n        for transition_rule in transition_rules:\n            if (\r\n                transition_rule.required_fields\r\n                and not transition_rule.required_fields.issubset(data.keys())\r\n            ):\n                logger.info(f\"Missing required fields for transition {transition_rule}\")\n                continue\n\n            return transition_rule\n\n        return None", "kind": "Chunk", "id": "moatless/transition_rules.py#258.25"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_logging_logger.logging_getLogger___name_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 326, "span_ids": ["imports"], "start_line": 1, "end_line": 41, "community": null}, "content": "import logging\nfrom typing import Optional\n\nfrom moatless.edit.clarify import ClarifyCodeChange\nfrom moatless.edit.edit import EditCode\nfrom moatless.edit.plan import PlanToCode\nfrom moatless.edit.plan_lines import PlanToCodeWithLines\nfrom moatless.find.decide import DecideRelevance\nfrom moatless.find.identify import IdentifyCode\nfrom moatless.find.search import SearchCode\nfrom moatless.transition_rules import TransitionRule, TransitionRules\nfrom moatless.state import Finished, Rejected, Pending\n\nCODE_TRANSITIONS = [\r\n    TransitionRule(\r\n        source=PlanToCode,\r\n        dest=EditCode,\r\n        trigger=\"edit_code\",\r\n        required_fields=EditCode.required_fields(),\r\n    ),\r\n    TransitionRule(\r\n        source=PlanToCode,\r\n        dest=ClarifyCodeChange,\r\n        trigger=\"edit_code\",\r\n        required_fields=ClarifyCodeChange.required_fields(),\r\n    ),\r\n    TransitionRule(source=PlanToCode, dest=Finished, trigger=\"finish\"),\r\n    TransitionRule(source=PlanToCode, dest=Rejected, trigger=\"reject\"),\r\n    TransitionRule(\r\n        source=ClarifyCodeChange,\r\n        dest=EditCode,\r\n        trigger=\"edit_code\",\r\n        required_fields=EditCode.required_fields(),\r\n    ),\r\n    TransitionRule(source=ClarifyCodeChange, dest=PlanToCode, trigger=\"reject\"),\r\n    TransitionRule(source=EditCode, dest=PlanToCode, trigger=\"finish\"),\r\n    TransitionRule(source=EditCode, dest=PlanToCode, trigger=\"reject\"),\r\n]\n\n\nlogger = logging.getLogger(__name__)", "kind": "Chunk", "id": "moatless/transitions.py#259.40"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_code_transitions_code_transitions.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 149, "span_ids": ["code_transitions"], "start_line": 44, "end_line": 64, "community": null}, "content": "def code_transitions(\r\n    global_params: Optional[dict] = None,\r\n    state_params: Optional[dict] = None,\r\n    max_prompt_file_tokens: Optional[int] = 16000,\r\n    max_tokens_in_edit_prompt: Optional[int] = 500,\r\n) -> TransitionRules:\n    state_params = state_params or {}\n    state_params.setdefault(\r\n        PlanToCode,\r\n        {\r\n            \"max_prompt_file_tokens\": max_prompt_file_tokens,\r\n            \"max_tokens_in_edit_prompt\": max_tokens_in_edit_prompt,\r\n        },\r\n    )\n\n    return TransitionRules(\r\n        global_params=global_params or {},\r\n        state_params=state_params,\r\n        initial_state=PlanToCode,\r\n        transition_rules=CODE_TRANSITIONS,\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#260.20"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_code_transitions_use_line_numbers_code_transitions_use_line_numbers.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 193, "span_ids": ["code_transitions_use_line_numbers"], "start_line": 67, "end_line": 86, "community": null}, "content": "def code_transitions_use_line_numbers(\r\n    global_params: Optional[dict] = None, state_params: Optional[dict] = None\r\n) -> TransitionRules:\n    return TransitionRules(\r\n        global_params=global_params or {},\r\n        state_params=state_params or {},\r\n        initial_state=PlanToCodeWithLines,\r\n        transition_rules=[\r\n            TransitionRule(\r\n                source=PlanToCodeWithLines,\r\n                dest=EditCode,\r\n                trigger=\"edit_code\",\r\n                required_fields=PlanToCodeWithLines.required_fields(),\r\n            ),\r\n            TransitionRule(source=PlanToCodeWithLines, dest=Finished, trigger=\"finish\"),\r\n            TransitionRule(source=PlanToCodeWithLines, dest=Rejected, trigger=\"reject\"),\r\n            TransitionRule(source=EditCode, dest=PlanToCodeWithLines, trigger=\"finish\"),\r\n            TransitionRule(source=EditCode, dest=PlanToCodeWithLines, trigger=\"reject\"),\r\n        ],\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#261.19"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_edit_code_transitions_edit_code_transitions.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 103, "span_ids": ["edit_code_transitions"], "start_line": 89, "end_line": 100, "community": null}, "content": "def edit_code_transitions(\r\n    global_params: Optional[dict] = None, state_params: Optional[dict] = None\r\n) -> TransitionRules:\n    return TransitionRules(\r\n        global_params=global_params or {},\r\n        state_params=state_params or {},\r\n        initial_state=EditCode,\r\n        transition_rules=[\r\n            TransitionRule(source=EditCode, dest=Finished, trigger=\"finish\"),\r\n            TransitionRule(source=EditCode, dest=Rejected, trigger=\"reject\"),\r\n        ],\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#262.11"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_search_transitions_search_transitions.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 342, "span_ids": ["search_transitions"], "start_line": 103, "end_line": 145, "community": null}, "content": "def search_transitions(\r\n    model: Optional[str] = None,\r\n    max_prompt_file_tokens: Optional[int] = None,\r\n    max_search_results: Optional[int] = None,\r\n    max_maybe_finish_iterations: int = 5,\r\n    global_params: Optional[dict] = None,\r\n    state_params: Optional[dict] = None,\r\n) -> TransitionRules:\n    global_params = global_params or {}\n\n    if model is not None:\n        global_params[\"model\"] = model\n\n    if state_params is None:\n        state_params = {}\n\n    if max_search_results is not None:\n        state_params.setdefault(SearchCode, {\"max_search_results\": max_search_results})\n\n    if max_prompt_file_tokens is not None:\n        state_params.setdefault(\r\n            IdentifyCode, {\"max_prompt_file_tokens\": max_prompt_file_tokens}\r\n        )\n\n    state_params.setdefault(\r\n        DecideRelevance, {\"max_iterations\": max_maybe_finish_iterations}\r\n    )\n\n    logger.info(state_params)\n\n    return TransitionRules(\r\n        global_params=global_params,\r\n        state_params=state_params,\r\n        initial_state=SearchCode,\r\n        transition_rules=[\r\n            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger=\"did_search\"),\r\n            TransitionRule(source=SearchCode, dest=Finished, trigger=\"finish\"),\r\n            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger=\"finish\"),\r\n            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(source=DecideRelevance, dest=Finished, trigger=\"finish\"),\r\n        ],\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#263.42"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_identify_directly_transition_identify_directly_transition.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 237, "span_ids": ["identify_directly_transition"], "start_line": 148, "end_line": 181, "community": null}, "content": "def identify_directly_transition(\r\n    model: Optional[str] = None,\r\n    max_prompt_file_tokens: Optional[int] = 30000,\r\n    max_search_results: Optional[int] = 100,\r\n    global_params: Optional[dict] = None,\r\n    state_params: Optional[dict] = None,\r\n) -> TransitionRules:\n    global_params = global_params or {}\n\n    if model is not None:\n        global_params[\"model\"] = model\n\n    if state_params is None:\n        state_params = {}\n\n    if max_search_results is not None:\n        state_params.setdefault(SearchCode, {\"max_search_results\": max_search_results})\n\n    if max_prompt_file_tokens is not None:\n        state_params.setdefault(\r\n            IdentifyCode, {\"max_prompt_file_tokens\": max_prompt_file_tokens}\r\n        )\n\n    logger.info(state_params)\n\n    return TransitionRules(\r\n        global_params=global_params,\r\n        state_params=state_params,\r\n        initial_state=IdentifyCode,\r\n        transition_rules=[\r\n            TransitionRule(source=IdentifyCode, dest=Finished, trigger=\"search\"),\r\n            TransitionRule(source=IdentifyCode, dest=Finished, trigger=\"finish\"),\r\n        ],\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#264.33"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_search_and_code_transitions_search_and_code_transitions.return.TransitionRules_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 268, "span_ids": ["search_and_code_transitions"], "start_line": 184, "end_line": 212, "community": null}, "content": "def search_and_code_transitions(\r\n    max_tokens_in_edit_prompt: Optional[int] = 500,\r\n    global_params: Optional[dict] = None,\r\n    state_params: Optional[dict] = None,\r\n) -> TransitionRules:\n    state_params = state_params or {}\n    if max_tokens_in_edit_prompt is not None:\n        state_params.setdefault(\r\n            PlanToCode, {\"max_tokens_in_edit_prompt\": max_tokens_in_edit_prompt}\r\n        )\n    return TransitionRules(\r\n        global_params=global_params,\r\n        state_params=state_params,\r\n        transition_rules=[\r\n            TransitionRule(source=Pending, dest=SearchCode, trigger=\"init\"),\r\n            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger=\"did_search\"),\r\n            TransitionRule(source=SearchCode, dest=PlanToCode, trigger=\"finish\"),\r\n            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger=\"finish\"),\r\n            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(\r\n                source=DecideRelevance,\r\n                dest=PlanToCode,\r\n                trigger=\"finish\",\r\n                exclude_fields={\"message\"},\r\n            ),\r\n        ]\r\n        + CODE_TRANSITIONS,\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#265.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py_identify_and_code_transitions_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\transitions.py", "file_name": "transitions.py", "file_type": "text/x-python", "category": "test", "tokens": 310, "span_ids": ["identify_and_code_transitions"], "start_line": 215, "end_line": 258, "community": null}, "content": "def identify_and_code_transitions(\r\n    model: Optional[str] = None,\r\n    max_prompt_file_tokens: Optional[int] = 16000,\r\n    max_tokens_in_edit_prompt: Optional[int] = 500,\r\n    max_search_results: Optional[int] = 100,\r\n    global_params: Optional[dict] = None,\r\n    state_params: Optional[dict] = None,\r\n) -> TransitionRules:\n    global_params = global_params or {}\n\n    if model is not None:\n        global_params[\"model\"] = model\n\n    if state_params is None:\n        state_params = {}\n\n    if max_search_results is not None:\n        state_params.setdefault(SearchCode, {\"max_search_results\": max_search_results})\n\n    if max_prompt_file_tokens is not None:\n        state_params.setdefault(\r\n            IdentifyCode, {\"max_prompt_file_tokens\": max_prompt_file_tokens}\r\n        )\n\n    if max_tokens_in_edit_prompt is not None:\n        state_params.setdefault(\r\n            PlanToCode,\r\n            {\r\n                \"max_prompt_file_tokens\": max_prompt_file_tokens,\r\n                \"max_tokens_in_edit_prompt\": max_tokens_in_edit_prompt,\r\n            },\r\n        )\n\n    return TransitionRules(\r\n        global_params=global_params,\r\n        state_params=state_params or {},\r\n        initial_state=IdentifyCode,\r\n        transition_rules=[\r\n            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger=\"search\"),\r\n            TransitionRule(source=IdentifyCode, dest=PlanToCode, trigger=\"finish\"),\r\n        ]\r\n        + CODE_TRANSITIONS,\r\n    )", "kind": "Chunk", "id": "moatless/transitions.py#266.43"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py_from_typing_import_Any_O_ActionRequest.action_name.return.self___class_____name__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py", "file_name": "types.py", "file_type": "text/x-python", "category": "test", "tokens": 162, "span_ids": ["FileWithSpans", "ActionRequest.action_name", "FileWithSpans.add_span_id", "FileWithSpans.add_span_ids", "imports", "ActionRequest"], "start_line": 1, "end_line": 28, "community": null}, "content": "from typing import Any, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass FileWithSpans(BaseModel):\n    file_path: str = Field(\r\n        description=\"The file path where the relevant code is found.\"\r\n    )\n    span_ids: list[str] = Field(\r\n        default_factory=list,\r\n        description=\"The span ids of the relevant code in the file\",\r\n    )\n\n    def add_span_id(self, span_id):\n        if span_id not in self.span_ids:\n            self.span_ids.append(span_id)\n\n    def add_span_ids(self, span_ids: list[str]):\n        for span_id in span_ids:\n            self.add_span_id(span_id)\n\nclass ActionRequest(BaseModel):\n    pass\n\n    @property\r\n    def action_name(self):\n        return self.__class__.__name__", "kind": "Chunk", "id": "moatless/types.py#267.27"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py_ActionResponse_ActionResponse.no_transition.return.cls_output_output_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py", "file_name": "types.py", "file_type": "text/x-python", "category": "test", "tokens": 188, "span_ids": ["ActionResponse.transition", "ActionResponse.retry", "ActionResponse.no_transition", "ActionResponse"], "start_line": 30, "end_line": 56, "community": null}, "content": "class ActionResponse(BaseModel):\n    trigger: Optional[str] = Field(\r\n        default=None,\r\n        description=\"Trigger to transition to the next state. If None, no transition is made.\",\r\n    )\n    output: Optional[dict[str, Any]] = Field(\r\n        default=None,\r\n        description=\"Output data to be passed to the next state.\",\r\n    )\n\n    retry_message: Optional[str] = Field(\r\n        default=None,\r\n        description=\"Message to use in retry.\"\r\n    )\n\n    @classmethod\r\n    def retry(cls, retry_message: str):\n        return cls(trigger=\"retry\", retry_message=retry_message)\n\n    @classmethod\r\n    def transition(cls, trigger: str, output: dict[str, Any] | None = None):\n        output = output or {}\n        return cls(trigger=trigger, output=output)\n\n    @classmethod\r\n    def no_transition(cls, output: dict[str, Any]):\n        return cls(output=output)", "kind": "Chunk", "id": "moatless/types.py#268.26"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py_Usage_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\types.py", "file_name": "types.py", "file_type": "text/x-python", "category": "test", "tokens": 385, "span_ids": ["Reject", "ActionTransaction.model_dump", "Message", "CodeChange", "AssistantMessage", "Response", "ActionTransaction", "Content", "Finish", "UserMessage", "Usage", "VerificationError", "EmptyRequest"], "start_line": 58, "end_line": 126, "community": null}, "content": "class Usage(BaseModel):\n    completion_cost: float\n    completion_tokens: int\n    prompt_tokens: int\n\n\nclass ActionTransaction(BaseModel):\n    request: ActionRequest\n    response: Optional[ActionResponse] = None\n    usage: Optional[Usage] = None\n\n    def model_dump(self, **kwargs):\n        data = super().model_dump(**kwargs)\n        data[\"request\"] = self.request.model_dump(**kwargs)\n        data[\"response\"] = self.response.model_dump(**kwargs) if self.response else None\n        return data\n\n\nclass EmptyRequest(ActionRequest):\n    pass\n\n\nclass Finish(ActionRequest):\n    thoughts: str = Field(..., description=\"The reason to finishing the request.\")\n\n\nclass Reject(ActionRequest):\n    thoughts: str = Field(..., description=\"The reason for rejecting the request.\")\n\n\nclass Content(ActionRequest):\n    content: str\n\n\nclass Message(BaseModel):\n    role: str\n    content: Optional[str] = None\n    action: Optional[ActionRequest] = Field(default=None)\n\n\nclass AssistantMessage(Message):\n    role: str = \"assistant\"\n    content: Optional[str] = None\n    action: Optional[ActionRequest] = Field(default=None)\n\n\nclass UserMessage(Message):\n    role: str = \"user\"\n    content: Optional[str] = None\n\n\nclass Response(BaseModel):\n    status: str\n    message: str\n    output: Optional[dict[str, Any]] = None\n\n\nclass VerificationError(BaseModel):\n    code: str\n    file_path: str\n    message: str\n    line: int\n\n\nclass CodeChange(BaseModel):\n    instructions: str = Field(..., description=\"Instructions to do the code change.\")\n    file_path: str = Field(..., description=\"The file path of the code to be updated.\")\n    span_id: str = Field(..., description=\"The span id of the code to be updated.\")", "kind": "Chunk", "id": "moatless/types.py#269.68"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\colors.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\colors.py", "file_name": "colors.py", "file_type": "text/x-python", "category": "test", "tokens": 87, "span_ids": ["Colors"], "start_line": 1, "end_line": 11, "community": null}, "content": "class Colors:\n    RED = \"\\033[91m\"\n    GREEN = \"\\033[92m\"\n    YELLOW = \"\\033[93m\"\n    BLUE = \"\\033[94m\"\n    MAGENTA = \"\\033[95m\"\n    CYAN = \"\\033[96m\"\n    WHITE = \"\\033[97m\"\n    GRAY = \"\\033[90m\"\n    RESET = \"\\033[0m\"", "kind": "Chunk", "id": "utils/colors.py#270.10"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\llm_utils.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\llm_utils.py", "file_name": "llm_utils.py", "file_type": "text/x-python", "category": "test", "tokens": 96, "span_ids": ["imports", "instructor_mode_by_model"], "start_line": 2, "end_line": 19, "community": null}, "content": "import instructor\n\n\ndef instructor_mode_by_model(model: str) -> instructor.Mode | None:\n    if \"gpt\" in model:\n        return instructor.Mode.TOOLS\n\n    if \"claude\" in model:\n        return instructor.Mode.TOOLS\n\n    if model.startswith(\"claude\"):\n        return instructor.Mode.ANTHROPIC_TOOLS\n\n    if model.startswith(\"openrouter/anthropic/claude\"):\n        return instructor.Mode.TOOLS\n\n    return instructor.Mode.JSON", "kind": "Chunk", "id": "utils/llm_utils.py#271.17"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py_logging_get_repo_dir_name.return.repo_replace___", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py", "file_name": "repo.py", "file_type": "text/x-python", "category": "test", "tokens": 166, "span_ids": ["imports", "setup_github_repo", "get_repo_dir_name"], "start_line": 1, "end_line": 24, "community": null}, "content": "import logging\nimport os\nimport subprocess\n\nlogger = logging.getLogger(__name__)\n\n\ndef setup_github_repo(repo: str, base_commit: str, base_dir: str = \"/tmp/repos\") -> str:\n    repo_name = get_repo_dir_name(repo)\n    repo_url = f\"https://github.com/{repo}.git\"\n    path = f\"{base_dir}/{repo_name}\"\n    logger.info(\r\n        f\"Clone Github repo {repo_url} to {path} and checkout commit {base_commit}\"\r\n    )\n    if not os.path.exists(path):\n        os.makedirs(path)\n        logger.info(f\"Directory '{path}' was created.\")\n    maybe_clone(repo_url, path)\n    checkout_commit(path, base_commit)\n    return path\n\n\ndef get_repo_dir_name(repo: str):\n    return repo.replace(\"/\", \"_\")", "kind": "Chunk", "id": "utils/repo.py#272.23"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py_maybe_clone_maybe_clone.if_not_os_path_exists_f_.if_result_returncode_0.else_.raise_ValueError_f_Failed", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py", "file_name": "repo.py", "file_type": "text/x-python", "category": "test", "tokens": 150, "span_ids": ["maybe_clone"], "start_line": 27, "end_line": 42, "community": null}, "content": "def maybe_clone(repo_url, repo_dir):\n    if not os.path.exists(f\"{repo_dir}/.git\"):\n        logger.info(f\"Cloning repo '{repo_url}'\")\n        # Clone the repo if the directory doesn't exist\r\n        result = subprocess.run(\r\n            [\"git\", \"clone\", repo_url, repo_dir],\r\n            check=True,\r\n            text=True,\r\n            capture_output=True,\r\n        )\n\n        if result.returncode == 0:\n            logger.info(f\"Repo '{repo_url}' was cloned to '{repo_dir}'\")\n        else:\n            logger.info(f\"Failed to clone repo '{repo_url}' to '{repo_dir}'\")\n            raise ValueError(f\"Failed to clone repo '{repo_url}' to '{repo_dir}'\")", "kind": "Chunk", "id": "utils/repo.py#273.15"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py_pull_latest_create_branch.try_.except_subprocess_CalledP.raise_e", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py", "file_name": "repo.py", "file_type": "text/x-python", "category": "test", "tokens": 182, "span_ids": ["clean_and_reset_state", "create_branch", "pull_latest"], "start_line": 45, "end_line": 83, "community": null}, "content": "def pull_latest(repo_dir):\n    subprocess.run(\r\n        [\"git\", \"pull\"],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n\n\ndef clean_and_reset_state(repo_dir):\n    subprocess.run(\r\n        [\"git\", \"clean\", \"-fd\"],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n    subprocess.run(\r\n        [\"git\", \"reset\", \"--hard\"],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n\n\ndef create_branch(repo_dir, branch_name):\n    try:\n        subprocess.run(\r\n            [\"git\", \"branch\", branch_name],\r\n            cwd=repo_dir,\r\n            check=True,\r\n            text=True,\r\n            capture_output=True,\r\n        )\n    except subprocess.CalledProcessError as e:\n        logger.error(e.stderr)\n        raise e", "kind": "Chunk", "id": "utils/repo.py#274.38"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py_create_and_checkout_branch_create_and_checkout_branch.try_.except_subprocess_CalledP.raise_e", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py", "file_name": "repo.py", "file_type": "text/x-python", "category": "test", "tokens": 167, "span_ids": ["create_and_checkout_branch"], "start_line": 86, "end_line": 114, "community": null}, "content": "def create_and_checkout_branch(repo_dir, branch_name):\n    try:\n        branches = subprocess.run(\r\n            [\"git\", \"branch\"],\r\n            cwd=repo_dir,\r\n            check=True,\r\n            text=True,\r\n            capture_output=True,\r\n        ).stdout.split(\"\\n\")\n        branches = [branch.strip() for branch in branches]\n        if branch_name in branches:\n            subprocess.run(\r\n                [\"git\", \"checkout\", branch_name],\r\n                cwd=repo_dir,\r\n                check=True,\r\n                text=True,\r\n                capture_output=True,\r\n            )\n        else:\n            subprocess.run(\r\n                [\"git\", \"checkout\", \"-b\", branch_name],\r\n                cwd=repo_dir,\r\n                check=True,\r\n                text=True,\r\n                capture_output=True,\r\n            )\n    except subprocess.CalledProcessError as e:\n        logger.error(e.stderr)\n        raise e", "kind": "Chunk", "id": "utils/repo.py#275.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py_commit_changes_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\repo.py", "file_name": "repo.py", "file_type": "text/x-python", "category": "test", "tokens": 455, "span_ids": ["commit_changes", "create_and_checkout_new_branch", "setup_repo", "stage_all_files", "clean_and_reset_repo", "push_branch", "get_diff", "checkout_commit", "checkout_branch"], "start_line": 117, "end_line": 200, "community": null}, "content": "def commit_changes(repo_dir, commit_message):\n    subprocess.run(\r\n        [\"git\", \"commit\", \"-m\", commit_message, \"--no-verify\"],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n\n\ndef checkout_branch(repo_dir, branch_name):\n    subprocess.run(\r\n        [\"git\", \"checkout\", branch_name],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n\n\ndef push_branch(repo_dir, branch_name):\n    subprocess.run(\r\n        [\"git\", \"push\", \"origin\", branch_name, \"--no-verify\"],\r\n        cwd=repo_dir,\r\n        check=True,\r\n        text=True,\r\n        capture_output=True,\r\n    )\n\n\ndef get_diff(repo_dir):\n    output = subprocess.run(\r\n        [\"git\", \"diff\"], cwd=repo_dir, check=True, text=True, capture_output=True\r\n    )\n\n    return output.stdout\n\n\ndef stage_all_files(repo_dir):\n    subprocess.run(\r\n        [\"git\", \"add\", \".\"], cwd=repo_dir, check=True, text=True, capture_output=True\r\n    )\n\n\ndef checkout_commit(repo_dir, commit_hash):\n    try:\n        subprocess.run(\r\n            [\"git\", \"reset\", \"--hard\", commit_hash],\r\n            cwd=repo_dir,\r\n            check=True,\r\n            text=True,\r\n            capture_output=True,\r\n        )\n    except subprocess.CalledProcessError as e:\n        logger.error(e.stderr)\n        raise e\n\n\ndef create_and_checkout_new_branch(repo_dir: str, branch_name: str):\n    try:\n        subprocess.run(\r\n            [\"git\", \"checkout\", \"-b\", branch_name],\r\n            cwd=repo_dir,\r\n            check=True,\r\n            text=True,\r\n            capture_output=True,\r\n        )\n    except subprocess.CalledProcessError as e:\n        logger.error(e.stderr)\n        raise e\n\n\ndef setup_repo(repo_url, repo_dir, branch_name=\"master\"):\n    maybe_clone(repo_url, repo_dir)\n    clean_and_reset_state(repo_dir)\n    checkout_branch(repo_dir, branch_name)\n    pull_latest(repo_dir)\n\n\ndef clean_and_reset_repo(repo_dir, branch_name=\"master\"):\n    clean_and_reset_state(repo_dir)\n    checkout_branch(repo_dir, branch_name)\n    pull_latest(repo_dir)", "kind": "Chunk", "id": "utils/repo.py#276.83"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\tokenizer.py_os_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\tokenizer.py", "file_name": "tokenizer.py", "file_type": "text/x-python", "category": "test", "tokens": 315, "span_ids": ["imports", "count_tokens"], "start_line": 1, "end_line": 49, "community": null}, "content": "import os\n\n_enc = None\n\n_voyageai = None\n\n\ndef count_tokens(content: str, model: str = \"gpt-3.5-turbo\") -> int:\n    global _enc, _voyageai\n\n    if model.startswith(\"voyage\"):\n        if _voyageai is None:\n            voyageai_import_err = (\r\n                \"`voyageai` package not found, please run `pip install voyageai`\"\r\n            )\n            try:\n                import voyageai\n            except ImportError as e:\n                raise ImportError(voyageai_import_err) from e\n\n            _voyageai = voyageai.Client()\n\n        return _voyageai.count_tokens([content])\n\n    if _enc is None:\n        tiktoken_import_err = (\r\n            \"`tiktoken` package not found, please run `pip install tiktoken`\"\r\n        )\n        try:\n            import tiktoken\n        except ImportError as e:\n            raise ImportError(tiktoken_import_err) from e\n\n        # set tokenizer cache temporarily\r\n        should_revert = False\n        if \"TIKTOKEN_CACHE_DIR\" not in os.environ:\n            should_revert = True\n            os.environ[\"TIKTOKEN_CACHE_DIR\"] = os.path.join(\r\n                os.path.dirname(os.path.abspath(__file__)),\r\n                \"_static/tiktoken_cache\",\r\n            )\n\n        _enc = tiktoken.encoding_for_model(model)\n\n        if should_revert:\n            del os.environ[\"TIKTOKEN_CACHE_DIR\"]\n\n    return len(_enc.encode(content, allowed_special=\"all\"))", "kind": "Chunk", "id": "utils/tokenizer.py#277.48"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\xml.py_re_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\utils\\xml.py", "file_name": "xml.py", "file_type": "text/x-python", "category": "test", "tokens": 148, "span_ids": ["extract_between_tags", "imports", "contains_tag"], "start_line": 1, "end_line": 17, "community": null}, "content": "import re\n\n\ndef extract_between_tags(tag: str, string: str, strip: bool = False) -> list[str]:\n    ext_list = re.findall(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL)\n    if strip:\n        ext_list = [e.strip() for e in ext_list]\n    return ext_list\n\n\ndef contains_tag(tag: str, string: str) -> bool:\n    return bool(re.search(f\"<{tag}>\", string, re.DOTALL))\n\n\n# def contains_tag(tag: str, string: str) -> bool:\r\n#    return bool(re.search(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL))\r", "kind": "Chunk", "id": "utils/xml.py#278.16"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\lint.py_logging_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\lint.py", "file_name": "lint.py", "file_type": "text/x-python", "category": "test", "tokens": 297, "span_ids": ["PylintVerifier", "imports", "PylintVerifier.__init__", "PylintVerifier.verify"], "start_line": 1, "end_line": 48, "community": null}, "content": "import logging\n\nfrom astroid import MANAGER\nfrom pylint.lint import Run\nfrom pylint.testutils import MinimalTestReporter\n\nfrom moatless.repository import CodeFile\nfrom moatless.types import VerificationError\nfrom moatless.verify.verify import Verifier\n\nlogger = logging.getLogger(__name__)\n\n\nclass PylintVerifier(Verifier):\n    def __init__(self, repo_dir: str, run_tests: bool = True):\n        self.repo_dir = repo_dir\n        self.run_tests = run_tests\n\n    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:\n        if not file:\n            logger.warning(\"No file to verify\")\n            return []\n\n        try:\n            MANAGER.astroid_cache.clear()\n            results = Run(\r\n                [f\"{self.repo_dir}/{file.file_path}\"],\r\n                exit=False,\r\n                reporter=MinimalTestReporter(),\r\n            )\n\n            for msg in results.linter.reporter.messages:\n                logger.debug(f\"Message: {msg.msg_id} {msg.msg} {msg.line}\")\n\n            return [\r\n                VerificationError(\r\n                    code=msg.msg_id,\r\n                    file_path=msg.path.replace(f\"{self.repo_dir}/\", \"\"),\r\n                    message=msg.msg,\r\n                    line=msg.line,\r\n                )\r\n                for msg in results.linter.reporter.messages\r\n                if msg.msg_id[0] in [\"E\", \"F\"]\r\n            ]\n        except Exception:\n            logger.exception(\"Error running pylint\")\n            return []", "kind": "Chunk", "id": "verify/lint.py#279.47"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py_logging_MavenVerifier.verify.try_.except_subprocess_CalledP.logger_warning_e_stderr_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py", "file_name": "maven.py", "file_type": "text/x-python", "category": "test", "tokens": 385, "span_ids": ["MavenVerifier.verify", "imports", "MavenVerifier", "MavenVerifier.__init__"], "start_line": 1, "end_line": 58, "community": null}, "content": "import logging\nimport os\nimport re\nimport subprocess\n\nfrom moatless.repository import CodeFile\nfrom moatless.types import VerificationError\nfrom moatless.verify.verify import Verifier\n\nlogger = logging.getLogger(__name__)\n\n\nclass MavenVerifier(Verifier):\n    def __init__(self, repo_dir: str, run_tests: bool = True):\n        self.repo_dir = repo_dir\n        self.run_tests = run_tests\n\n    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:\n        try:\n            # os.environ[\"JAVA_HOME\"] = \"/home/albert/.sdkman/candidates/java/17.0.8-tem\"\r\n\n            version = \"21-tem\"\n\n            sdkman_cmd = (\r\n                f\"source $HOME/.sdkman/bin/sdkman-init.sh && sdk use java {version}\"\r\n            )\n\n            if self.run_tests:\n                mvn_cmd = \"./mvnw clean test\"\n            else:\n                mvn_cmd = \"./mvnw clean compile test-compile\"\n\n            logger.info(\r\n                f\"Running Maven command: {mvn_cmd} with Java version {version} in {self.repo_dir}\"\r\n            )\n            result = subprocess.run(\r\n                f\"{sdkman_cmd} && {mvn_cmd}\",\r\n                cwd=self.repo_dir,\r\n                check=False,\r\n                text=True,\r\n                shell=True,\r\n                capture_output=True,\r\n            )\n\n            stdout = result.stdout\n            stderr = result.stderr\n\n            combined_output = stdout + \"\\n\" + stderr\n            compilation_errors = self.parse_compilation_errors(combined_output)\n            if compilation_errors or not self.run_tests:\n                return compilation_errors\n\n            test_failures = self.parse_test_failures(combined_output)\n            return test_failures\n\n        except subprocess.CalledProcessError as e:\n            logger.warning(\"Error running Maven command:\")\n            logger.warning(e.stderr)", "kind": "Chunk", "id": "verify/maven.py#280.57"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py_MavenVerifier.parse_compilation_errors_MavenVerifier.parse_compilation_errors.return.errors", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py", "file_name": "maven.py", "file_type": "text/x-python", "category": "test", "tokens": 138, "span_ids": ["MavenVerifier.parse_compilation_errors"], "start_line": 60, "end_line": 76, "community": null}, "content": "class MavenVerifier(Verifier):\n\n    def parse_compilation_errors(self, output: str) -> list[VerificationError]:\n        error_pattern = re.compile(r\"\\[ERROR\\] (.*?):\\[(\\d+),(\\d+)\\] (.*)\")\n        matches = error_pattern.findall(output)\n\n        errors = []\n        for match in matches:\n            file_path, line, column, message = match\n\n            file_path = file_path.replace(f\"{self.repo_dir}/\", \"\")\n            error = VerificationError(\r\n                code=\"COMPILATION_ERROR\",\r\n                file_path=file_path.strip(),\r\n                message=message.strip(),\r\n                line=int(line),\r\n            )\n            errors.append(error)\n        return errors", "kind": "Chunk", "id": "verify/maven.py#281.16"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py_MavenVerifier.find_file_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\maven.py", "file_name": "maven.py", "file_type": "text/x-python", "category": "test", "tokens": 206, "span_ids": ["MavenVerifier.parse_test_failures", "MavenVerifier.find_file"], "start_line": 78, "end_line": 106, "community": null}, "content": "class MavenVerifier(Verifier):\n\n    def find_file(self, class_name: str) -> str:\n        for root, _, files in os.walk(self.repo_dir):\n            for file in files:\n                if file == f\"{class_name}.java\":\n                    absolute_path = os.path.join(root, file)\n                    return os.path.relpath(absolute_path, self.repo_dir)\n        return \"\"\n\n    def parse_test_failures(self, output: str) -> list[VerificationError]:\n        failure_pattern = re.compile(r\"\\[ERROR\\]   (.*?):(\\d+) (.*)\")\n        matches = failure_pattern.findall(output)\n\n        errors = []\n        for match in matches:\n            test_case, line, message = match\n\n            class_name = test_case.split(\".\")[0]\n\n            file_path = self.find_file(class_name)\n\n            error = VerificationError(\r\n                code=\"TEST_FAILURE\",\r\n                file_path=file_path.strip(),\r\n                message=message.strip(),\r\n                line=int(line),\r\n            )\n            errors.append(error)\n        return errors", "kind": "Chunk", "id": "verify/maven.py#282.28"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\verify.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\verify\\verify.py", "file_name": "verify.py", "file_type": "text/x-python", "category": "test", "tokens": 58, "span_ids": ["imports", "Verifier.verify", "Verifier"], "start_line": 1, "end_line": 11, "community": null}, "content": "from abc import ABC, abstractmethod\n\nfrom moatless.repository import CodeFile\nfrom moatless.types import VerificationError\n\n\nclass Verifier(ABC):\n    @abstractmethod\r\n    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:\n        pass", "kind": "Chunk", "id": "verify/verify.py#283.10"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py_logging_logger.logging_getLogger___name_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py", "file_name": "workspace.py", "file_type": "text/x-python", "category": "test", "tokens": 118, "span_ids": ["imports"], "start_line": 1, "end_line": 15, "community": null}, "content": "import logging\nfrom typing import Any, Optional, Dict\n\nfrom moatless.codeblocks.parser.python import PythonParser\nfrom moatless.file_context import FileContext\nfrom moatless.index import IndexSettings\nfrom moatless.index.code_index import CodeIndex\nfrom moatless.repository import CodeFile, FileRepository, GitRepository\nfrom moatless.types import FileWithSpans, VerificationError\nfrom moatless.verify.lint import PylintVerifier\nfrom moatless.verify.maven import MavenVerifier\n\n_parser = PythonParser()\n\nlogger = logging.getLogger(__name__)", "kind": "Chunk", "id": "moatless/workspace.py#284.14"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py_Workspace_Workspace.__init__.if_file_context_.else_.self._file_context.self_create_file_context_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py", "file_name": "workspace.py", "file_type": "text/x-python", "category": "test", "tokens": 321, "span_ids": ["Workspace", "Workspace.__init__"], "start_line": 18, "end_line": 64, "community": null}, "content": "class Workspace:\n    def __init__(\r\n        self,\r\n        file_repo: FileRepository,\r\n        index_dir: Optional[str] = None,\r\n        index_settings: IndexSettings | None = None,\r\n        max_results: int = 25,\r\n        code_index: CodeIndex | None = None,\r\n        verification_job: Optional[str] = \"pylint\",\r\n        max_file_context_tokens: int = 4000,\r\n        file_context: FileContext | None = None,\r\n    ):\n        self.file_repo = file_repo\n\n        if code_index:\n            self.code_index = code_index\n        elif index_dir:\n            try:\n                self.code_index = CodeIndex.from_persist_dir(\r\n                    index_dir, file_repo=file_repo, max_results=max_results\r\n                )\n            except FileNotFoundError:\n                logger.info(\"No index found. Creating a new index.\")\n                code_index = CodeIndex(\r\n                    file_repo=file_repo,\r\n                    settings=index_settings,\r\n                    max_results=max_results,\r\n                )\n                code_index.run_ingestion()\n                code_index.persist(index_dir)\n                self.code_index = code_index\n        else:\n            self.code_index = None\n\n        if verification_job == \"maven\":\n            self.verifier = MavenVerifier(self.file_repo.path)\n        elif verification_job == \"pylint\":\n            self.verifier = PylintVerifier(self.file_repo.path)\n        else:\n            self.verifier = None\n\n        if file_context:\n            self._file_context = file_context\n        else:\n            self._file_context = self.create_file_context(\r\n                max_tokens=max_file_context_tokens\r\n            )", "kind": "Chunk", "id": "moatless/workspace.py#285.46"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py_Workspace.from_dirs_Workspace.from_dirs.return.cls_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py", "file_name": "workspace.py", "file_type": "text/x-python", "category": "test", "tokens": 157, "span_ids": ["Workspace.from_dirs"], "start_line": 66, "end_line": 88, "community": null}, "content": "class Workspace:\n\n    @classmethod\r\n    def from_dirs(\r\n        cls,\r\n        git_repo_url: Optional[str] = None,\r\n        commit: Optional[str] = None,\r\n        repo_path: Optional[str] = None,\r\n        max_file_context_tokens: int = 4000,\r\n        **kwargs,\r\n    ):\n        if git_repo_url:\n            file_repo = GitRepository.from_repo(\r\n                git_repo_url=git_repo_url, repo_path=repo_path, commit=commit\r\n            )\n        elif repo_path:\n            file_repo = FileRepository(repo_path)\n        else:\n            raise ValueError(\"Either git_repo_url or repo_dir must be provided.\")\n\n        return cls(\r\n            file_repo=file_repo,\r\n            max_file_context_tokens=max_file_context_tokens,\r\n            **kwargs,\r\n        )", "kind": "Chunk", "id": "moatless/workspace.py#286.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py_Workspace.from_dict_Workspace.from_dict.return.cls_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py", "file_name": "workspace.py", "file_type": "text/x-python", "category": "test", "tokens": 264, "span_ids": ["Workspace.from_dict"], "start_line": 90, "end_line": 123, "community": null}, "content": "class Workspace:\n\n    @classmethod\r\n    def from_dict(cls, data: dict, **kwargs):\n        if \"repository\" not in data:\n            raise ValueError(\"Missing repository key\")\n\n        if data[\"repository\"].get(\"git_repo_url\"):\n            file_repo = GitRepository.from_repo(\r\n                git_repo_url=data[\"repository\"].get(\"git_repo_url\"),\r\n                repo_path=data[\"repository\"].get(\"repo_path\"),\r\n                commit=data[\"repository\"].get(\"commit\"),\r\n            )\n        elif data[\"repository\"].get(\"repo_path\"):\n            file_repo = FileRepository(data[\"repository\"].get(\"repo_path\"))\n        else:\n            raise ValueError(\"Either git_repo_url or repo_dir must be provided.\")\n\n        file_context = FileContext(\r\n            repo=file_repo, max_tokens=data[\"file_context\"].get(\"max_tokens\")\r\n        )\n        file_context.load_files_from_dict(data[\"file_context\"].get(\"files\", []))\n\n        if data.get(\"code_index\", {}).get(\"index_name\"):\n            code_index = CodeIndex.from_index_name(\r\n                data[\"code_index\"].get(\"index_name\"), file_repo=file_repo\r\n            )\n        else:\n            code_index = None\n\n        return cls(\r\n            file_repo=file_repo,\r\n            file_context=file_context,\r\n            code_index=code_index,\r\n            **kwargs,\r\n        )", "kind": "Chunk", "id": "moatless/workspace.py#287.33"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py_Workspace.restore_from_snapshot_Workspace.verify.return._", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\moatless\\workspace.py", "file_name": "workspace.py", "file_type": "text/x-python", "category": "test", "tokens": 329, "span_ids": ["Workspace.file_context", "Workspace.get_file", "Workspace.restore_from_snapshot", "Workspace.create_file_context", "Workspace.save", "Workspace.snapshot", "Workspace.dict", "Workspace.verify"], "start_line": 125, "end_line": 171, "community": null}, "content": "class Workspace:\n\n    def restore_from_snapshot(self, snapshot: dict):\n        self.file_repo.restore_from_snapshot(snapshot[\"repository\"])\n        self._file_context.restore_from_snapshot(snapshot[\"file_context\"])\n\n    def dict(self):\n        return {\r\n            \"repository\": self.file_repo.dict(),\r\n            \"file_context\": self.file_context.model_dump(\r\n                exclude_none=True, exclude_unset=True\r\n            ),\r\n            \"code_index\": self.code_index.dict() if self.code_index else None,\r\n        }\n\n    def snapshot(self) -> Dict[str, Any]:\n        return {\r\n            \"repository\": self.file_repo.snapshot(),\r\n            \"file_context\": self.file_context.snapshot(),\r\n        }\n\n    def create_file_context(\r\n        self,\r\n        files_with_spans: list[FileWithSpans] | None = None,\r\n        max_tokens: int = 4000,\r\n    ):\n        file_context = FileContext(self.file_repo, max_tokens=max_tokens)\n        if files_with_spans:\n            file_context.add_files_with_spans(files_with_spans)\n        return file_context\n\n    @property\r\n    def file_context(self):\n        return self._file_context\n\n    def get_file(self, file_path, refresh: bool = False, from_origin: bool = False):\n        return self.file_repo.get_file(\r\n            file_path, refresh=refresh, from_origin=from_origin\r\n        )\n\n    def save(self):\n        self.file_repo.save()\n\n    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:\n        if self.verifier:\n            return self.verifier.verify(file)\n\n        logger.info(\"No verifier configured.\")\n        return []", "kind": "Chunk", "id": "moatless/workspace.py#288.46"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\conftest.py_logging_pytest_addoption.None_4", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\conftest.py", "file_name": "conftest.py", "file_type": "text/x-python", "category": "test", "tokens": 233, "span_ids": ["imports", "pytest_addoption"], "start_line": 1, "end_line": 40, "community": null}, "content": "import logging\nimport os\nfrom dotenv import load_dotenv\nimport pytest\n\nload_dotenv()\nlogger = logging.getLogger(__name__)\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\r\n        \"--index-store-dir\",\r\n        action=\"store\",\r\n        default=os.getenv(\"INDEX_STORE_DIR\", \"/tmp/index-store\"),\r\n        help=\"Path for INDEX_STORE_DIR\",\r\n    )\n    parser.addoption(\r\n        \"--repo-dir\",\r\n        action=\"store\",\r\n        default=os.getenv(\"REPO_DIR\", \"/tmp/repo\"),\r\n        help=\"Path for REPO_DIR\",\r\n    )\n    parser.addoption(\r\n        \"--moatless-dir\",\r\n        action=\"store\",\r\n        default=os.getenv(\"MOATLESS_DIR\", \"/tmp/moatless\"),\r\n        help=\"Path for MOATLESS_DIR\",\r\n    )\n    parser.addoption(\r\n        \"--run-llm-integration\",\r\n        action=\"store_true\",\r\n        default=False,\r\n        help=\"run integration tests that call LLMs\",\r\n    )\n    parser.addoption(\r\n        \"--run-with-index\",\r\n        action=\"store_true\",\r\n        default=False,\r\n        help=\"run tests that need vector store index files\",\r\n    )", "kind": "Chunk", "id": "tests/conftest.py#315.39"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\conftest.py_set_env_vars_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\conftest.py", "file_name": "conftest.py", "file_type": "text/x-python", "category": "test", "tokens": 198, "span_ids": ["set_env_vars"], "start_line": 43, "end_line": 65, "community": null}, "content": "@pytest.fixture(autouse=True)\r\ndef set_env_vars(monkeypatch, request):\n    index_store_dir = request.config.getoption(\"--index-store-dir\")\n    repo_dir = request.config.getoption(\"--repo-dir\")\n    moatless_dir = request.config.getoption(\"--moatless-dir\")\n\n    logger.debug(f\"Setting INDEX_STORE_DIR={index_store_dir}\")\n    logger.debug(f\"Setting REPO_DIR={repo_dir}\")\n    logger.debug(f\"Setting MOATLESS_DIR={moatless_dir}\")\n\n    if not os.path.exists(index_store_dir):\n        os.makedirs(index_store_dir)\n\n    if not os.path.exists(repo_dir):\n        os.makedirs(repo_dir)\n\n    if not os.path.exists(moatless_dir):\n        os.makedirs(moatless_dir)\n\n    monkeypatch.setenv(\"INDEX_STORE_DIR\", index_store_dir)\n    monkeypatch.setenv(\"REPO_DIR\", repo_dir)\n    monkeypatch.setenv(\"MOATLESS_DIR\", moatless_dir)", "kind": "Chunk", "id": "tests/conftest.py#316.22"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py_os_pytest.mark.llm_integration.pytest_mark_skipif_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py", "file_name": "integration_test.py", "file_type": "text/x-python", "category": "test", "tokens": 228, "span_ids": ["imports"], "start_line": 1, "end_line": 31, "community": null}, "content": "import os\nfrom datetime import datetime\n\nimport litellm\nimport pytest\nfrom dotenv import load_dotenv\n\nfrom moatless import AgenticLoop\nfrom moatless.benchmark.swebench import load_instance, create_workspace\nfrom moatless.benchmark.utils import trace_metadata\nfrom moatless.edit import EditCode\nfrom moatless.transitions import (\r\n    search_transitions,\r\n    code_transitions,\r\n    search_and_code_transitions,\r\n)\n\nload_dotenv()\nmoatless_dir = os.getenv(\"MOATLESS_DIR\", \"/tmp/moatless\")\n\nglobal_params = {\r\n    \"model\": \"gpt-4o-mini-2024-07-18\",  # \"azure/gpt-4o\",\r\n    \"temperature\": 0.5,\r\n    \"max_tokens\": 2000,\r\n    \"max_prompt_file_tokens\": 8000,\r\n}\n\npytest.mark.llm_integration = pytest.mark.skipif(\r\n    \"not config.getoption('--run-llm-integration')\",\r\n    reason=\"need --run-llm-integration option to run tests that call LLMs\",\r\n)", "kind": "Chunk", "id": "tests/integration_test.py#342.30"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py_test_run_and_reload_django_16379_test_run_and_reload_django_16379.None_4", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py", "file_name": "integration_test.py", "file_type": "text/x-python", "category": "test", "tokens": 286, "span_ids": ["test_run_and_reload_django_16379"], "start_line": 34, "end_line": 73, "community": null}, "content": "@pytest.mark.llm_integration\r\ndef test_run_and_reload_django_16379():\n    instance = load_instance(\"django__django-16379\")\n    workspace = create_workspace(instance)\n\n    datestr = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    dir = f\"{moatless_dir}/{datestr}_test_django_16379_search_for_small_change\"\n    trajectory_path = f\"{dir}/trajectory.json\"\n\n    loop = AgenticLoop(\r\n        search_and_code_transitions(global_params=global_params),\r\n        workspace=workspace,\r\n        trajectory_path=trajectory_path,\r\n        prompt_log_dir=dir,\r\n    )\n\n    response = loop.run(message=instance[\"problem_statement\"])\n    print(\"Response\")\n    print(response)\n\n    diff = loop.workspace.file_repo.diff()\n    print(\"Diff\")\n    print(diff)\n\n    assert workspace.file_context.has_span(\r\n        \"django/core/cache/backends/filebased.py\", \"FileBasedCache.has_key\"\r\n    )\n\n    saved_loop = AgenticLoop.from_trajectory_file(trajectory_path=trajectory_path)\n\n    saved_response = saved_loop.run(message=instance[\"problem_statement\"])\n\n    assert saved_response.status == response.status\n    assert saved_response.message == response.message\n\n    assert saved_loop.workspace.file_context.has_span(\r\n        \"django/core/cache/backends/filebased.py\", \"FileBasedCache.has_key\"\r\n    )\n\n    assert saved_loop.workspace.file_repo.diff() == diff", "kind": "Chunk", "id": "tests/integration_test.py#343.39"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py_test_different_edit_models_", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\integration_test.py", "file_name": "integration_test.py", "file_type": "text/x-python", "category": "test", "tokens": 415, "span_ids": ["test_different_edit_models"], "start_line": 76, "end_line": 141, "community": null}, "content": "@pytest.mark.llm_integration\r\ndef test_different_edit_models():\n    instance = load_instance(\"django__django-16379\")\n    workspace = create_workspace(instance)\n\n    datestr = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    dir = f\"{moatless_dir}/{datestr}_test_django_16379_search_for_small_change\"\n    trajectory_path = f\"{dir}/trajectory.json\"\n\n    metadata = trace_metadata(\r\n        instance_id=instance[\"instance_id\"],\r\n        session_id=\"integration_test\",\r\n        trace_name=\"search\",\r\n    )\n\n    state_params = {\r\n        EditCode: {\r\n            \"model\": \"gpt-4o-2024-05-13\",\r\n        }\r\n    }\n\n    loop = AgenticLoop(\r\n        search_and_code_transitions(\r\n            global_params=global_params, state_params=state_params\r\n        ),\r\n        workspace=workspace,\r\n        trajectory_path=trajectory_path,\r\n        prompt_log_dir=dir,\r\n        metadata=metadata,\r\n    )\n\n    response = loop.run(message=instance[\"problem_statement\"])\n\n    print(\"Response\")\n    print(response)\n\n    diff = loop.workspace.file_repo.diff()\n    print(\"Diff\")\n    print(diff)\n\n    assert workspace.file_context.has_span(\r\n        \"django/core/cache/backends/filebased.py\", \"FileBasedCache.has_key\"\r\n    )\n\n    first_commit = loop.workspace.file_repo._current_commit\n    assert first_commit != loop.workspace.file_repo._initial_commit\n\n    # Reverts to PlanToCode state and set LLM to GPT-4o-mini in the EditCode state\r\n    response_mini = loop.retry_from_transition(\r\n        transition_id=4,  # PlanToCode\r\n        state_params={\r\n            EditCode: {\r\n                \"model\": \"gpt-4o-mini-2024-07-18\",\r\n            }\r\n        },\r\n    )\n\n    print(\"Response\")\n    print(response_mini)\n\n    diff = loop.workspace.file_repo.diff()\n    print(\"Diff\")\n    print(diff)\n\n    assert loop.workspace.file_repo._current_commit != first_commit", "kind": "Chunk", "id": "tests/integration_test.py#344.65"}, {"og_id": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\utils.py__", "metadata": {"file_path": "C:\\Users\\jpeng\\Documents\\projects\\test_rtfs\\tests\\repos\\moatless-tools\\tests\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "category": "test", "tokens": 83, "span_ids": ["imports", "create_loop"], "start_line": 1, "end_line": 13, "community": null}, "content": "from moatless import Transitions, AgenticLoop\nfrom moatless.benchmark.swebench import create_workspace\n\n\ndef create_loop(transitions: Transitions, instance: dict):\n    workspace = create_workspace(instance)\n    trajectory_path = f\"search_{instance['name']}.json\"\n    return AgenticLoop(\r\n        transitions,\r\n        workspace=workspace,\r\n        trajectory_path=trajectory_path,\r\n    )", "kind": "Chunk", "id": "tests/utils.py#364.12"}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 1}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 12}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 5}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 7}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 11}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 14}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 22}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 10}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 18}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 9}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 8}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 2}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 6}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 16}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 17}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 20}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 3}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 4}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 23}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 27}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 24}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 21}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 13}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 25}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 15}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 26}, {"kind": "Cluster", "title": "", "summary": "", "key_variables": [], "id": 19}], "links": [{"kind": "CallTo", "ref": "search_and_code_transitions", "source": "benchmark/claude_evaluation.py#2.65", "target": "moatless/transitions.py#265.28"}, {"kind": "ImportFrom", "ref": "search_and_code_transitions", "source": "benchmark/claude_evaluation.py#2.65", "target": "moatless/transitions.py#265.28"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#2.65", "target": 1}, {"kind": "ImportFrom", "ref": "search_and_code_transitions", "source": "benchmark/claude_evaluation.py#4.33", "target": "moatless/transitions.py#265.28"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#4.33", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#5.26", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#5.26", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#5.26", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#5.26", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "Finished", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "benchmark/claude_evaluation.py#5.26", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "create_evaluation_name", "source": "benchmark/claude_evaluation.py#5.26", "target": "benchmark/evaluation.py#21.88"}, {"kind": "CallTo", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#5.26", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ImportFrom", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#5.26", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#5.26", "target": 1}, {"kind": "CallTo", "ref": "search_transitions", "source": "benchmark/claude_evaluation.py#6.27", "target": "moatless/transitions.py#263.42"}, {"kind": "ImportFrom", "ref": "search_transitions", "source": "benchmark/claude_evaluation.py#6.27", "target": "moatless/transitions.py#263.42"}, {"kind": "ImportFrom", "ref": "create_evaluation_name", "source": "benchmark/claude_evaluation.py#6.27", "target": "benchmark/evaluation.py#21.88"}, {"kind": "CallTo", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#6.27", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ImportFrom", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#6.27", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#6.27", "target": 12}, {"kind": "ImportFrom", "ref": "create_evaluation_name", "source": "benchmark/claude_evaluation.py#7.27", "target": "benchmark/evaluation.py#21.88"}, {"kind": "CallTo", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#7.27", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ImportFrom", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#7.27", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#7.27", "target": 12}, {"kind": "ImportFrom", "ref": "create_evaluation_name", "source": "benchmark/claude_evaluation.py#8.18", "target": "benchmark/evaluation.py#21.88"}, {"kind": "CallTo", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#8.18", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ImportFrom", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#8.18", "target": "benchmark/evaluation.py#14.65"}, {"kind": "CallTo", "ref": "code_transitions", "source": "benchmark/claude_evaluation.py#8.18", "target": "moatless/transitions.py#260.20"}, {"kind": "ImportFrom", "ref": "code_transitions", "source": "benchmark/claude_evaluation.py#8.18", "target": "moatless/transitions.py#260.20"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#8.18", "target": 12}, {"kind": "CallTo", "ref": "TransitionRules", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "benchmark/claude_evaluation.py#9.56", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "benchmark/claude_evaluation.py#9.56", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "Finished", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Rejected", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "benchmark/claude_evaluation.py#9.56", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "create_evaluation_name", "source": "benchmark/claude_evaluation.py#9.56", "target": "benchmark/evaluation.py#21.88"}, {"kind": "CallTo", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#9.56", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ImportFrom", "ref": "Evaluation", "source": "benchmark/claude_evaluation.py#9.56", "target": "benchmark/evaluation.py#14.65"}, {"kind": "ChunkToCluster", "source": "benchmark/claude_evaluation.py#9.56", "target": 1}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "benchmark/create_dataset.py#12.117", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "get_file_spans_from_patch", "source": "benchmark/create_dataset.py#12.117", "target": "benchmark/utils.py#39.19"}, {"kind": "ImportFrom", "ref": "get_file_spans_from_patch", "source": "benchmark/create_dataset.py#12.117", "target": "benchmark/utils.py#39.19"}, {"kind": "ChunkToCluster", "source": "benchmark/create_dataset.py#12.117", "target": 5}, {"kind": "CallTo", "ref": "TransitionRules", "source": "benchmark/evaluation.py#14.65", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "benchmark/evaluation.py#14.65", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ChunkToCluster", "source": "benchmark/evaluation.py#14.65", "target": 12}, {"kind": "CallTo", "ref": "Trajectory", "source": "benchmark/evaluation.py#17.85", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "benchmark/evaluation.py#17.85", "target": "moatless/trajectory.py#248.23"}, {"kind": "CallTo", "ref": "Trajectory", "source": "benchmark/evaluation.py#17.85", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "benchmark/evaluation.py#17.85", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Workspace", "source": "benchmark/evaluation.py#17.85", "target": "moatless/workspace.py#285.46"}, {"kind": "ImportFrom", "ref": "trace_metadata", "source": "benchmark/evaluation.py#17.85", "target": "benchmark/utils.py#43.23"}, {"kind": "CallTo", "ref": "AgenticLoop", "source": "benchmark/evaluation.py#17.85", "target": "moatless/loop.py#219.112"}, {"kind": "ImportFrom", "ref": "AgenticLoop", "source": "benchmark/evaluation.py#17.85", "target": "moatless/loop.py#219.112"}, {"kind": "CallTo", "ref": "GitRepository", "source": "benchmark/evaluation.py#17.85", "target": "repository/git.py#238.98"}, {"kind": "ImportFrom", "ref": "GitRepository", "source": "benchmark/evaluation.py#17.85", "target": "repository/git.py#238.98"}, {"kind": "ChunkToCluster", "source": "benchmark/evaluation.py#17.85", "target": 7}, {"kind": "CallTo", "ref": "to_result", "source": "benchmark/evaluation.py#18.21", "target": "benchmark/report_v2.py#26.229"}, {"kind": "ImportFrom", "ref": "to_result", "source": "benchmark/evaluation.py#18.21", "target": "benchmark/report_v2.py#26.229"}, {"kind": "ChunkToCluster", "source": "benchmark/evaluation.py#18.21", "target": 11}, {"kind": "ImportFrom", "ref": "to_result", "source": "benchmark/evaluation.py#19.45", "target": "benchmark/report_v2.py#26.229"}, {"kind": "ChunkToCluster", "source": "benchmark/evaluation.py#19.45", "target": 11}, {"kind": "CallTo", "ref": "to_result", "source": "benchmark/evaluation.py#21.88", "target": "benchmark/report_v2.py#26.229"}, {"kind": "ImportFrom", "ref": "to_result", "source": "benchmark/evaluation.py#21.88", "target": "benchmark/report_v2.py#26.229"}, {"kind": "ChunkToCluster", "source": "benchmark/evaluation.py#21.88", "target": 12}, {"kind": "CallTo", "ref": "get_missing_files", "source": "benchmark/report_v1.py#23.307", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_files", "source": "benchmark/report_v1.py#23.307", "target": "benchmark/utils.py#41.27"}, {"kind": "CallTo", "ref": "get_missing_files", "source": "benchmark/report_v1.py#23.307", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_files", "source": "benchmark/report_v1.py#23.307", "target": "benchmark/utils.py#41.27"}, {"kind": "ChunkToCluster", "source": "benchmark/report_v1.py#23.307", "target": 11}, {"kind": "CallTo", "ref": "FileContext", "source": "benchmark/report_v1.py#24.96", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "benchmark/report_v1.py#24.96", "target": "moatless/file_context.py#151.38"}, {"kind": "ChunkToCluster", "source": "benchmark/report_v1.py#24.96", "target": 5}, {"kind": "CallTo", "ref": "Trajectory", "source": "benchmark/report_v2.py#26.229", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "benchmark/report_v2.py#26.229", "target": "moatless/trajectory.py#248.23"}, {"kind": "CallTo", "ref": "AgenticState", "source": "benchmark/report_v2.py#26.229", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "benchmark/report_v2.py#26.229", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "get_missing_files", "source": "benchmark/report_v2.py#26.229", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_files", "source": "benchmark/report_v2.py#26.229", "target": "benchmark/utils.py#41.27"}, {"kind": "CallTo", "ref": "get_missing_files", "source": "benchmark/report_v2.py#26.229", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_files", "source": "benchmark/report_v2.py#26.229", "target": "benchmark/utils.py#41.27"}, {"kind": "ChunkToCluster", "source": "benchmark/report_v2.py#26.229", "target": 11}, {"kind": "CallTo", "ref": "Trajectory", "source": "benchmark/report_v2.py#27.87", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "benchmark/report_v2.py#27.87", "target": "moatless/trajectory.py#248.23"}, {"kind": "CallTo", "ref": "FileContext", "source": "benchmark/report_v2.py#27.87", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "benchmark/report_v2.py#27.87", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "Content", "source": "benchmark/report_v2.py#27.87", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "benchmark/report_v2.py#27.87", "target": 7}, {"kind": "CallTo", "ref": "FileContext", "source": "benchmark/report_v2.py#28.96", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "benchmark/report_v2.py#28.96", "target": "moatless/file_context.py#151.38"}, {"kind": "ChunkToCluster", "source": "benchmark/report_v2.py#28.96", "target": 5}, {"kind": "CallTo", "ref": "get_missing_spans", "source": "swebench/utils.py#31.24", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_spans", "source": "swebench/utils.py#31.24", "target": "benchmark/utils.py#41.27"}, {"kind": "ChunkToCluster", "source": "swebench/utils.py#31.24", "target": 11}, {"kind": "ImportFrom", "ref": "Workspace", "source": "swebench/utils.py#32.109", "target": "moatless/workspace.py#285.46"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "CallTo", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "CallTo", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "ImportFrom", "ref": "file_spans_to_dict", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#40.17"}, {"kind": "CallTo", "ref": "get_missing_files", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#41.27"}, {"kind": "ImportFrom", "ref": "get_missing_files", "source": "swebench/utils.py#32.109", "target": "benchmark/utils.py#41.27"}, {"kind": "ChunkToCluster", "source": "swebench/utils.py#32.109", "target": 14}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "swebench/utils.py#33.76", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileContext", "source": "swebench/utils.py#33.76", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "swebench/utils.py#33.76", "target": "moatless/file_context.py#151.38"}, {"kind": "ChunkToCluster", "source": "swebench/utils.py#33.76", "target": 5}, {"kind": "CallTo", "ref": "setup_github_repo", "source": "swebench/utils.py#34.20", "target": "utils/repo.py#272.23"}, {"kind": "ImportFrom", "ref": "setup_github_repo", "source": "swebench/utils.py#34.20", "target": "utils/repo.py#272.23"}, {"kind": "ChunkToCluster", "source": "swebench/utils.py#34.20", "target": 22}, {"kind": "CallTo", "ref": "GitRepository", "source": "swebench/utils.py#35.34", "target": "repository/git.py#238.98"}, {"kind": "ImportFrom", "ref": "GitRepository", "source": "swebench/utils.py#35.34", "target": "repository/git.py#238.98"}, {"kind": "CallTo", "ref": "CodeIndex", "source": "swebench/utils.py#35.34", "target": "index/code_index.py#180.34"}, {"kind": "ImportFrom", "ref": "CodeIndex", "source": "swebench/utils.py#35.34", "target": "index/code_index.py#180.34"}, {"kind": "CallTo", "ref": "Workspace", "source": "swebench/utils.py#35.34", "target": "moatless/workspace.py#285.46"}, {"kind": "ImportFrom", "ref": "Workspace", "source": "swebench/utils.py#35.34", "target": "moatless/workspace.py#285.46"}, {"kind": "ChunkToCluster", "source": "swebench/utils.py#35.34", "target": 10}, {"kind": "ImportFrom", "ref": "Module", "source": "benchmark/utils.py#36.45", "target": "codeblocks/module.py#73.42"}, {"kind": "ImportFrom", "ref": "Module", "source": "benchmark/utils.py#36.45", "target": "codeblocks/module.py#73.42"}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#36.45", "target": 18}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "benchmark/utils.py#38.36", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileWithSpans", "source": "benchmark/utils.py#38.36", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "FileWithSpans", "source": "benchmark/utils.py#38.36", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#38.36", "target": 9}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "benchmark/utils.py#39.19", "target": "repository/file.py#234.24"}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#39.19", "target": 5}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#40.17", "target": 14}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#41.27", "target": 11}, {"kind": "ChunkToCluster", "source": "benchmark/utils.py#43.23", "target": 7}, {"kind": "CallTo", "ref": "CodeParser", "source": "codeblocks/__init__.py#44.18", "target": "parser/parser.py#80.49"}, {"kind": "ImportFrom", "ref": "CodeParser", "source": "codeblocks/__init__.py#44.18", "target": "parser/parser.py#80.49"}, {"kind": "CallTo", "ref": "PythonParser", "source": "codeblocks/__init__.py#44.18", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "PythonParser", "source": "codeblocks/__init__.py#44.18", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "JavaParser", "source": "codeblocks/__init__.py#44.18", "target": "parser/java.py#78.12"}, {"kind": "ChunkToCluster", "source": "codeblocks/__init__.py#44.18", "target": 8}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#45.28", "target": 2}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#46.41", "target": 2}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#48.45", "target": 2}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#50.19", "target": 6}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#51.45", "target": 6}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#52.59", "target": 2}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#53.99", "target": 2}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "CallTo", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "CallTo", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "CallTo", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ImportFrom", "ref": "Colors", "source": "codeblocks/codeblocks.py#58.109", "target": "utils/colors.py#270.10"}, {"kind": "ChunkToCluster", "source": "codeblocks/codeblocks.py#58.109", "target": 16}, {"kind": "CallTo", "ref": "CodeBlock", "source": "codeblocks/module.py#73.42", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "codeblocks/module.py#73.42", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "codeblocks/module.py#73.42", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "codeblocks/module.py#73.42", "target": 18}, {"kind": "CallTo", "ref": "CodeParser", "source": "parser/create.py#77.25", "target": "parser/parser.py#80.49"}, {"kind": "ImportFrom", "ref": "CodeParser", "source": "parser/create.py#77.25", "target": "parser/parser.py#80.49"}, {"kind": "CallTo", "ref": "CodeParser", "source": "parser/create.py#77.25", "target": "parser/parser.py#80.49"}, {"kind": "ImportFrom", "ref": "CodeParser", "source": "parser/create.py#77.25", "target": "parser/parser.py#80.49"}, {"kind": "CallTo", "ref": "PythonParser", "source": "parser/create.py#77.25", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "PythonParser", "source": "parser/create.py#77.25", "target": "parser/python.py#96.60"}, {"kind": "CallTo", "ref": "PythonParser", "source": "parser/create.py#77.25", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "PythonParser", "source": "parser/create.py#77.25", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "JavaParser", "source": "parser/create.py#77.25", "target": "parser/java.py#78.12"}, {"kind": "ImportFrom", "ref": "JavaParser", "source": "parser/create.py#77.25", "target": "parser/java.py#78.12"}, {"kind": "ChunkToCluster", "source": "parser/create.py#77.25", "target": 8}, {"kind": "ChunkToCluster", "source": "parser/java.py#78.12", "target": 8}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#79.67", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#79.67", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#79.67", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#80.49", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#80.49", "target": 8}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#82.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#82.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#82.38", "target": 2}, {"kind": "CallTo", "ref": "CodeBlock", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "BlockSpan", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#83.106", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "Module", "source": "parser/parser.py#83.106", "target": "codeblocks/module.py#73.42"}, {"kind": "ImportFrom", "ref": "Module", "source": "parser/parser.py#83.106", "target": "codeblocks/module.py#73.42"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#83.106", "target": 2}, {"kind": "CallTo", "ref": "CodeBlock", "source": "parser/parser.py#84.92", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#84.92", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#84.92", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#84.92", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#85.25", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#85.25", "target": 2}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#88.80", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#88.80", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#88.80", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "ImportFrom", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "CallTo", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "ImportFrom", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "CallTo", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "ImportFrom", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "CallTo", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "ImportFrom", "ref": "Relationship", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#51.45"}, {"kind": "ImportFrom", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "RelationshipType", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "CallTo", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "ReferenceScope", "source": "parser/parser.py#89.84", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#89.84", "target": 6}, {"kind": "CallTo", "ref": "Parameter", "source": "parser/parser.py#90.19", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "Parameter", "source": "parser/parser.py#90.19", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#90.19", "target": 2}, {"kind": "CallTo", "ref": "CodeBlock", "source": "parser/parser.py#91.37", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#91.37", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#91.37", "target": 2}, {"kind": "CallTo", "ref": "Module", "source": "parser/parser.py#92.26", "target": "codeblocks/module.py#73.42"}, {"kind": "ImportFrom", "ref": "Module", "source": "parser/parser.py#92.26", "target": "codeblocks/module.py#73.42"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#92.26", "target": 18}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "CallTo", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "SpanType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "CallTo", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "CallTo", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "CallTo", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#93.83", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#93.83", "target": 2}, {"kind": "CallTo", "ref": "BlockSpan", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "CallTo", "ref": "CodeBlock", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/parser.py#94.45", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#94.45", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/parser.py#95.32", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#95.32", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#95.32", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#95.32", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "parser/parser.py#95.32", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ChunkToCluster", "source": "parser/parser.py#95.32", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "NodeMatch", "source": "parser/python.py#96.60", "target": "parser/parser.py#79.67"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#96.60", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "parser/python.py#96.60", "target": 8}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "ReferenceScope", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "ReferenceScope", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#50.19"}, {"kind": "ImportFrom", "ref": "ValidationError", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "ValidationError", "source": "parser/python.py#97.73", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ChunkToCluster", "source": "parser/python.py#97.73", "target": 2}, {"kind": "CallTo", "ref": "ActionRequest", "source": "edit/clarify.py#99.29", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/clarify.py#99.29", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#99.29", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "edit/clarify.py#100.15", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "edit/clarify.py#100.15", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "CodeFile", "source": "edit/clarify.py#100.15", "target": "repository/file.py#231.27"}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "edit/clarify.py#100.15", "target": "repository/file.py#231.27"}, {"kind": "CallTo", "ref": "BlockSpan", "source": "edit/clarify.py#100.15", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "edit/clarify.py#100.15", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#100.15", "target": 1}, {"kind": "ImportFrom", "ref": "FileWithSpans", "source": "edit/clarify.py#101.28", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/clarify.py#101.28", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#101.28", "target": 9}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "edit/clarify.py#103.15", "target": "repository/file.py#231.27"}, {"kind": "ImportFrom", "ref": "BlockSpan", "source": "edit/clarify.py#103.15", "target": "codeblocks/codeblocks.py#52.59"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#103.15", "target": 17}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "edit/clarify.py#104.66", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/clarify.py#104.66", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "count_tokens", "source": "edit/clarify.py#104.66", "target": "utils/tokenizer.py#277.48"}, {"kind": "ImportFrom", "ref": "count_tokens", "source": "edit/clarify.py#104.66", "target": "utils/tokenizer.py#277.48"}, {"kind": "ImportFrom", "ref": "Message", "source": "edit/clarify.py#104.66", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#104.66", "target": 20}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/clarify.py#105.66", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/clarify.py#105.66", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#105.66", "target": 2}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#106.30", "target": 3}, {"kind": "ChunkToCluster", "source": "edit/clarify.py#107.29", "target": 3}, {"kind": "CallTo", "ref": "ActionRequest", "source": "edit/edit.py#108.84", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/edit.py#108.84", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/edit.py#108.84", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "edit/edit.py#109.28", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "edit/edit.py#109.28", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "edit/edit.py#109.28", "target": 1}, {"kind": "ImportFrom", "ref": "Content", "source": "edit/edit.py#110.43", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "edit/edit.py#110.43", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#110.43", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#110.43", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#110.43", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/edit.py#110.43", "target": 3}, {"kind": "ImportFrom", "ref": "Content", "source": "edit/edit.py#111.100", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "VerificationError", "source": "edit/edit.py#111.100", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "VerificationError", "source": "edit/edit.py#111.100", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#111.100", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#111.100", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/edit.py#111.100", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/edit.py#111.100", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/edit.py#111.100", "target": 3}, {"kind": "ImportFrom", "ref": "UserMessage", "source": "edit/edit.py#113.51", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "edit/edit.py#113.51", "target": 4}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/plan.py#115.31", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#115.31", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "edit/plan.py#116.61", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "edit/plan.py#116.61", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#116.61", "target": 1}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#117.29", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#117.29", "target": 3}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#118.59", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#118.59", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#118.59", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#118.59", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#118.59", "target": 3}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan.py#119.54", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "edit/plan.py#119.54", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "_get_pre_start_line", "source": "edit/plan.py#119.54", "target": "edit/clarify.py#106.30"}, {"kind": "ImportFrom", "ref": "_get_post_end_line_index", "source": "edit/plan.py#119.54", "target": "edit/clarify.py#107.29"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#119.54", "target": 3}, {"kind": "CallTo", "ref": "UserMessage", "source": "edit/plan.py#121.41", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "UserMessage", "source": "edit/plan.py#121.41", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "edit/plan.py#121.41", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "edit/plan.py#121.41", "target": 4}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/plan_lines.py#123.29", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/plan_lines.py#123.29", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "edit/plan_lines.py#124.69", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "edit/plan_lines.py#124.69", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#124.69", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/plan_lines.py#124.69", "target": 1}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/plan_lines.py#125.90", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "edit/plan_lines.py#125.90", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/plan_lines.py#125.90", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "edit/plan_lines.py#125.90", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "edit/plan_lines.py#125.90", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "count_tokens", "source": "edit/plan_lines.py#125.90", "target": "utils/tokenizer.py#277.48"}, {"kind": "ImportFrom", "ref": "count_tokens", "source": "edit/plan_lines.py#125.90", "target": "utils/tokenizer.py#277.48"}, {"kind": "CallTo", "ref": "_get_pre_start_line", "source": "edit/plan_lines.py#125.90", "target": "edit/clarify.py#106.30"}, {"kind": "ImportFrom", "ref": "_get_pre_start_line", "source": "edit/plan_lines.py#125.90", "target": "edit/clarify.py#106.30"}, {"kind": "ImportFrom", "ref": "_get_post_end_line_index", "source": "edit/plan_lines.py#125.90", "target": "edit/clarify.py#107.29"}, {"kind": "ChunkToCluster", "source": "edit/plan_lines.py#125.90", "target": 3}, {"kind": "CallTo", "ref": "UserMessage", "source": "edit/plan_lines.py#127.37", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "UserMessage", "source": "edit/plan_lines.py#127.37", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "edit/plan_lines.py#127.37", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "edit/plan_lines.py#127.37", "target": 4}, {"kind": "CallTo", "ref": "ActionRequest", "source": "edit/review.py#129.29", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/review.py#129.29", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/review.py#129.29", "target": 9}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/review.py#130.35", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/review.py#130.35", "target": 9}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "edit/review.py#131.25", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "edit/review.py#131.25", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "edit/review.py#132.57", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "edit/review.py#132.57", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#132.57", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/review.py#132.57", "target": 1}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#133.88", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/review.py#133.88", "target": 3}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#134.84", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#134.84", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#134.84", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#134.84", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "edit/review.py#134.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "edit/review.py#134.84", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "_get_pre_start_line", "source": "edit/review.py#134.84", "target": "edit/clarify.py#106.30"}, {"kind": "ImportFrom", "ref": "_get_post_end_line_index", "source": "edit/review.py#134.84", "target": "edit/clarify.py#107.29"}, {"kind": "ChunkToCluster", "source": "edit/review.py#134.84", "target": 3}, {"kind": "CallTo", "ref": "ActionResponse", "source": "edit/review.py#135.23", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#135.23", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#135.23", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "edit/review.py#135.23", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "edit/review.py#135.23", "target": 3}, {"kind": "CallTo", "ref": "UserMessage", "source": "edit/review.py#137.40", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "UserMessage", "source": "edit/review.py#137.40", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "edit/review.py#137.40", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "edit/review.py#137.40", "target": 4}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#138.39", "target": 23}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "moatless/file_context.py#139.27", "target": "repository/file.py#231.27"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#139.27", "target": 17}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "moatless/file_context.py#141.18", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#141.18", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "SpanMarker", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "SpanMarker", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#143.103", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#143.103", "target": 2}, {"kind": "ImportFrom", "ref": "UpdateResult", "source": "moatless/file_context.py#148.13", "target": "repository/file.py#230.23"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#148.13", "target": 27}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "moatless/file_context.py#149.21", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#149.21", "target": 2}, {"kind": "CallTo", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/file_context.py#151.38", "target": "repository/file.py#234.24"}, {"kind": "ChunkToCluster", "source": "moatless/file_context.py#151.38", "target": 5}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "find/decide.py#161.20", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "find/decide.py#161.20", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "find/decide.py#162.55", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "find/decide.py#162.55", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "find/decide.py#162.55", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/decide.py#162.55", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/decide.py#162.55", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/decide.py#162.55", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/decide.py#162.55", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "find/decide.py#162.55", "target": 1}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "find/identify.py#165.63", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "find/identify.py#165.63", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "find/identify.py#166.16", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "find/identify.py#166.16", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "find/identify.py#166.16", "target": 1}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/identify.py#167.27", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "find/identify.py#167.27", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "find/identify.py#167.27", "target": 3}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "find/search.py#173.21", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "find/search.py#173.21", "target": 9}, {"kind": "CallTo", "ref": "AgenticState", "source": "find/search.py#174.26", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "find/search.py#174.26", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "find/search.py#174.26", "target": 1}, {"kind": "CallTo", "ref": "RankedFileSpan", "source": "find/search.py#175.54", "target": "moatless/file_context.py#138.39"}, {"kind": "ImportFrom", "ref": "RankedFileSpan", "source": "find/search.py#175.54", "target": "moatless/file_context.py#138.39"}, {"kind": "ChunkToCluster", "source": "find/search.py#175.54", "target": 23}, {"kind": "CallTo", "ref": "instructor_mode_by_model", "source": "find/search.py#176.28", "target": "utils/llm_utils.py#271.17"}, {"kind": "ImportFrom", "ref": "instructor_mode_by_model", "source": "find/search.py#176.28", "target": "utils/llm_utils.py#271.17"}, {"kind": "ChunkToCluster", "source": "find/search.py#176.28", "target": 24}, {"kind": "CallTo", "ref": "UserMessage", "source": "find/search.py#177.74", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "UserMessage", "source": "find/search.py#177.74", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "find/search.py#177.74", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "find/search.py#177.74", "target": 4}, {"kind": "ImportFrom", "ref": "IndexSettings", "source": "index/code_index.py#179.50", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "SimpleFaissVectorStore", "source": "index/code_index.py#179.50", "target": "index/simple_faiss.py#210.55"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#179.50", "target": 21}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "index/code_index.py#180.34", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "IndexSettings", "source": "index/code_index.py#180.34", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "IndexSettings", "source": "index/code_index.py#180.34", "target": "index/settings.py#208.52"}, {"kind": "CallTo", "ref": "get_embed_model", "source": "index/code_index.py#180.34", "target": "index/embed_model.py#199.35"}, {"kind": "ImportFrom", "ref": "get_embed_model", "source": "index/code_index.py#180.34", "target": "index/embed_model.py#199.35"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#180.34", "target": 10}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "index/code_index.py#181.27", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "SimpleFaissVectorStore", "source": "index/code_index.py#181.27", "target": "index/simple_faiss.py#210.55"}, {"kind": "ImportFrom", "ref": "SimpleFaissVectorStore", "source": "index/code_index.py#181.27", "target": "index/simple_faiss.py#210.55"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#181.27", "target": 21}, {"kind": "CallTo", "ref": "FileRepository", "source": "index/code_index.py#182.23", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "index/code_index.py#182.23", "target": "repository/file.py#234.24"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#182.23", "target": 5}, {"kind": "CallTo", "ref": "FileRepository", "source": "index/code_index.py#183.25", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "index/code_index.py#183.25", "target": "repository/file.py#234.24"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#183.25", "target": 5}, {"kind": "CallTo", "ref": "SearchCodeResponse", "source": "index/code_index.py#184.47", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#184.47", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#184.47", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#184.47", "target": 13}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#185.52", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#185.52", "target": 13}, {"kind": "ImportFrom", "ref": "SearchCodeHit", "source": "index/code_index.py#186.92", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#186.92", "target": 13}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#187.11", "target": "index/types.py#217.34"}, {"kind": "CallTo", "ref": "SearchCodeResponse", "source": "index/code_index.py#187.11", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#187.11", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#187.11", "target": 13}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#188.113", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#188.113", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#188.113", "target": "index/types.py#217.34"}, {"kind": "CallTo", "ref": "SearchCodeHit", "source": "index/code_index.py#188.113", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeHit", "source": "index/code_index.py#188.113", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#188.113", "target": 13}, {"kind": "CallTo", "ref": "SearchCodeResponse", "source": "index/code_index.py#189.37", "target": "index/types.py#217.34"}, {"kind": "ImportFrom", "ref": "SearchCodeResponse", "source": "index/code_index.py#189.37", "target": "index/types.py#217.34"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#189.37", "target": 13}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/code_index.py#190.12", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "FileWithSpans", "source": "index/code_index.py#190.12", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "FileWithSpans", "source": "index/code_index.py#190.12", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#190.12", "target": 9}, {"kind": "CallTo", "ref": "CodeSnippet", "source": "index/code_index.py#191.117", "target": "index/types.py#216.27"}, {"kind": "ImportFrom", "ref": "CodeSnippet", "source": "index/code_index.py#191.117", "target": "index/types.py#216.27"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#191.117", "target": 25}, {"kind": "CallTo", "ref": "CodeBlock", "source": "index/code_index.py#194.13", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/code_index.py#194.13", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/code_index.py#194.13", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/code_index.py#194.13", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#194.13", "target": 2}, {"kind": "CallTo", "ref": "EpicSplitter", "source": "index/code_index.py#195.38", "target": "index/epic_split.py#201.93"}, {"kind": "ImportFrom", "ref": "EpicSplitter", "source": "index/code_index.py#195.38", "target": "index/epic_split.py#201.93"}, {"kind": "ChunkToCluster", "source": "index/code_index.py#195.38", "target": 15}, {"kind": "ChunkToCluster", "source": "index/code_node.py#198.14", "target": 26}, {"kind": "ChunkToCluster", "source": "index/embed_model.py#199.35", "target": 10}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlock", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#200.38", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#200.38", "target": 2}, {"kind": "CallTo", "ref": "CommentStrategy", "source": "index/epic_split.py#201.93", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CommentStrategy", "source": "index/epic_split.py#201.93", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CommentStrategy", "source": "index/epic_split.py#201.93", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CommentStrategy", "source": "index/epic_split.py#201.93", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#201.93", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#201.93", "target": 15}, {"kind": "CallTo", "ref": "create_parser", "source": "index/epic_split.py#202.56", "target": "parser/create.py#77.25"}, {"kind": "ImportFrom", "ref": "create_parser", "source": "index/epic_split.py#202.56", "target": "parser/create.py#77.25"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#202.56", "target": 8}, {"kind": "CallTo", "ref": "CodeBlock", "source": "index/epic_split.py#203.33", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#203.33", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#203.33", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#203.33", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#203.33", "target": 2}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#204.94", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#204.94", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#204.94", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CommentStrategy", "source": "index/epic_split.py#204.94", "target": "index/settings.py#208.52"}, {"kind": "CallTo", "ref": "CommentStrategy", "source": "index/epic_split.py#204.94", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CommentStrategy", "source": "index/epic_split.py#204.94", "target": "index/settings.py#208.52"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#204.94", "target": 15}, {"kind": "CallTo", "ref": "PathTree", "source": "index/epic_split.py#205.76", "target": "codeblocks/codeblocks.py#48.45"}, {"kind": "ImportFrom", "ref": "PathTree", "source": "index/epic_split.py#205.76", "target": "codeblocks/codeblocks.py#48.45"}, {"kind": "CallTo", "ref": "CodeBlock", "source": "index/epic_split.py#205.76", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#205.76", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#205.76", "target": 2}, {"kind": "CallTo", "ref": "CodeBlock", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "ImportFrom", "ref": "CodeBlock", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#53.99"}, {"kind": "CallTo", "ref": "PathTree", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#48.45"}, {"kind": "ImportFrom", "ref": "PathTree", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#48.45"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "index/epic_split.py#206.58", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#206.58", "target": 2}, {"kind": "CallTo", "ref": "CodeNode", "source": "index/epic_split.py#207.54", "target": "index/code_node.py#198.14"}, {"kind": "ImportFrom", "ref": "CodeNode", "source": "index/epic_split.py#207.54", "target": "index/code_node.py#198.14"}, {"kind": "ChunkToCluster", "source": "index/epic_split.py#207.54", "target": 26}, {"kind": "ChunkToCluster", "source": "index/settings.py#208.52", "target": 15}, {"kind": "ChunkToCluster", "source": "index/simple_faiss.py#210.55", "target": 21}, {"kind": "ChunkToCluster", "source": "index/types.py#216.27", "target": 25}, {"kind": "ChunkToCluster", "source": "index/types.py#217.34", "target": 13}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/loop.py#219.112", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/loop.py#219.112", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "Workspace", "source": "moatless/loop.py#219.112", "target": "moatless/workspace.py#285.46"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "moatless/loop.py#219.112", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "moatless/loop.py#219.112", "target": "moatless/trajectory.py#248.23"}, {"kind": "CallTo", "ref": "Trajectory", "source": "moatless/loop.py#219.112", "target": "moatless/trajectory.py#248.23"}, {"kind": "ImportFrom", "ref": "Trajectory", "source": "moatless/loop.py#219.112", "target": "moatless/trajectory.py#248.23"}, {"kind": "CallTo", "ref": "Pending", "source": "moatless/loop.py#219.112", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Pending", "source": "moatless/loop.py#219.112", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#219.112", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#219.112", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#219.112", "target": 7}, {"kind": "ImportFrom", "ref": "Response", "source": "moatless/loop.py#220.45", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Response", "source": "moatless/loop.py#220.45", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "Pending", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Pending", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Rejected", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/loop.py#220.45", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#220.45", "target": 1}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#221.38", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/loop.py#221.38", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#221.38", "target": 1}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#222.53", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "Pending", "source": "moatless/loop.py#222.53", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#222.53", "target": 1}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/loop.py#223.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#223.40", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/loop.py#223.40", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/loop.py#223.40", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Rejected", "source": "moatless/loop.py#223.40", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/loop.py#223.40", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#223.40", "target": 1}, {"kind": "CallTo", "ref": "NoopState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "NoopState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "AgenticState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "AgenticState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#224.22", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#224.22", "target": 1}, {"kind": "ImportFrom", "ref": "Usage", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "Usage", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Usage", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Content", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "Usage", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Usage", "source": "moatless/loop.py#225.125", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#225.125", "target": 4}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/loop.py#226.105", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#226.105", "target": 1}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "moatless/loop.py#227.37", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "moatless/loop.py#227.37", "target": 9}, {"kind": "ChunkToCluster", "source": "repository/file.py#230.23", "target": 27}, {"kind": "ImportFrom", "ref": "Module", "source": "repository/file.py#231.27", "target": "codeblocks/module.py#73.42"}, {"kind": "CallTo", "ref": "PythonParser", "source": "repository/file.py#231.27", "target": "parser/python.py#96.60"}, {"kind": "ImportFrom", "ref": "PythonParser", "source": "repository/file.py#231.27", "target": "parser/python.py#96.60"}, {"kind": "ChunkToCluster", "source": "repository/file.py#231.27", "target": 17}, {"kind": "CallTo", "ref": "CodeBlockType", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "ImportFrom", "ref": "CodeBlockType", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#46.41"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "CallTo", "ref": "CodeBlockTypeGroup", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ImportFrom", "ref": "CodeBlockTypeGroup", "source": "repository/file.py#233.85", "target": "codeblocks/codeblocks.py#45.28"}, {"kind": "ChunkToCluster", "source": "repository/file.py#233.85", "target": 2}, {"kind": "ChunkToCluster", "source": "repository/file.py#234.24", "target": 5}, {"kind": "ImportFrom", "ref": "checkout_commit", "source": "repository/git.py#238.98", "target": "utils/repo.py#276.83"}, {"kind": "ImportFrom", "ref": "maybe_clone", "source": "repository/git.py#238.98", "target": "utils/repo.py#273.15"}, {"kind": "ChunkToCluster", "source": "repository/git.py#238.98", "target": 5}, {"kind": "CallTo", "ref": "ActionRequest", "source": "moatless/state.py#242.107", "target": "moatless/types.py#267.27"}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "moatless/state.py#242.107", "target": "moatless/types.py#267.27"}, {"kind": "CallTo", "ref": "Usage", "source": "moatless/state.py#242.107", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Usage", "source": "moatless/state.py#242.107", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "ActionTransaction", "source": "moatless/state.py#242.107", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "ActionResponse", "source": "moatless/state.py#242.107", "target": "moatless/types.py#268.26"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "moatless/state.py#242.107", "target": "moatless/types.py#268.26"}, {"kind": "CallTo", "ref": "FileContext", "source": "moatless/state.py#242.107", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "moatless/state.py#242.107", "target": "moatless/file_context.py#151.38"}, {"kind": "ChunkToCluster", "source": "moatless/state.py#242.107", "target": 1}, {"kind": "CallTo", "ref": "Content", "source": "moatless/state.py#244.79", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Content", "source": "moatless/state.py#244.79", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "moatless/state.py#244.79", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "AssistantMessage", "source": "moatless/state.py#244.79", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "AssistantMessage", "source": "moatless/state.py#244.79", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "ActionRequest", "source": "moatless/state.py#244.79", "target": "moatless/types.py#267.27"}, {"kind": "ChunkToCluster", "source": "moatless/state.py#244.79", "target": 4}, {"kind": "ChunkToCluster", "source": "moatless/state.py#245.19", "target": 1}, {"kind": "ChunkToCluster", "source": "moatless/state.py#246.34", "target": 19}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/trajectory.py#247.47", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/trajectory.py#247.47", "target": 1}, {"kind": "ImportFrom", "ref": "Workspace", "source": "moatless/trajectory.py#248.23", "target": "moatless/workspace.py#285.46"}, {"kind": "ChunkToCluster", "source": "moatless/trajectory.py#248.23", "target": 7}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/trajectory.py#249.72", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "Workspace", "source": "moatless/trajectory.py#249.72", "target": "moatless/workspace.py#285.46"}, {"kind": "ImportFrom", "ref": "Workspace", "source": "moatless/trajectory.py#249.72", "target": "moatless/workspace.py#285.46"}, {"kind": "CallTo", "ref": "get_state_class", "source": "moatless/trajectory.py#249.72", "target": "moatless/state.py#246.34"}, {"kind": "ImportFrom", "ref": "get_state_class", "source": "moatless/trajectory.py#249.72", "target": "moatless/state.py#246.34"}, {"kind": "CallTo", "ref": "Content", "source": "moatless/trajectory.py#249.72", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Content", "source": "moatless/trajectory.py#249.72", "target": "moatless/types.py#269.68"}, {"kind": "CallTo", "ref": "Usage", "source": "moatless/trajectory.py#249.72", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "Usage", "source": "moatless/trajectory.py#249.72", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "ActionResponse", "source": "moatless/trajectory.py#249.72", "target": "moatless/types.py#268.26"}, {"kind": "ChunkToCluster", "source": "moatless/trajectory.py#249.72", "target": 4}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/trajectory.py#252.35", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/trajectory.py#252.35", "target": 1}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#254.61", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#254.61", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "get_state_class", "source": "moatless/transition_rules.py#254.61", "target": "moatless/state.py#246.34"}, {"kind": "ImportFrom", "ref": "get_state_class", "source": "moatless/transition_rules.py#254.61", "target": "moatless/state.py#246.34"}, {"kind": "ImportFrom", "ref": "get_state_class", "source": "moatless/transition_rules.py#254.61", "target": "moatless/state.py#246.34"}, {"kind": "ChunkToCluster", "source": "moatless/transition_rules.py#254.61", "target": 1}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#255.36", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#255.36", "target": "moatless/state.py#242.107"}, {"kind": "CallTo", "ref": "AgenticState", "source": "moatless/transition_rules.py#255.36", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#255.36", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/transition_rules.py#255.36", "target": 1}, {"kind": "CallTo", "ref": "get_state_class", "source": "moatless/transition_rules.py#256.20", "target": "moatless/state.py#246.34"}, {"kind": "ImportFrom", "ref": "get_state_class", "source": "moatless/transition_rules.py#256.20", "target": "moatless/state.py#246.34"}, {"kind": "ImportFrom", "ref": "get_state_class", "source": "moatless/transition_rules.py#256.20", "target": "moatless/state.py#246.34"}, {"kind": "ChunkToCluster", "source": "moatless/transition_rules.py#256.20", "target": 19}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#257.16", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/transition_rules.py#257.16", "target": 1}, {"kind": "CallTo", "ref": "AgenticState", "source": "moatless/transition_rules.py#258.25", "target": "moatless/state.py#242.107"}, {"kind": "ImportFrom", "ref": "AgenticState", "source": "moatless/transition_rules.py#258.25", "target": "moatless/state.py#242.107"}, {"kind": "ChunkToCluster", "source": "moatless/transition_rules.py#258.25", "target": 1}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#259.40", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#259.40", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "CallTo", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#259.40", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "ImportFrom", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "CallTo", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "ImportFrom", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "CallTo", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "ImportFrom", "ref": "ClarifyCodeChange", "source": "moatless/transitions.py#259.40", "target": "edit/clarify.py#100.15"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/transitions.py#259.40", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#259.40", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Rejected", "source": "moatless/transitions.py#259.40", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/transitions.py#259.40", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#259.40", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#260.20", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#260.20", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#260.20", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#260.20", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#260.20", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#260.20", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#260.20", "target": "edit/plan.py#116.61"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#260.20", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "CallTo", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "CallTo", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "CallTo", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "CallTo", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "ImportFrom", "ref": "PlanToCodeWithLines", "source": "moatless/transitions.py#261.19", "target": "edit/plan_lines.py#124.69"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#261.19", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#261.19", "target": "edit/edit.py#109.28"}, {"kind": "CallTo", "ref": "EditCode", "source": "moatless/transitions.py#261.19", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#261.19", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#261.19", "target": "edit/edit.py#109.28"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/transitions.py#261.19", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#261.19", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "Rejected", "source": "moatless/transitions.py#261.19", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/transitions.py#261.19", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#261.19", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#262.11", "target": "edit/edit.py#109.28"}, {"kind": "CallTo", "ref": "EditCode", "source": "moatless/transitions.py#262.11", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#262.11", "target": "edit/edit.py#109.28"}, {"kind": "ImportFrom", "ref": "EditCode", "source": "moatless/transitions.py#262.11", "target": "edit/edit.py#109.28"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#262.11", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/transitions.py#262.11", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#262.11", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Rejected", "source": "moatless/transitions.py#262.11", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#262.11", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#263.42", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#263.42", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#263.42", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#263.42", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/transitions.py#263.42", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#263.42", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#263.42", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#263.42", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#264.33", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#264.33", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#264.33", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#264.33", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#264.33", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#264.33", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#264.33", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "Finished", "source": "moatless/transitions.py#264.33", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#264.33", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Finished", "source": "moatless/transitions.py#264.33", "target": "moatless/state.py#245.19"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#264.33", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#265.28", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "PlanToCode", "source": "moatless/transitions.py#265.28", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#265.28", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#265.28", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#265.28", "target": "moatless/transition_rules.py#254.61"}, {"kind": "CallTo", "ref": "Pending", "source": "moatless/transitions.py#265.28", "target": "moatless/state.py#245.19"}, {"kind": "ImportFrom", "ref": "Pending", "source": "moatless/transitions.py#265.28", "target": "moatless/state.py#245.19"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#265.28", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#265.28", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "CallTo", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "ImportFrom", "ref": "DecideRelevance", "source": "moatless/transitions.py#265.28", "target": "find/decide.py#162.55"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#265.28", "target": 1}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#255.36"}, {"kind": "CallTo", "ref": "TransitionRules", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "TransitionRules", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#255.36"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#266.43", "target": "find/search.py#174.26"}, {"kind": "CallTo", "ref": "SearchCode", "source": "moatless/transitions.py#266.43", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "SearchCode", "source": "moatless/transitions.py#266.43", "target": "find/search.py#174.26"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#266.43", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#266.43", "target": "find/identify.py#166.16"}, {"kind": "CallTo", "ref": "IdentifyCode", "source": "moatless/transitions.py#266.43", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#266.43", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "IdentifyCode", "source": "moatless/transitions.py#266.43", "target": "find/identify.py#166.16"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#266.43", "target": "edit/plan.py#116.61"}, {"kind": "ImportFrom", "ref": "PlanToCode", "source": "moatless/transitions.py#266.43", "target": "edit/plan.py#116.61"}, {"kind": "CallTo", "ref": "TransitionRule", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ImportFrom", "ref": "TransitionRule", "source": "moatless/transitions.py#266.43", "target": "moatless/transition_rules.py#254.61"}, {"kind": "ChunkToCluster", "source": "moatless/transitions.py#266.43", "target": 1}, {"kind": "ChunkToCluster", "source": "moatless/types.py#267.27", "target": 9}, {"kind": "ChunkToCluster", "source": "moatless/types.py#268.26", "target": 3}, {"kind": "ChunkToCluster", "source": "moatless/types.py#269.68", "target": 4}, {"kind": "ChunkToCluster", "source": "utils/colors.py#270.10", "target": 16}, {"kind": "ChunkToCluster", "source": "utils/llm_utils.py#271.17", "target": 24}, {"kind": "ChunkToCluster", "source": "utils/repo.py#272.23", "target": 22}, {"kind": "ChunkToCluster", "source": "utils/repo.py#273.15", "target": 5}, {"kind": "ChunkToCluster", "source": "utils/repo.py#276.83", "target": 5}, {"kind": "ChunkToCluster", "source": "utils/tokenizer.py#277.48", "target": 20}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "verify/lint.py#279.47", "target": "repository/file.py#231.27"}, {"kind": "CallTo", "ref": "VerificationError", "source": "verify/lint.py#279.47", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "VerificationError", "source": "verify/lint.py#279.47", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "verify/lint.py#279.47", "target": 4}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "verify/maven.py#280.57", "target": "repository/file.py#231.27"}, {"kind": "ChunkToCluster", "source": "verify/maven.py#280.57", "target": 17}, {"kind": "CallTo", "ref": "VerificationError", "source": "verify/maven.py#281.16", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "VerificationError", "source": "verify/maven.py#281.16", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "verify/maven.py#281.16", "target": 4}, {"kind": "CallTo", "ref": "VerificationError", "source": "verify/maven.py#282.28", "target": "moatless/types.py#269.68"}, {"kind": "ImportFrom", "ref": "VerificationError", "source": "verify/maven.py#282.28", "target": "moatless/types.py#269.68"}, {"kind": "ChunkToCluster", "source": "verify/maven.py#282.28", "target": 4}, {"kind": "ImportFrom", "ref": "PythonParser", "source": "moatless/workspace.py#284.14", "target": "parser/python.py#96.60"}, {"kind": "ChunkToCluster", "source": "moatless/workspace.py#284.14", "target": 8}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/workspace.py#285.46", "target": "repository/file.py#234.24"}, {"kind": "ImportFrom", "ref": "IndexSettings", "source": "moatless/workspace.py#285.46", "target": "index/settings.py#208.52"}, {"kind": "ImportFrom", "ref": "CodeIndex", "source": "moatless/workspace.py#285.46", "target": "index/code_index.py#180.34"}, {"kind": "CallTo", "ref": "CodeIndex", "source": "moatless/workspace.py#285.46", "target": "index/code_index.py#180.34"}, {"kind": "ImportFrom", "ref": "CodeIndex", "source": "moatless/workspace.py#285.46", "target": "index/code_index.py#180.34"}, {"kind": "CallTo", "ref": "CodeIndex", "source": "moatless/workspace.py#285.46", "target": "index/code_index.py#180.34"}, {"kind": "ImportFrom", "ref": "CodeIndex", "source": "moatless/workspace.py#285.46", "target": "index/code_index.py#180.34"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "moatless/workspace.py#285.46", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "MavenVerifier", "source": "moatless/workspace.py#285.46", "target": "verify/maven.py#280.57"}, {"kind": "ImportFrom", "ref": "PylintVerifier", "source": "moatless/workspace.py#285.46", "target": "verify/lint.py#279.47"}, {"kind": "ChunkToCluster", "source": "moatless/workspace.py#285.46", "target": 10}, {"kind": "ImportFrom", "ref": "GitRepository", "source": "moatless/workspace.py#286.22", "target": "repository/git.py#238.98"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/workspace.py#286.22", "target": "repository/file.py#234.24"}, {"kind": "ChunkToCluster", "source": "moatless/workspace.py#286.22", "target": 5}, {"kind": "CallTo", "ref": "GitRepository", "source": "moatless/workspace.py#287.33", "target": "repository/git.py#238.98"}, {"kind": "ImportFrom", "ref": "GitRepository", "source": "moatless/workspace.py#287.33", "target": "repository/git.py#238.98"}, {"kind": "ImportFrom", "ref": "FileRepository", "source": "moatless/workspace.py#287.33", "target": "repository/file.py#234.24"}, {"kind": "CallTo", "ref": "FileContext", "source": "moatless/workspace.py#287.33", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "FileContext", "source": "moatless/workspace.py#287.33", "target": "moatless/file_context.py#151.38"}, {"kind": "ImportFrom", "ref": "CodeIndex", "source": "moatless/workspace.py#287.33", "target": "index/code_index.py#180.34"}, {"kind": "ChunkToCluster", "source": "moatless/workspace.py#287.33", "target": 5}, {"kind": "ImportFrom", "ref": "CodeFile", "source": "moatless/workspace.py#288.46", "target": "repository/file.py#231.27"}, {"kind": "ChunkToCluster", "source": "moatless/workspace.py#288.46", "target": 17}, {"kind": "CallTo", "ref": "AgenticLoop", "source": "tests/integration_test.py#343.39", "target": "moatless/loop.py#219.112"}, {"kind": "ImportFrom", "ref": "AgenticLoop", "source": "tests/integration_test.py#343.39", "target": "moatless/loop.py#219.112"}, {"kind": "ImportFrom", "ref": "AgenticLoop", "source": "tests/integration_test.py#343.39", "target": "moatless/loop.py#219.112"}, {"kind": "CallTo", "ref": "search_and_code_transitions", "source": "tests/integration_test.py#343.39", "target": "moatless/transitions.py#265.28"}, {"kind": "ImportFrom", "ref": "search_and_code_transitions", "source": "tests/integration_test.py#343.39", "target": "moatless/transitions.py#265.28"}, {"kind": "ChunkToCluster", "source": "tests/integration_test.py#343.39", "target": 7}, {"kind": "CallTo", "ref": "trace_metadata", "source": "tests/integration_test.py#344.65", "target": "benchmark/utils.py#43.23"}, {"kind": "ImportFrom", "ref": "trace_metadata", "source": "tests/integration_test.py#344.65", "target": "benchmark/utils.py#43.23"}, {"kind": "CallTo", "ref": "AgenticLoop", "source": "tests/integration_test.py#344.65", "target": "moatless/loop.py#219.112"}, {"kind": "ImportFrom", "ref": "AgenticLoop", "source": "tests/integration_test.py#344.65", "target": "moatless/loop.py#219.112"}, {"kind": "CallTo", "ref": "search_and_code_transitions", "source": "tests/integration_test.py#344.65", "target": "moatless/transitions.py#265.28"}, {"kind": "ImportFrom", "ref": "search_and_code_transitions", "source": "tests/integration_test.py#344.65", "target": "moatless/transitions.py#265.28"}, {"kind": "ChunkToCluster", "source": "tests/integration_test.py#344.65", "target": 7}, {"kind": "CallTo", "ref": "AgenticLoop", "source": "tests/utils.py#364.12", "target": "moatless/loop.py#219.112"}, {"kind": "ImportFrom", "ref": "AgenticLoop", "source": "tests/utils.py#364.12", "target": "moatless/loop.py#219.112"}, {"kind": "ChunkToCluster", "source": "tests/utils.py#364.12", "target": 7}]}}